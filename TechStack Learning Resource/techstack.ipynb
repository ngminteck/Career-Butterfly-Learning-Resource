{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b9b981e-d994-41b8-81d8-8ff213a69c73",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\n",
      " * Running on http://localhost:5000\n",
      "Press CTRL+C to quit\n",
      "127.0.0.1 - - [28/Mar/2024 16:27:21] \"GET /generate_learning_resource HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [28/Mar/2024 16:29:18] \"GET /generate_learning_resource HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [28/Mar/2024 16:31:07] \"GET /generate_learning_resource HTTP/1.1\" 200 -\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "import pandas as pd\n",
    "import pypandoc\n",
    "import csv\n",
    "import os\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import shutil\n",
    "import zipfile\n",
    "import html2text\n",
    "import json\n",
    "import requests\n",
    "import io\n",
    "from flask import Flask, send_file, jsonify, request, make_response\n",
    "from werkzeug.serving import run_simple\n",
    "\n",
    "class Skill:\n",
    "    def __init__(self, name, keyword, groups=None):\n",
    "        filename = name\n",
    "        filename = filename.replace('/', '-')\n",
    "        filename = filename.replace(\"\\\\\", '-')\n",
    "        filename = filename + \".html\"\n",
    "        path = os.path.join(\"skill\", filename)\n",
    "        path = path.replace(\"\\\\\", '/')\n",
    "        self.resource_path = path  # for the resource path\n",
    "        self.keyword_search = keyword  # keyword for searching LLM\n",
    "        self.group_set = set()\n",
    "        if groups is not None:\n",
    "            self.UpdateGroupSet(groups)\n",
    "\n",
    "    def UpdateGroupSet(self, groups):\n",
    "        self.group_set.update(groups)\n",
    "        # print(\"skill group set updated.\")\n",
    "\n",
    "    def ChangeKeyword(self, keyword):\n",
    "        self.keyword_search = keyword\n",
    "\n",
    "\n",
    "class Group:\n",
    "    def __init__(self, name, skills):\n",
    "        filename = name\n",
    "        filename = filename.replace('/', '-')\n",
    "        filename = filename.replace(\"\\\\\", '-')\n",
    "        filename = filename + \".html\"\n",
    "        path = os.path.join(\"group\", filename)\n",
    "        path = path.replace(\"\\\\\", '/')\n",
    "        self.resource_path = path  # for the resource path\n",
    "        self.keyword_search = name + \" in tech\"  # keyword for searching LLM\n",
    "        self.skill_set = skills\n",
    "\n",
    "    def UpdateSkillSet(self, skill):\n",
    "        self.skill_set.update(skill)\n",
    "        # print(\"group skill set updated.\")\n",
    "\n",
    "    def ChangeKeyword(self, keyword):\n",
    "        self.keyword_search = keyword\n",
    "\n",
    "\n",
    "class TechStack:\n",
    "    def __init__(self):\n",
    "        self.nlp = spacy.load('en_core_web_md')\n",
    "        self.skill_dict_list = {}\n",
    "        self.group_dict_list = {}\n",
    "        self.exact_match_replace_dict_list = {}\n",
    "        self.partial_match_replace_dict_list = {}\n",
    "        self.vector_group_dict_list = {}\n",
    "        self.ignore_set = set()\n",
    "        self.not_found_dict_list = {}\n",
    "        self.three_word_skill_classification_set = set()\n",
    "        self.two_word_skill_classification_set = set()\n",
    "        self.one_word_skill_classification_set = set()\n",
    "        self.backup_keyword_dict_list = {}\n",
    "        self.leetcode_list = [\"c++\", \"c\", \"c#\", \"python\", \"java\", \"javascript\", \"typescript\", \"php\", \"swift\", \"kotlin\",\n",
    "                              \"go\", \"ruby\", \"scala\", \"rust\", \"racket\"]\n",
    "        self.leetcode_company_dict_list = {}\n",
    "        self.leetcode_overall_frequency_dict_list = {}\n",
    "        self.ImportIgnoreSet()\n",
    "        self.AllThisWillBeRemoveOnceFinalize()\n",
    "        self.ImportClassificationSet()\n",
    "        self.ImportSkillDictList()\n",
    "        self.GroupTextVectorization()\n",
    "        self.InitLeetCodeCompanyNameDictList()\n",
    "        self.InitLeetcodeOverallFrequencyDictList()\n",
    "        self.request_queue_no = 0\n",
    "\n",
    "    def GetRequestQueueNo(self):\n",
    "        self.request_queue_no += 1\n",
    "        return self.request_queue_no\n",
    "\n",
    "    def GenerateLearningResource(self, your_skills, job_skills, company_name, generated_directory):\n",
    "        result_dict = {\"Leetcode Question\": None, \"Skill Learning Resource Content\": None,\n",
    "                       \"Skill Learning Resource Remarks\": str(\"\")}\n",
    "        if not os.path.exists(\"learning resource/\" + generated_directory):\n",
    "            os.makedirs(\"learning resource/\" + generated_directory)\n",
    "\n",
    "        for key in job_skills:\n",
    "            text = key\n",
    "            text = text.lower()\n",
    "            if text in self.leetcode_list:\n",
    "                result_dict[\"Leetcode Question\"] = self.GenerateLeetcodeResource(company_name, generated_directory)\n",
    "                break\n",
    "        difference_skill_dict_list = {}\n",
    "        # difference_skill_dict_list = [dict_ for dict_ in job_skills if not any(dict_ == dict2 for dict2 in your_skills)]\n",
    "        difference_skill_dict_list = job_skills\n",
    "        if len(difference_skill_dict_list) != 0:\n",
    "            skill_result_dict = self.GenerateSkillResource(difference_skill_dict_list, generated_directory)\n",
    "            result_dict[\"Skill Learning Resource Content\"] = skill_result_dict[\"Skill Learning Resource Content\"]\n",
    "            result_dict[\"Skill Learning Resource Remarks\"] = skill_result_dict[\"Skill Learning Resource Remarks\"]\n",
    "\n",
    "        filename = \"learning resource/\"+ generated_directory +\"/response.json\"\n",
    "\n",
    "        # Serialize and write the list of dictionaries to a file\n",
    "        with open(filename, 'w') as file:\n",
    "            json.dump(result_dict, file, indent=4)\n",
    "        \n",
    "\n",
    "        self.ZipLearningResource(generated_directory)\n",
    "\n",
    "\n",
    "    @staticmethod\n",
    "    def ZipLearningResource(generated_directory):\n",
    "        directory_path = \"learning resource/\" + generated_directory\n",
    "        zip_filename = \"learning resource/\" + generated_directory + \"/learning resource.zip\"\n",
    "        valid_extensions = ('.html', '.docx', '.csv','.json')\n",
    "\n",
    "        with zipfile.ZipFile(zip_filename, 'w') as zipf:\n",
    "            for folder_name, sub_folders, filenames in os.walk(directory_path):\n",
    "                for filename in filenames:\n",
    "                    if filename.endswith(valid_extensions):\n",
    "                        file_path = os.path.join(folder_name, filename)\n",
    "                        zipf.write(file_path, arcname=filename)\n",
    "\n",
    "    def GenerateLeetcodeResource(self, company, generated_directory):\n",
    "        leetcode_dict_list = {}\n",
    "        check_company = company\n",
    "        check_company = check_company.lower()\n",
    "        company_name_to_search = str(\"\")\n",
    "        for c in self.leetcode_company_dict_list:\n",
    "            check = c.lower()\n",
    "            if check == check_company:\n",
    "                company_name_to_search = c\n",
    "                break\n",
    "        if company_name_to_search == \"\":\n",
    "            shutil.copyfile(\"leetcode/leetcode learning resource.html\",\n",
    "                            \"learning resource/\" + generated_directory + \"/leetcode learning resource.html\")\n",
    "            shutil.copyfile(\"leetcode/leetcode learning resource.docx\",\n",
    "                            \"learning resource/\" + generated_directory + \"/leetcode learning resource.docx\")\n",
    "            df = pd.read_csv(\"leetcode/Top 100 Question List.csv\")\n",
    "            questions_content = str(\"\")\n",
    "            for index, row in df.iterrows():\n",
    "                no = str(row['No'])\n",
    "                title = str(row['Title'])\n",
    "                link = str(row['Link'])\n",
    "                path = \"leetcode/Question/\" + no + \".html\"\n",
    "                if os.path.isfile(path):\n",
    "                    with open(path, \"r\", encoding=\"utf-8\") as file:\n",
    "                        file_content = file.read()\n",
    "\n",
    "                        questions_content += \"<h1><u><b>\"\n",
    "                        questions_content += no\n",
    "                        questions_content += \". \"\n",
    "                        questions_content += title\n",
    "                        questions_content += \"</b></u></h1>\\n\"\n",
    "                        questions_content += link\n",
    "                        questions_content += \"\\n\"\n",
    "                        questions_content += file_content\n",
    "\n",
    "                        h = html2text.HTML2Text()\n",
    "                        h.ignore_links = False\n",
    "                        h.inline_links = False\n",
    "                        h.reference_links = False\n",
    "                        string_format = h.handle(file_content)\n",
    "                        string_format = string_format.replace(\"**\", \"\")\n",
    "                        leetcode_dict_list[no] = no + \". \" + title + \"\\n\" + link + \"\\n\\n\" + string_format\n",
    "                        file.close()\n",
    "\n",
    "            with open(\"learning resource/\" + generated_directory + \"/leetcode question.html\", 'w',\n",
    "                      encoding='utf-8') as file:\n",
    "                file.write(questions_content)\n",
    "                file.close()\n",
    "            pypandoc.convert_text(questions_content, 'docx', format='html',\n",
    "                                  outputfile='learning resource/' + generated_directory + '/leetcode question.docx')\n",
    "            df[company + \" Company Frequency\"] = 0\n",
    "            df[\"Overall Frequency\"] = df[\"Frequency\"]\n",
    "            df = df.drop(columns=['Frequency'])\n",
    "            df.to_csv(\"learning resource/\" + generated_directory + \"/leetcode question list.csv\", encoding='utf-8',\n",
    "                      index=False)\n",
    "            return leetcode_dict_list\n",
    "        else:\n",
    "            html_content = \"\"\n",
    "            title = \"<h1><u><b>\" + company + \" Leetcode Tag Type Appear in the Question Count</b></u></h1>\\n\"\n",
    "            html_content += title\n",
    "            html_content += \"<table>\\n\"\n",
    "            html_content += \"<tr>\\n\"\n",
    "            html_content += \"  <th>Tag</th>\\n\"\n",
    "            html_content += \"  <th>Count</th>\\n\"\n",
    "            html_content += \"</tr>\\n\"\n",
    "            df = pd.read_csv(\"leetcode/Top Tag/\" + company_name_to_search + \".csv\")\n",
    "            for index, row in df.iterrows():\n",
    "                html_content += \"<tr>\\n\"\n",
    "                tag_html = \"  <td>\" + str(row[\"Tag\"]) + \"</td>\\n\"\n",
    "                count_html = \"  <td>\" + str(row[\"Appearance\"]) + \"</td>\\n\"\n",
    "                html_content += tag_html\n",
    "                html_content += count_html\n",
    "                html_content += \"</tr>\\n\"\n",
    "            html_content += \"</table>\\n\"\n",
    "            with open(\"leetcode/leetcode learning resource.html\", \"r\", encoding=\"utf-8\") as file:\n",
    "                html_content += file.read()\n",
    "                file.close()\n",
    "            with open(\"learning resource/\" + generated_directory + \"/leetcode learning resource.html\", 'w',\n",
    "                      encoding='utf-8') as file:\n",
    "                file.write(html_content)\n",
    "                file.close()\n",
    "            pypandoc.convert_text(html_content, 'docx', format='html', outputfile=\"learning resource/\" + generated_directory + \"/leetcode learning resource.docx\")\n",
    "            df1 = pd.read_csv(\"leetcode/Companies Leetcode/\" + company_name_to_search + \".csv\")\n",
    "            df1[company + \" Company Frequency\"] = df1[\"Frequency\"]\n",
    "            df1 = df1.drop(columns=['Frequency'])\n",
    "            df1[\"Overall Frequency\"] = str(\"\")\n",
    "            for index, row in df1.iterrows():\n",
    "                no = str(row['No'])\n",
    "                if no in self.leetcode_overall_frequency_dict_list:\n",
    "                    df1.at[index, \"Overall Frequency\"] = self.leetcode_overall_frequency_dict_list[no]\n",
    "            df = pd.read_csv(\"leetcode/Top 100 Question List.csv\")\n",
    "            df[company + \" Company Frequency\"] = 0\n",
    "            df[\"Overall Frequency\"] = df['Frequency']\n",
    "            df = df.drop(columns=['Frequency'])\n",
    "            appended_df = pd.concat([df1, df], ignore_index=True)\n",
    "            appended_df = appended_df.drop_duplicates(keep='first')\n",
    "            final_df = appended_df.head(100).copy()\n",
    "            final_df.to_csv(\"learning resource/\" + generated_directory + \"/leetcode question list.csv\",\n",
    "                            encoding='utf-8', index=False)\n",
    "            questions_content = \"\"\n",
    "            for index, row in final_df.iterrows():\n",
    "                no = str(row['No'])\n",
    "                title = str(row['Title'])\n",
    "                link = str(row['Link'])\n",
    "                path = \"leetcode/Question/\" + no + \".html\"\n",
    "                if os.path.isfile(path):\n",
    "                    with open(path, \"r\", encoding=\"utf-8\") as file:\n",
    "                        file_content = file.read()\n",
    "\n",
    "                        questions_content += \"<h1><u><b>\"\n",
    "                        questions_content += no\n",
    "                        questions_content += \". \"\n",
    "                        questions_content += title\n",
    "                        questions_content += \"</b></u></h1>\\n\"\n",
    "                        questions_content += link\n",
    "                        questions_content += \"\\n\"\n",
    "                        questions_content += file_content\n",
    "\n",
    "                        h = html2text.HTML2Text()\n",
    "                        h.ignore_links = False\n",
    "                        h.inline_links = False\n",
    "                        h.reference_links = False\n",
    "                        string_format = h.handle(file_content)\n",
    "                        string_format = string_format.replace(\"**\", \"\")\n",
    "                        leetcode_dict_list[no] = no + \". \" + title + \"\\n\" + link + \"\\n\\n\" + string_format\n",
    "                        file.close()\n",
    "\n",
    "            with open(\"learning resource/\" + generated_directory + \"/leetcode question.html\", 'w', encoding='utf-8') as file:\n",
    "                file.write(questions_content)\n",
    "                file.close()\n",
    "            pypandoc.convert_text(questions_content, 'docx', format='html', outputfile=\"learning resource/\" + generated_directory + \"/leetcode question.docx\")\n",
    "            return leetcode_dict_list\n",
    "\n",
    "    def GenerateSkillResource(self, skills, generated_directory):\n",
    "        result_dict = {\"Skill Learning Resource Content\": None, \"Skill Learning Resource Remarks\": str(\"\")}\n",
    "\n",
    "        result_dict[\"Skill Learning Resource Remarks\"], document_prepare_set = self.GenerateSkillResourcePreProcessing(\n",
    "            skills, result_dict[\"Skill Learning Resource Remarks\"])\n",
    "        if len(document_prepare_set) == 0:\n",
    "            return result_dict\n",
    "\n",
    "        result_dict[\"Skill Learning Resource Remarks\"], result_dict[\"Skill Learning Resource Content\"] = self.GenerateSkillResourceContent(skills, document_prepare_set, result_dict[\"Skill Learning Resource Remarks\"], generated_directory)\n",
    "        return result_dict\n",
    "\n",
    "    def GenerateSkillResourcePreProcessing(self, skills, remarks):\n",
    "        document_prepare_set = set()\n",
    "\n",
    "        for key, value in skills.items():\n",
    "            remarks, skills[key] = self.SkillLearningResourceFilter(key, value, remarks)\n",
    "            if skills[key] != \"\":\n",
    "                remarks, document_prepare_set = self.SkillLearningResourceSearch(key, skills[key], document_prepare_set, remarks)\n",
    "        return remarks, document_prepare_set\n",
    "\n",
    "    def GenerateSkillResourceContent(self, skills, document_prepare_set, remarks, generated_directory):\n",
    "        skill_dict = {}\n",
    "        html_content = \"\"\n",
    "        for d in document_prepare_set:\n",
    "            if d in self.skill_dict_list:\n",
    "                v = self.skill_dict_list.get(d)\n",
    "                path = v.resource_path\n",
    "            elif d in self.skill_dict_list:\n",
    "                v = self.group_dict_list.get(d)\n",
    "                path = v.resource_path\n",
    "            else:\n",
    "                continue\n",
    "            if not os.path.isfile(path):\n",
    "                if len(remarks) != 0:\n",
    "                    remarks += \"\\n\"\n",
    "                remarks += \"can't generate content for \"\n",
    "                remarks += d.title()\n",
    "            else:\n",
    "                with open(path, \"r\", encoding=\"utf-8\") as file:\n",
    "                    title = d.title()\n",
    "                    html_content += \"<h1><u><b>\"\n",
    "                    html_content += title\n",
    "                    html_content += \"</b></u></h1>\"\n",
    "                    file_content = file.read()\n",
    "                    html_content += file_content\n",
    "                    h = html2text.HTML2Text()\n",
    "                    h.ignore_links = False\n",
    "                    h.inline_links = False\n",
    "                    h.reference_links = True\n",
    "                    skill_dict[title] = h.handle(file_content)\n",
    "                file.close()\n",
    "        with open(\"learning resource/\" + generated_directory + \"/skill learning resource.html\", 'w',\n",
    "                  encoding='utf-8') as file:\n",
    "            file.write(html_content)\n",
    "            file.close()\n",
    "        pypandoc.convert_text(html_content, 'docx', format='html',\n",
    "                              outputfile=\"learning resource/\" + generated_directory + \"/skill learning resource.docx\")\n",
    "        return remarks, skill_dict\n",
    "\n",
    "    def SkillLearningResourceFilter(self, key, text, remarks):\n",
    "        text = text.lower()\n",
    "        text = text.replace(\"/\", \" \")\n",
    "        if text.find('(') != -1:\n",
    "            text = text.split(\"(\")[0]\n",
    "            text = text.rsplit()[0]\n",
    "        if text in self.ignore_set:\n",
    "            if len(remarks) != 0:\n",
    "                remarks += \"\\n\"\n",
    "            remarks += key\n",
    "            remarks += \" not found\"\n",
    "            return remarks, str(\"\")\n",
    "        if text in self.exact_match_replace_dict_list:\n",
    "            text = self.exact_match_replace_dict_list.get(text)\n",
    "        words = text.split()\n",
    "        new_text = \"\"\n",
    "        for word in words:\n",
    "            if word in self.partial_match_replace_dict_list:\n",
    "                new_text += self.partial_match_replace_dict_list.get(word)\n",
    "                new_text += \" \"\n",
    "            else:\n",
    "                new_text += word\n",
    "                new_text += \" \"\n",
    "        new_text = new_text[:-1]\n",
    "        lower_key = key.lower()\n",
    "        if lower_key != new_text:\n",
    "            if len(remarks) != 0:\n",
    "                remarks += \"\\n\"\n",
    "            remarks += key\n",
    "            remarks += \" also known as \"\n",
    "            remarks += new_text.title()\n",
    "        return remarks, new_text\n",
    "\n",
    "    def SkillLearningResourceSearch(self, key, text, document_prepare_set, remarks):\n",
    "        if text in self.skill_dict_list:\n",
    "            document_prepare_set.add(text)\n",
    "            return remarks, document_prepare_set\n",
    "\n",
    "        if text in self.group_dict_list:\n",
    "            document_prepare_set.add(text)\n",
    "            return remarks, document_prepare_set\n",
    "\n",
    "        # check for . - space and .js\n",
    "        for sdl in self.skill_dict_list:\n",
    "\n",
    "            check1 = sdl\n",
    "            if check1.endswith('s'):\n",
    "                check1 = check1[:-1]\n",
    "            check2 = text\n",
    "            if check2.endswith('s'):\n",
    "                check2 = check2[:-1]\n",
    "            if check1 == check2:\n",
    "                document_prepare_set.add(sdl)\n",
    "                return remarks, document_prepare_set\n",
    "            check1 = sdl\n",
    "            check1 = check1.replace(\".\", \"\")\n",
    "            check2 = text\n",
    "            check2 = check2.replace(\".\", \"\")\n",
    "            if check1 == check2:\n",
    "                document_prepare_set.add(sdl)\n",
    "                return remarks, document_prepare_set\n",
    "            check1 = sdl\n",
    "            check1 = check1.replace(\"-\", \" \")\n",
    "            check2 = text\n",
    "            check2 = check2.replace(\"-\", \" \")\n",
    "            if check1 == check2:\n",
    "                document_prepare_set.add(sdl)\n",
    "                return remarks, document_prepare_set\n",
    "            check1 = sdl\n",
    "            check1 = check1.replace(\" \", \"\")\n",
    "            check2 = text\n",
    "            check2 = check2.replace(\" \", \"\")\n",
    "            if check1 == check2:\n",
    "                document_prepare_set.add(sdl)\n",
    "                return remarks, document_prepare_set\n",
    "            check1 = sdl\n",
    "            check1 = check1.replace(\".js\", \"\")\n",
    "            check1 = check1.replace(\"js\", \"\")\n",
    "            check2 = text\n",
    "            check2 = check2.replace(\".js\", \"\")\n",
    "            check2 = check2.replace(\"js\", \"\")\n",
    "            if check1 == check2:\n",
    "                document_prepare_set.add(sdl)\n",
    "                return remarks, document_prepare_set\n",
    "\n",
    "        found = False\n",
    "        words = text.split()\n",
    "        # check word by word\n",
    "        for word in words:\n",
    "            if word in self.skill_dict_list:\n",
    "                document_prepare_set.add(word)\n",
    "                if len(remarks) != 0:\n",
    "                    remarks += \"\\n\"\n",
    "                remarks += key\n",
    "                remarks += \" also known as \"\n",
    "                remarks += word.title()\n",
    "                found = True\n",
    "            elif word in self.group_dict_list:\n",
    "                document_prepare_set.add(word)\n",
    "                if len(remarks) != 0:\n",
    "                    remarks += \"\\n\"\n",
    "                remarks += key\n",
    "                remarks += \" also known as \"\n",
    "                remarks += word.title()\n",
    "                found = True\n",
    "\n",
    "        if not found:\n",
    "            if len(remarks) != 0:\n",
    "                remarks += \"\\n\"\n",
    "            remarks += key\n",
    "            remarks += \" not found\"\n",
    "        return remarks, document_prepare_set\n",
    "\n",
    "    def AddSkillDictList(self, name, keyword, groups=None):\n",
    "        if name not in self.skill_dict_list:\n",
    "            self.skill_dict_list[name] = Skill(name, keyword, groups)\n",
    "            # print(name,\"added in skill_dict_list.\")\n",
    "            if groups is not None:\n",
    "                for g in groups:\n",
    "                    if g in self.group_dict_list:\n",
    "                        self.group_dict_list.get(g).UpdateSkillSet({name})\n",
    "                        # print(name,\"added in\",g,\".\")\n",
    "                    else:\n",
    "                        self.group_dict_list[g] = Group(g, {name})\n",
    "                        # print(\"new group:\",g,\"have been created and added\",name,\".\")\n",
    "        else:\n",
    "            self.UpdateSkillDictList(name, groups)\n",
    "\n",
    "    def ReClassificationSkillDictList(self, name, keyword, groups):\n",
    "        search_keyword = keyword\n",
    "        if name in self.backup_keyword_dict_list:\n",
    "            search_keyword = self.backup_keyword_dict_list[name]\n",
    "        self.AddSkillDictList(name, search_keyword, groups)\n",
    "\n",
    "    def UpdateSkillDictList(self, name, groups):\n",
    "        if name in self.skill_dict_list:\n",
    "            self.skill_dict_list[name].UpdateGroupSet(groups)\n",
    "\n",
    "    def AddGroupDictList(self, name, skills):\n",
    "        if skills is not None:\n",
    "            if name in self.group_dict_list:\n",
    "                self.UpdateGroupDictList(name, skills)\n",
    "            else:\n",
    "                found_set = set()\n",
    "                for s in skills:\n",
    "                    if s in self.skill_dict_list:\n",
    "                        self.skill_dict_list[s].UpdateGroupSet({name})\n",
    "                        found_set.add(s)\n",
    "                        # print(s,\"added in\",name,\"group set.\")\n",
    "                self.group_dict_list[name] = Group(name, found_set)\n",
    "\n",
    "    def UpdateGroupDictList(self, name, skills):\n",
    "        if name in self.group_dict_list:\n",
    "            found_set = set()\n",
    "            for s in skills:\n",
    "                if s in self.skill_dict_list:\n",
    "                    found_set.add(s)\n",
    "            self.group_dict_list[name].UpdateSkillSet(found_set)\n",
    "        else:\n",
    "            self.AddGroupDictList(name, skills)\n",
    "\n",
    "    def AddNotFoundDictList(self, name, keyword):\n",
    "        if name not in self.not_found_dict_list:\n",
    "            path = \"unclassified\"\n",
    "            self.not_found_dict_list[name] = Skill(name, path, keyword)\n",
    "\n",
    "    def ImportIgnoreSet(self):\n",
    "        f = open(\"ignore.txt\", \"r\")\n",
    "        for c in f:\n",
    "            c = c.replace(\"\\n\", \"\")\n",
    "            self.ignore_set.add(c)\n",
    "        f.close()\n",
    "\n",
    "    def ImportClassificationSet(self):\n",
    "        file = open(\"three word skill classification.txt\", \"r\")\n",
    "        for word in file:\n",
    "            word = word.replace(\"\\n\", \"\")\n",
    "            self.three_word_skill_classification_set.add(word)\n",
    "        file.close()\n",
    "        file = open(\"two word skill classification.txt\", \"r\")\n",
    "        for word in file:\n",
    "            word = word.replace(\"\\n\", \"\")\n",
    "            self.two_word_skill_classification_set.add(word)\n",
    "        file.close()\n",
    "        file = open(\"one word skill classification.txt\", \"r\")\n",
    "        for word in file:\n",
    "            word = word.replace(\"\\n\", \"\")\n",
    "            self.one_word_skill_classification_set.add(word)\n",
    "        file.close()\n",
    "\n",
    "    def ExportSkillDictList(self):\n",
    "        file_path = \"skills.csv\"\n",
    "        with open(file_path, 'w', newline='') as file:\n",
    "            writer = csv.writer(file)\n",
    "            writer.writerow([\"Name\", \"Search Keyword\", \"Resource Path\", \"Groups\"])\n",
    "            for key, value in self.skill_dict_list.items():\n",
    "                name = key\n",
    "                search = value.keyword_search\n",
    "                path = value.resource_path\n",
    "                groups = \"\"\n",
    "\n",
    "                for g in value.group_set:\n",
    "                    groups += \"[\"\n",
    "                    groups += g\n",
    "                    groups += \"]\"\n",
    "\n",
    "                writer.writerow([name, search, path, groups])\n",
    "            file.close()\n",
    "        with open('skills.txt', 'w') as f:\n",
    "            for i in self.skill_dict_list:\n",
    "                f.write(i)\n",
    "                f.write(\"\\n\")\n",
    "            f.close()\n",
    "\n",
    "    def ImportSkillDictList(self):\n",
    "        df = pd.read_csv(\"skills.csv\")\n",
    "        for index, row in df.iterrows():\n",
    "            name = str(row['Name'])\n",
    "            keyword = str(row['Search Keyword'])\n",
    "            groups = str(row['Groups'])\n",
    "            groups_set = None\n",
    "            groups = groups.replace('[', '')\n",
    "            groups_list = groups.split(']')\n",
    "            if len(groups_list) > 0:\n",
    "                groups_list = groups_list[:-1]\n",
    "                groups_set = set()\n",
    "                for g in groups_list:\n",
    "                    groups_set.add(g)\n",
    "            # auto create group also\n",
    "            self.AddSkillDictList(name, keyword, groups_set)\n",
    "\n",
    "    def ExportGroupDictList(self):\n",
    "        file_path = \"groups.csv\"\n",
    "        with open(file_path, 'w', newline='') as file:\n",
    "            writer = csv.writer(file)\n",
    "            writer.writerow([\"Name\", \"Search Keyword\", \"Resource Path\", \"skills\"])\n",
    "            for key, value in self.group_dict_list.items():\n",
    "                name = key\n",
    "                search = value.keyword_search\n",
    "                path = value.resource_path\n",
    "                skills = \"\"\n",
    "                for s in value.skill_set:\n",
    "                    skills += \"[\"\n",
    "                    skills += s\n",
    "                    skills += \"]\"\n",
    "                writer.writerow([name, search, path, skills])\n",
    "            file.close()\n",
    "\n",
    "    def ExportMatchReplaceDictList(self):\n",
    "        file_path = \"exact match.csv\"\n",
    "        with open(file_path, 'w', newline='') as file:\n",
    "            writer = csv.writer(file)\n",
    "            writer.writerow([\"Word\", \"Replace\"])\n",
    "            for key, value in self.exact_match_replace_dict_list.items():\n",
    "                writer.writerow([key, value])\n",
    "            file.close()\n",
    "        file_path = \"partial match.csv\"\n",
    "        with open(file_path, 'w', newline='') as file:\n",
    "            writer = csv.writer(file)\n",
    "            writer.writerow([\"Word\", \"Replace\"])\n",
    "            for key, value in self.partial_match_replace_dict_list.items():\n",
    "                writer.writerow([key, value])\n",
    "            file.close()\n",
    "\n",
    "    def ExportNotFoundSet(self):\n",
    "        file_path = \"not found.csv\"\n",
    "        with open(file_path, 'w', newline='') as file:\n",
    "            writer = csv.writer(file)\n",
    "            writer.writerow([\"Name\", \"Search Keyword\", \"Resource Path\"])\n",
    "            for key, value in self.not_found_dict_list.items():\n",
    "                name = key\n",
    "                search = value.keyword_search\n",
    "                path = \"skill unclassified/not tech/\" + name + \".html\"\n",
    "\n",
    "                writer.writerow([name, search, path])\n",
    "            file.close()\n",
    "\n",
    "    def GroupTextVectorization(self):\n",
    "        for word in self.group_dict_list:\n",
    "            if self.nlp.vocab[word].has_vector:\n",
    "                vector_word = self.nlp(word)\n",
    "                if vector_word not in self.vector_group_dict_list:\n",
    "                    self.vector_group_dict_list[vector_word] = set()\n",
    "                self.vector_group_dict_list[vector_word].add(word)\n",
    "\n",
    "    def VectorSearch(self, word):\n",
    "        if self.nlp.vocab[word].has_vector:\n",
    "            vector_word = self.nlp(word)\n",
    "            for vw in self.vector_group_dict_list:\n",
    "                similarity_score = vector_word.similarity(vw)\n",
    "                if similarity_score >= 0.9:\n",
    "                    for w in self.vector_group_dict_list[vw]:\n",
    "                        print(w)\n",
    "\n",
    "    def CopyReplaceFolder(self, source_dir, dest_dir, filename):\n",
    "        if dest_dir == \"unknown\":\n",
    "            keyword = filename + \" in tech\"\n",
    "        else:\n",
    "            keyword = filename\n",
    "        self.ReClassificationSkillDictList(filename, keyword, {dest_dir})\n",
    "        dest_dir = \"skill classified/\" + dest_dir\n",
    "        if not os.path.exists(dest_dir):\n",
    "            os.makedirs(dest_dir)\n",
    "        source_path_doc = source_dir + \"/\" + filename + \".docx\"\n",
    "        source_path_html = source_dir + \"/\" + filename + \".html\"\n",
    "        destination_path_doc = dest_dir + \"/\" + filename + \".docx\"\n",
    "        destination_path_html = dest_dir + \"/\" + filename + \".html\"\n",
    "        if source_path_doc != destination_path_doc:\n",
    "            shutil.copyfile(source_path_doc, destination_path_doc)\n",
    "        if source_path_html != destination_path_html:\n",
    "            shutil.copyfile(source_path_html, destination_path_html)\n",
    "\n",
    "    @staticmethod\n",
    "    def MakeDocsFromHtml():\n",
    "        directory = 'skill unclassified/not tech/'\n",
    "        filenames = [f for f in listdir(directory) if isfile(join(directory, f))]\n",
    "        for f in filenames:\n",
    "            print(f)\n",
    "            words = f.rsplit(\".\")\n",
    "            extension = words[len(words) - 1]\n",
    "            if extension == \"html\":\n",
    "                filename = f.replace(\".html\", \"\")\n",
    "                pypandoc.convert_file(directory + \"/\" + f, 'docx', outputfile=directory + \"/\" + filename + \".docx\")\n",
    "\n",
    "    def DeleteAllSkillFile(self):\n",
    "        for directory in self.three_word_skill_classification_set:\n",
    "            path = \"skill classified/\" + directory\n",
    "            if os.path.isdir(path):\n",
    "                for filename in os.listdir(path):\n",
    "                    file_path = os.path.join(path, filename)\n",
    "                    try:\n",
    "                        if os.path.isfile(file_path) or os.path.islink(file_path):\n",
    "                            os.unlink(file_path)\n",
    "                        elif os.path.isdir(file_path):\n",
    "                            shutil.rmtree(file_path)\n",
    "                    except Exception as e:\n",
    "                        print(f'Failed to delete {file_path}. Reason: {e}')\n",
    "        for directory in self.two_word_skill_classification_set:\n",
    "            path = \"skill classified/\" + directory\n",
    "            if os.path.isdir(directory):\n",
    "                for filename in os.listdir(path):\n",
    "                    file_path = os.path.join(path, filename)\n",
    "                    try:\n",
    "                        if os.path.isfile(file_path) or os.path.islink(file_path):\n",
    "                            os.unlink(file_path)\n",
    "                        elif os.path.isdir(file_path):\n",
    "                            shutil.rmtree(file_path)\n",
    "                    except Exception as e:\n",
    "                        print(f'Failed to delete {file_path}. Reason: {e}')\n",
    "        for directory in self.one_word_skill_classification_set:\n",
    "            path = \"skill classified/\" + directory\n",
    "            if os.path.isdir(path):\n",
    "                for filename in os.listdir(path):\n",
    "                    file_path = os.path.join(path, filename)\n",
    "                    try:\n",
    "                        if os.path.isfile(file_path) or os.path.islink(file_path):\n",
    "                            os.unlink(file_path)\n",
    "                        elif os.path.isdir(file_path):\n",
    "                            shutil.rmtree(file_path)\n",
    "                    except Exception as e:\n",
    "                        print(f'Failed to delete {file_path}. Reason: {e}')\n",
    "        source_dir = 'skill'\n",
    "        destination_dir = 'skill classified/unknown'\n",
    "        os.makedirs(destination_dir, exist_ok=True)\n",
    "\n",
    "        for file_name in os.listdir(source_dir):\n",
    "            source_file = os.path.join(source_dir, file_name)\n",
    "            destination_file = os.path.join(destination_dir, file_name)\n",
    "            shutil.copy(source_file, destination_file)\n",
    "\n",
    "    @staticmethod\n",
    "    def FilterHtmlContent(text_content):\n",
    "        text_content = text_content.lower()\n",
    "        text_content = text_content.replace(\"[1]\", \"\")\n",
    "        text_content = text_content.replace(\"[2]\", \"\")\n",
    "        text_content = text_content.replace(\"[3]\", \"\")\n",
    "        text_content = text_content.replace(\"[4]\", \"\")\n",
    "        text_content = text_content.replace(\"[5]\", \"\")\n",
    "        text_content = text_content.replace(\"[6]\", \"\")\n",
    "        text_content = text_content.replace(\"[7]\", \"\")\n",
    "        text_content = text_content.replace(\"[8]\", \"\")\n",
    "        text_content = text_content.replace(\"[9]\", \"\")\n",
    "        text_content = text_content.replace(\"[0]\", \"\")\n",
    "        text_content = text_content.replace(\"[\", \"\")\n",
    "        text_content = text_content.replace(\"]\", \"\")\n",
    "        text_content = text_content.replace(\"(\", \"\")\n",
    "        text_content = text_content.replace(\")\", \"\")\n",
    "        text_content = text_content.replace(\"*\", \"\")\n",
    "        text_content = text_content.replace(\"\\\"\", \"\")\n",
    "        text_content = text_content.replace(\"â€™s\", \"\")\n",
    "        text_content = text_content.replace(\"!\", \"\")\n",
    "        text_content = text_content.replace(\":\", \"\")\n",
    "        text_content = text_content.replace(\",\", \"\")\n",
    "        text_content = text_content.replace(\"\\n\", \" \")\n",
    "        text_content = text_content.replace(\"/\", \" \")\n",
    "        text_content = text_content.replace(\"-\", \" \")\n",
    "        return text_content\n",
    "\n",
    "    def SkillReClassification(self):\n",
    "        self.backup_keyword_dict_list.clear()\n",
    "        for s in self.skill_dict_list:\n",
    "            self.backup_keyword_dict_list[s] = self.skill_dict_list[s].keyword_search\n",
    "\n",
    "        self.skill_dict_list.clear()\n",
    "        self.group_dict_list.clear()\n",
    "        self.vector_group_dict_list.clear()\n",
    "        self.DeleteAllSkillFile()\n",
    "        h = html2text.HTML2Text()\n",
    "        h.ignore_links = False\n",
    "        h.inline_links = False\n",
    "        h.reference_links = True\n",
    "        directory = 'skill classified/unknown'\n",
    "        filenames = [f for f in listdir(directory) if isfile(join(directory, f))]\n",
    "\n",
    "        for f in filenames:\n",
    "            words = f.rsplit(\".\")\n",
    "            extension = words[len(words) - 1]\n",
    "            if extension == \"html\":\n",
    "                filename = f.replace(\".html\", \"\")\n",
    "                with open(directory + \"/\" + f, 'r', encoding=\"utf-8\") as file:\n",
    "                    html_content = file.read()\n",
    "                    file.close()\n",
    "                text_content = self.FilterHtmlContent(h.handle(html_content))\n",
    "                words = text_content.split()\n",
    "                have_classified = False\n",
    "                for i in range(len(words)):\n",
    "                    first_word = words[i]\n",
    "                    if first_word.endswith('.'):\n",
    "                        first_word = first_word[:-1]\n",
    "\n",
    "                    one_word = first_word\n",
    "                    one_word = one_word.replace(\"microservices\", \"microservice\")\n",
    "                    one_word = one_word.replace(\"protocols\", \"protocol\")\n",
    "                    one_word = one_word.replace(\"networks\", \"network\")\n",
    "                    one_word = one_word.replace(\"website\", \"web\")\n",
    "                    one_word = one_word.replace(\"test\", \"testing\")\n",
    "                    one_word = one_word.replace(\"visualizations\", \"visualization\")\n",
    "                    one_word = one_word.replace(\"aws\", \"amazon\")\n",
    "\n",
    "                    if one_word in self.one_word_skill_classification_set:\n",
    "                        self.CopyReplaceFolder(directory, one_word, filename)\n",
    "                        have_classified = True\n",
    "\n",
    "                    if one_word == \"ai\":\n",
    "                        one_word = \"artificial intelligence\"\n",
    "                        if one_word in self.two_word_skill_classification_set:\n",
    "                            self.CopyReplaceFolder(directory, one_word, filename)\n",
    "                            have_classified = True\n",
    "                    if one_word == \"api\":\n",
    "                        one_word = \"application programming interface\"\n",
    "                        if one_word in self.three_word_skill_classification_set:\n",
    "                            self.CopyReplaceFolder(directory, one_word, filename)\n",
    "                            have_classified = True\n",
    "                    if one_word == \"nlp\":\n",
    "                        one_word = \"natural language processing\"\n",
    "                        if one_word in self.three_word_skill_classification_set:\n",
    "                            self.CopyReplaceFolder(directory, one_word, filename)\n",
    "                            have_classified = True\n",
    "\n",
    "                    if i + 1 >= len(words):\n",
    "                        break\n",
    "                    second_word = words[i + 1]\n",
    "                    if second_word.endswith('.'):\n",
    "                        second_word = second_word[:-1]\n",
    "\n",
    "                    two_word = first_word + \" \" + second_word\n",
    "                    two_word = two_word.replace(\" servers\", \" server\")\n",
    "                    two_word = two_word.replace(\" services\", \" service\")\n",
    "                    two_word = two_word.replace(\" applications\", \" application\")\n",
    "                    two_word = two_word.replace(\" apps\", \" application\")\n",
    "                    two_word = two_word.replace(\" app\", \" application\")\n",
    "                    two_word = two_word.replace(\" databases\", \" database\")\n",
    "                    two_word = two_word.replace(\" machines\", \" machine\")\n",
    "                    two_word = two_word.replace(\"website\", \"web\")\n",
    "\n",
    "                    if two_word in self.two_word_skill_classification_set:\n",
    "                        self.CopyReplaceFolder(directory, two_word, filename)\n",
    "                        have_classified = True\n",
    "\n",
    "                    if i + 2 >= len(words):\n",
    "                        break\n",
    "                    third_word = words[i + 2]\n",
    "                    if third_word.endswith('.'):\n",
    "                        third_word = third_word[:-1]\n",
    "                    three_word = first_word + \" \" + second_word + \" \" + third_word\n",
    "                    if three_word in self.three_word_skill_classification_set:\n",
    "                        self.CopyReplaceFolder(directory, three_word, filename)\n",
    "                        have_classified = True\n",
    "\n",
    "                if have_classified:\n",
    "                    file_path = directory + \"/\" + filename + \".html\"\n",
    "                    if os.path.isfile(file_path):\n",
    "                        os.remove(file_path)\n",
    "                    else:\n",
    "                        print(f\"The file {file_path} does not exist.\")\n",
    "                    file_path = directory + \"/\" + filename + \".docx\"\n",
    "                    if os.path.isfile(file_path):\n",
    "                        os.remove(file_path)\n",
    "                    else:\n",
    "                        print(f\"The file {file_path} does not exist.\")\n",
    "                else:\n",
    "                    self.ReClassificationSkillDictList(filename, filename + \" in tech\", {\"unknown\"})\n",
    "\n",
    "        self.GroupTextVectorization()\n",
    "        self.ExportSkillDictList()\n",
    "        self.ExportGroupDictList()\n",
    "\n",
    "    def ClassificationUnClassifiedSkill(self):\n",
    "        h = html2text.HTML2Text()\n",
    "        h.ignore_links = False\n",
    "        h.inline_links = False\n",
    "        h.reference_links = True\n",
    "        directory = 'skill unclassified/not tech'\n",
    "        filenames = [f for f in listdir(directory) if isfile(join(directory, f))]\n",
    "        ignore_word_list = [\"a\", \"an\", \"the\", \"of\", \"on\", \"as\", \"by\", \"to\", \"with\", \"for\", \"is\", \"are\", \"was\", \"were\",\n",
    "                            \"in\"]\n",
    "        tech_word_list = [\"software\", \"application\", \"applications\", \"platform\", \"platforms\", \"api\", \"web\", \"website\",\n",
    "                          \"network\", \"networks\", \"security\", \"architecture\", \"development\", \"system\", \"systems\",\n",
    "                          \"language\", \"cloud\", \"data\", \"open\", \"source\", \"windows\"]\n",
    "        for f in filenames:\n",
    "            words = f.rsplit(\".\")\n",
    "            extension = words[len(words) - 1]\n",
    "            if extension == \"html\":\n",
    "                with open(directory + \"/\" + f, 'r', encoding=\"utf-8\") as file:\n",
    "                    html_content = file.read()\n",
    "                    file.close()\n",
    "                text_content = self.FilterHtmlContent(h.handle(html_content))\n",
    "                words = text_content.split()\n",
    "                is_tech = False\n",
    "                for i in range(len(words)):\n",
    "                    if words[i] in tech_word_list:\n",
    "                        is_tech = True\n",
    "                        break\n",
    "                if is_tech:\n",
    "                    source_file = os.path.join(\"skill unclassified/not tech\", f)\n",
    "                    destination_file = os.path.join(\"skill unclassified/tech\", f)\n",
    "                    shutil.copy(source_file, destination_file)\n",
    "\n",
    "    def FindClassificationKeyword(self):\n",
    "        h = html2text.HTML2Text()\n",
    "        h.ignore_links = False\n",
    "        h.inline_links = False\n",
    "        h.reference_links = True\n",
    "        directory = 'skill classified/unknown'\n",
    "        filenames = [f for f in listdir(directory) if isfile(join(directory, f))]\n",
    "        one_word_dict_list = {}\n",
    "        two_word_dict_list = {}\n",
    "        three_word_dict_list = {}\n",
    "        ignore_word_list = [\"a\", \"an\", \"the\", \"of\", \"on\", \"as\", \"by\", \"to\", \"with\", \"for\", \"is\", \"are\", \"was\", \"were\",\n",
    "                            \"in\"]\n",
    "        for f in filenames:\n",
    "            words = f.rsplit(\".\")\n",
    "            extension = words[len(words) - 1]\n",
    "            if extension == \"html\":\n",
    "                with open(directory + \"/\" + f, 'r', encoding=\"utf-8\") as file:\n",
    "                    html_content = file.read()\n",
    "                    file.close()\n",
    "                text_content = self.FilterHtmlContent(h.handle(html_content))\n",
    "                words = text_content.split()\n",
    "                for i in range(len(words)):\n",
    "                    first_word = words[i]\n",
    "                    if '1.' in first_word:\n",
    "                        break\n",
    "                    if first_word.endswith('.'):\n",
    "                        first_word = first_word[:-1]\n",
    "                    if first_word in ignore_word_list:\n",
    "                        continue\n",
    "                    one_word = first_word\n",
    "                    if one_word not in one_word_dict_list:\n",
    "                        one_word_dict_list[one_word] = 0\n",
    "                    one_word_dict_list[one_word] += 1\n",
    "\n",
    "                    second_word = words[i + 1]\n",
    "                    if second_word.endswith('.'):\n",
    "                        second_word = second_word[:-1]\n",
    "                    if second_word in ignore_word_list:\n",
    "                        continue\n",
    "                    two_word = first_word + \" \" + second_word\n",
    "                    if two_word not in two_word_dict_list:\n",
    "                        two_word_dict_list[two_word] = 0\n",
    "                    two_word_dict_list[two_word] += 1\n",
    "\n",
    "                    third_word = words[i + 2]\n",
    "                    if third_word.endswith('.'):\n",
    "                        third_word = third_word[:-1]\n",
    "                    if third_word in ignore_word_list:\n",
    "                        continue\n",
    "                    three_word = first_word + \" \" + second_word + \" \" + third_word\n",
    "                    if three_word not in three_word_dict_list:\n",
    "                        three_word_dict_list[three_word] = 0\n",
    "                    three_word_dict_list[three_word] += 1\n",
    "        with open('count one word.txt', 'w', encoding=\"utf-8\") as f:\n",
    "            for s in sorted(one_word_dict_list, key=one_word_dict_list.get, reverse=True):\n",
    "                f.write(str(s) + \" - \" + str(one_word_dict_list[s]))\n",
    "                f.write('\\n')\n",
    "            file.close()\n",
    "        with open('count two word.txt', 'w', encoding=\"utf-8\") as f:\n",
    "            for s in sorted(two_word_dict_list, key=two_word_dict_list.get, reverse=True):\n",
    "                f.write(str(s) + \" - \" + str(two_word_dict_list[s]))\n",
    "                f.write('\\n')\n",
    "            file.close()\n",
    "        with open('count three word.txt', 'w', encoding=\"utf-8\") as f:\n",
    "            for s in sorted(three_word_dict_list, key=three_word_dict_list.get, reverse=True):\n",
    "                f.write(str(s) + \" - \" + str(three_word_dict_list[s]))\n",
    "                f.write('\\n')\n",
    "            file.close()\n",
    "\n",
    "    def InitLeetCodeCompanyNameDictList(self):\n",
    "        f = open(\"leetcode/companies.txt\", \"r\")\n",
    "\n",
    "        for c in f:\n",
    "            c = c.replace(\"\\n\", \"\")\n",
    "            key = c\n",
    "            key = key.lower()\n",
    "            self.leetcode_company_dict_list[key] = c\n",
    "        f.close()\n",
    "\n",
    "    def InitLeetcodeOverallFrequencyDictList(self):\n",
    "        df = pd.read_csv(\"leetcode/Question List.csv\")\n",
    "        for index, row in df.iterrows():\n",
    "            self.leetcode_overall_frequency_dict_list[str(row[\"No\"])] = str(row[\"Frequency\"])\n",
    "\n",
    "    def AllThisWillBeRemoveOnceFinalize(self):\n",
    "\n",
    "        self.exact_match_replace_dict_list[\"aws\"] = \"amazon web services\"\n",
    "        self.exact_match_replace_dict_list[\"tdd\"] = \"testing\"\n",
    "        self.exact_match_replace_dict_list[\"webdriver\"] = \"web crawler\"\n",
    "        self.exact_match_replace_dict_list[\"vbnet\"] = \"visual basic .net\"\n",
    "        self.exact_match_replace_dict_list[\"vb.net\"] = \"visual basic .net\"\n",
    "        self.exact_match_replace_dict_list[\"vb\"] = \"visual basic\"\n",
    "        self.exact_match_replace_dict_list[\"html5\"] = \"html\"\n",
    "        self.exact_match_replace_dict_list[\"svn\"] = \"subversion\"\n",
    "        self.exact_match_replace_dict_list[\"rdbms\"] = \"relational\"\n",
    "        self.exact_match_replace_dict_list[\"unity3d\"] = \"unity\"\n",
    "        self.exact_match_replace_dict_list[\"mssql\"] = \"microsoft sql\"\n",
    "        self.exact_match_replace_dict_list[\"shaders\"] = \"shader\"\n",
    "        self.exact_match_replace_dict_list[\"uat\"] = \"testing\"\n",
    "        self.exact_match_replace_dict_list[\"mui\"] = \"material ui\"\n",
    "        self.exact_match_replace_dict_list[\"gui\"] = \"graphical user interface\"\n",
    "        self.exact_match_replace_dict_list[\"ui\"] = \"user interface\"\n",
    "        self.exact_match_replace_dict_list[\"mq\"] = \"message queue\"\n",
    "        self.exact_match_replace_dict_list[\"aliyun\"] = \"alibaba cloud\"\n",
    "        self.exact_match_replace_dict_list[\"ali-cloud\"] = \"alibaba cloud\"\n",
    "\n",
    "        self.partial_match_replace_dict_list[\"ms\"] = \"microsoft\"\n",
    "        self.partial_match_replace_dict_list[\"vm\"] = \"virtual machine\"\n",
    "        self.partial_match_replace_dict_list[\"website\"] = \"web\"\n",
    "        self.partial_match_replace_dict_list[\"test\"] = \"testing\"\n",
    "        self.partial_match_replace_dict_list[\"networking\"] = \"network\"\n",
    "\n",
    "        self.ExportMatchReplaceDictList()\n",
    "\n",
    "app = Flask(__name__)\n",
    "learning_resource = TechStack()\n",
    "\n",
    "\n",
    "@app.route('/')\n",
    "def hello():\n",
    "    return 'Hello, World!'\n",
    "\n",
    "@app.route('/generate_learning_resource', methods=['GET'])\n",
    "def generate_learning_resource():\n",
    "    nodeflair = {}\n",
    "    file = open(\"nodeflair skill.txt\", \"r\")\n",
    "    for s in file:\n",
    "        s = s.replace(\"\\n\", \"\")\n",
    "        nodeflair[s] =s\n",
    "    file.close()\n",
    "    generated_directory = str(learning_resource.GetRequestQueueNo())\n",
    "    learning_resource.GenerateLearningResource(None, nodeflair, \"Google\",generated_directory)\n",
    "    learning_resource_zip_path = \"learning resource/\" + generated_directory + \"/learning resource.zip\"\n",
    "\n",
    "    \n",
    "    return send_file(learning_resource_zip_path, as_attachment=True, download_name='learning resource.zip')\n",
    "\n",
    "\n",
    "# To run the Flask app with Werkzeug's run_simple function:\n",
    "if __name__ == '__main__':\n",
    "    run_simple('localhost', 5000, app)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a4c4910-cb60-4ca0-b94f-8bf01f758b75",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7515a9f5-a5a8-4be8-ba4d-a9b8a1af7db3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
