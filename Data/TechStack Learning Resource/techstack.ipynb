{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4b9b981e-d994-41b8-81d8-8ff213a69c73",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import en_core_web_sm\n",
    "import pandas as pd\n",
    "import pypandoc\n",
    "from pypandoc.pandoc_download import download_pandoc\n",
    "#download_pandoc()\n",
    "import csv\n",
    "import docx\n",
    "import os\n",
    "from pathlib import Path\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import shutil\n",
    "import html2text\n",
    "\n",
    "class Skill:\n",
    "    def __init__(self,name, keyword , groups=None,prerequisites= None):\n",
    "        filename = name\n",
    "        filename = filename.replace('/','-')\n",
    "        filename = filename.replace(\"\\\\\",'-')\n",
    "        filename = filename + \".html\"\n",
    "        path = os.path.join(\"skill\", filename)\n",
    "        path = path.replace(\"\\\\\",'/')\n",
    "        self.resource_path = path # for the resource path\n",
    "        self.keyword_search = keyword  # keyword for searching LLM\n",
    "        self.group_set = set()\n",
    "        if groups is not None:    \n",
    "            self.UpdateGroupSet(groups)\n",
    "        \n",
    "    def UpdateGroupSet(self,groups):\n",
    "        self.group_set.update(groups)\n",
    "        #print(\"skill group set updated.\")\n",
    "\n",
    "    def ChangeKeyword(self,keyword):\n",
    "        self.keyword_search = keyword\n",
    "  \n",
    "class Group:\n",
    "    def __init__(self,name,skills):\n",
    "        filename = name\n",
    "        filename = filename.replace('/','-')\n",
    "        filename = filename.replace(\"\\\\\",'-')\n",
    "        filename = filename + \".html\"\n",
    "        path = os.path.join(\"group\", filename)\n",
    "        path = path.replace(\"\\\\\",'/')\n",
    "        self.resource_path = path # for the resource path\n",
    "        self.keyword_search = name + \" in tech\" # keyword for searching LLM\n",
    "        self.skill_set = skills\n",
    "\n",
    "    def UpdateSkillSet(self,skill):\n",
    "        self.skill_set.update(skill)\n",
    "        #print(\"group skill set updated.\")\n",
    "\n",
    "    def ChangeKeyword(self,keyword):\n",
    "        self.keyword_search = keyword\n",
    "\n",
    "class TechStack:\n",
    "    def __init__(self):\n",
    "        self.nlp = spacy.load('en_core_web_md')\n",
    "        self.skill_dict_list = {}\n",
    "        self.group_dict_list = {}\n",
    "        self.exact_match_replace_dict_list = {}\n",
    "        self.partial_match_replace_dict_list = {}\n",
    "        self.vector_group_dict_list = {}\n",
    "        self.ignore_set = set()\n",
    "        self.not_found_dict_list = {}\n",
    "        self.document_pepare_set = set()\n",
    "        self.three_word_skill_classification_set =set()\n",
    "        self.two_word_skill_classification_set =set()\n",
    "        self.one_word_skill_classification_set =set()\n",
    "        self.backup_keyword_dict_list={}\n",
    "        self.leetcode_list = [\"c++\",\"c\",\"c#\",\"python\",\"java\",\"javascript\",\"typescript\",\"php\",\"swift\",\"kotlin\",\"go\",\"ruby\",\"scala\",\"rust\",\"racket\"]\n",
    "        self.leetcode_company_dict_list = {}\n",
    "        self.ImportIgnoreSet()\n",
    "        self.AllThisWillBeRemoveOnceFinalize()\n",
    "        self.ImportClassificationSet()\n",
    "        self.ImportSkillDictList()\n",
    "        self.GroupTextVectorization()\n",
    "        self.InitLeetCodeCompanyNameDictList()\n",
    "\n",
    "    def GenerateLearningResource(self,your_skills, job_skills, company_name):\n",
    "        result_dict = {\"Leetcode Content\":None , \"Skill Learning Resource Content\":None ,\"Skill Learning Resource Remarks\": str(\"\") }\n",
    "        skills = set()\n",
    "        if your_skills is not None:\n",
    "            skills =  job_skills -  your_skills \n",
    "        else:\n",
    "            skills = job_skills\n",
    "        if len(skills) != 0:\n",
    "            skill_result_dict = self.GenerateSkillResource(skills)\n",
    "            result_dict[\"Skill Learning Resource Content\"] = skill_result_dict[\"Skill Learning Resource Content\"]\n",
    "            result_dict[\"Skill Learning Resource Remarks\"] = skill_result_dict[\"Skill Learning Resource Remarks\"]\n",
    "        return result_dict\n",
    "        \n",
    "    def GenerateSkillResource(self,skills):\n",
    "        result_dict = {\"Skill Learning Resource Content\":None ,\"Skill Learning Resource Remarks\" : str(\"\") }\n",
    "       \n",
    "        result_dict[\"Skill Learning Resource Remarks\"]  = self.GenerateSkillResourcePreProcessing(skills)\n",
    "        if len(self.document_pepare_set) == 0 :\n",
    "            return result_dict\n",
    "            \n",
    "        skill_dict = {}\n",
    "        html_content = \"\"\n",
    "        for d in self.document_pepare_set:\n",
    "            path = \"\"\n",
    "            if d in self.skill_dict_list:\n",
    "                v = self.skill_dict_list.get(d)\n",
    "                path = v.resource_path\n",
    "            elif d in self.skill_dict_list:\n",
    "                v = self.group_dict_list.get(d)\n",
    "                path = v.resource_path\n",
    "            else:\n",
    "                continue\n",
    "            if os.path.isfile(path) == False:\n",
    "                if len(result_dict[\"Skill Learning Resource Remarks\"]) != 0:\n",
    "                    result_dict[\"Skill Learning Resource Remarks\"] +=\", \"\n",
    "                result_dict[\"Skill Learning Resource Remarks\"] += \"there a problem generate \"\n",
    "                result_dict[\"Skill Learning Resource Remarks\"] += d.title()\n",
    "                result_dict[\"Skill Learning Resource Remarks\"] += \" learning resource\"\n",
    "            else:\n",
    "                with open(path, \"r\", encoding=\"utf-8\") as file:\n",
    "                    title = d.title()\n",
    "                    html_content +=\"<h1><u><b>\"\n",
    "                    html_content += title\n",
    "                    html_content +=\"</b></u></h1>\"\n",
    "                    file_content = file.read()\n",
    "                    html_content += file_content\n",
    "                    h = html2text.HTML2Text()\n",
    "                    h.ignore_links = False\n",
    "                    h.inline_links = False\n",
    "                    h.reference_links = True\n",
    "                    skill_dict[title] =  h.handle(file_content)\n",
    "                file.close()\n",
    "        with open(\"learning resource/skill learning resource.html\", 'w', encoding='utf-8') as file:\n",
    "            file.write(html_content)  \n",
    "            file.close()\n",
    "        output = pypandoc.convert_text(html_content, 'docx', format='html', outputfile='learning resource/skill learning resource.docx')\n",
    "        if (len(skill_dict)) != 0:\n",
    "            result_dict[\"Skill Learning Resource Content\"] = skill_dict\n",
    "        return result_dict\n",
    "\n",
    "    def GenerateSkillResourcePreProcessing(self, skills):\n",
    "        self.document_pepare_set.clear()\n",
    "        remarks = str(\"\")\n",
    "        for skill in skills:\n",
    "            s = self.Filter(skill)\n",
    "            if s == \"\":\n",
    "                if len(remarks)!= 0:\n",
    "                    remarks += \", \"\n",
    "                remarks += skill.title()\n",
    "                remarks += \" not found\"\n",
    "            else:\n",
    "                found = self.Search(s)\n",
    "                if found == False:\n",
    "                    if len(remarks)!= 0:\n",
    "                        remarks += \", \"\n",
    "                    remarks += skill.title()\n",
    "                    remarks += \" not found\"\n",
    "        return remarks\n",
    "          \n",
    "    def AddSkillDictList(self,name,keyword,groups=None):\n",
    "        if name not in self.skill_dict_list:\n",
    "            self.skill_dict_list[name] = Skill(name,keyword,groups)\n",
    "            #print(name,\"added in skill_dict_list.\")\n",
    "            if groups is not None:\n",
    "                for g in groups:\n",
    "                    if g in self.group_dict_list:\n",
    "                        self.group_dict_list.get(g).UpdateSkillSet({name})\n",
    "                        #print(name,\"added in\",g,\".\")\n",
    "                    else:\n",
    "                        self.group_dict_list[g] = Group(g,{name})\n",
    "                        #print(\"new group:\",g,\"have been created and added\",name,\".\")\n",
    "        else:\n",
    "            self.UpdateSkillDictList(name,groups)\n",
    "\n",
    "    def ReClassificationSkillDictList(self,name,keyword,groups):\n",
    "        search_keyword = keyword\n",
    "        if name in self.backup_keyword_dict_list:\n",
    "            search_keyword = self.backup_keyword_dict_list[name]\n",
    "        self.AddSkillDictList(name,search_keyword,groups)\n",
    "                    \n",
    "    def UpdateSkillDictList(self,name,groups):\n",
    "        if name in self.skill_dict_list:\n",
    "            self.skill_dict_list[name].UpdateGroupSet(groups)\n",
    "\n",
    "    def AddGroupDictList(self,name,skills):\n",
    "        if skills is not None:\n",
    "            if name in self.group_dict_list:\n",
    "                self.UpdateGroupDictList(name,skills)\n",
    "            else:\n",
    "                found_set = set()\n",
    "                for s in skills:\n",
    "                    if s in self.skill_dict_list:\n",
    "                        self.skill_dict_list[s].UpdateGroupSet({name})\n",
    "                        found_set.add(s)  \n",
    "                        #print(s,\"added in\",name,\"group set.\")\n",
    "                self.group_dict_list[name] = Group(name,found_set)\n",
    "\n",
    "    def UpdateGroupDictList(self,name,skills):\n",
    "        if name in self.group_dict_list:\n",
    "            found_set = set()\n",
    "            for s in skills:\n",
    "                if s in self.skill_dict_list:\n",
    "                      found_set.add(s)  \n",
    "            self.group_dict_list[name].UpdateSkillSet(found_set)\n",
    "        else:\n",
    "            self.AddGroupDictList(name,skills)\n",
    "\n",
    "    def AddNotFoundDictList(self,name,keyword):\n",
    "        if name not in self.not_found_dict_list:\n",
    "            path = \"unclassified\"\n",
    "            self.not_found_dict_list[name] =  Skill(name,path,keyword,None)   \n",
    "\n",
    "    def ImportIgnoreSet(self):\n",
    "        f = open(\"ignore.txt\", \"r\")\n",
    "        for c in f:\n",
    "            c = c.replace(\"\\n\", \"\")\n",
    "            self.ignore_set.add(c)\n",
    "        f.close()\n",
    "\n",
    "    def ImportClassificationSet(self):\n",
    "        f = open(\"three word skill classification.txt\", \"r\")\n",
    "        for l in f:\n",
    "            l = l.replace(\"\\n\", \"\")\n",
    "            self.three_word_skill_classification_set.add(l)\n",
    "        f.close()\n",
    "        f = open(\"two word skill classification.txt\", \"r\")\n",
    "        for l in f:\n",
    "            l = l.replace(\"\\n\", \"\")\n",
    "            self.two_word_skill_classification_set.add(l)\n",
    "        f.close()\n",
    "        f = open(\"one word skill classification.txt\", \"r\")\n",
    "        for l in f:\n",
    "            l = l.replace(\"\\n\", \"\")\n",
    "            self.one_word_skill_classification_set.add(l)\n",
    "        f.close()\n",
    "        \n",
    "    def ExportSkillDictList(self):\n",
    "        file_path = \"skills.csv\"\n",
    "        with open(file_path, 'w', newline='') as file:\n",
    "            writer = csv.writer(file)\n",
    "            writer.writerow([\"Name\", \"Search Keyword\",\"Resource Path\",\"Groups\"])\n",
    "            for key, value in self.skill_dict_list.items():\n",
    "                name=key\n",
    "                search = value.keyword_search\n",
    "                path = value.resource_path\n",
    "                groups =\"\"\n",
    "            \n",
    "                for g in value.group_set:\n",
    "                    groups += \"[\"\n",
    "                    groups += g\n",
    "                    groups +=\"]\"\n",
    "             \n",
    "                writer.writerow([name,search,path,groups])\n",
    "            file.close()\n",
    "        with open('skills.txt', 'w') as f:\n",
    "            for i in self.skill_dict_list:\n",
    "                f.write(i)\n",
    "                f.write(\"\\n\")\n",
    "            f.close()\n",
    "            \n",
    "    def ImportSkillDictList(self):\n",
    "        df = pd.read_csv(\"skills.csv\")\n",
    "        for index, row in df.iterrows():\n",
    "            name = str(row['Name'])\n",
    "            keyword = str(row['Search Keyword'])\n",
    "            groups = str(row['Groups'])\n",
    "            groups_set = None\n",
    "            groups = groups.replace('[', '')\n",
    "            groups_list = groups.split(']')\n",
    "            if len(groups_list) > 0 :\n",
    "                groups_list = groups_list[:-1]\n",
    "                groups_set = set()\n",
    "                for g in groups_list:\n",
    "                    groups_set.add(g)\n",
    "            # auto create group also\n",
    "            self.AddSkillDictList(name,keyword,groups_set)\n",
    "                \n",
    "    def ExportGroupDictList(self):\n",
    "        file_path = \"groups.csv\"\n",
    "        with open(file_path, 'w', newline='') as file:\n",
    "            writer = csv.writer(file)\n",
    "            writer.writerow([\"Name\", \"Search Keyword\",\"Resource Path\",\"skills\"])\n",
    "            for key, value in self.group_dict_list.items():\n",
    "                name=key\n",
    "                search = value.keyword_search\n",
    "                path = value.resource_path\n",
    "                skills =\"\"\n",
    "                for s in value.skill_set:\n",
    "                    skills += \"[\"\n",
    "                    skills += s\n",
    "                    skills +=\"]\"\n",
    "                writer.writerow([name,search,path,skills])\n",
    "            file.close()\n",
    "\n",
    "    def ExportMatchReplaceDictList(self):\n",
    "        file_path = \"exact match.csv\"\n",
    "        with open(file_path, 'w', newline='') as file:\n",
    "            writer = csv.writer(file)\n",
    "            writer.writerow([\"Word\", \"Replace\"])\n",
    "            for key, value in self.exact_match_replace_dict_list.items():\n",
    "                writer.writerow([key,value])\n",
    "            file.close()\n",
    "        file_path = \"partial match.csv\"\n",
    "        with open(file_path, 'w', newline='') as file:\n",
    "            writer = csv.writer(file)\n",
    "            writer.writerow([\"Word\", \"Replace\"])\n",
    "            for key, value in self.partial_match_replace_dict_list.items():\n",
    "                writer.writerow([key,value])\n",
    "            file.close()\n",
    "\n",
    "    def ExportNotFoundSet(self):\n",
    "        file_path = \"not found.csv\"\n",
    "        with open(file_path, 'w', newline='') as file:\n",
    "            writer = csv.writer(file)\n",
    "            writer.writerow([\"Name\", \"Search Keyword\",\"Resource Path\"])\n",
    "            for key, value in self.not_found_dict_list.items():\n",
    "                name=key\n",
    "                search = value.keyword_search\n",
    "                path = \"skill unclassified/not tech/\" + name + \".html\"\n",
    "             \n",
    "                writer.writerow([name,search,path])\n",
    "            file.close()\n",
    "     \n",
    "    def Filter(self, text):\n",
    "        text = text.lower()\n",
    "        text = text.replace(\"/\",\" \")\n",
    "        if text.find('(') != -1:\n",
    "            text = text.split(\"(\")[0]\n",
    "            text = text.rsplit()[0]\n",
    "            \n",
    "        words = text.split()\n",
    "    \n",
    "        if text in self.ignore_set:\n",
    "            return str(\"\")\n",
    "            \n",
    "        if text in self.exact_match_replace_dict_list:\n",
    "            text = self.exact_match_replace_dict_list.get(text)\n",
    "            \n",
    "        words = text.split()\n",
    "        new_text = \"\"\n",
    "        for word in words:\n",
    "            if word in self.partial_match_replace_dict_list:\n",
    "                new_text += self.partial_match_replace_dict_list.get(word) \n",
    "                new_text +=\" \"\n",
    "            else:\n",
    "                new_text += word \n",
    "                new_text +=\" \"\n",
    "        return new_text[:-1]\n",
    "\n",
    "    def Search(self,text):\n",
    "        if text in self.skill_dict_list:\n",
    "            self.document_pepare_set.add(text)\n",
    "            return True\n",
    "        if text in self.group_dict_list:\n",
    "            self.document_pepare_set.add(text)\n",
    "            return True\n",
    "        # check for . - space and .js js\n",
    "        for sdl in  self.skill_dict_list:\n",
    "            check1 = sdl\n",
    "            check1 = check1.replace(\".\",\"\")\n",
    "            check2 = text\n",
    "            check2 = check2.replace(\".\",\"\")\n",
    "            if check1 == check2:\n",
    "                self.document_pepare_set.add(sdl)\n",
    "                return True\n",
    "            check1 = sdl\n",
    "            check1 = check1.replace(\"-\",\" \")\n",
    "            check2 = text\n",
    "            check2 = check2.replace(\"-\",\" \")\n",
    "            if check1 == check2:\n",
    "                self.document_pepare_set.add(sdl)\n",
    "                return True\n",
    "            check1 = sdl\n",
    "            check1 = check1.replace(\" \",\"\")\n",
    "            check2 = text\n",
    "            check2 = check2.replace(\" \",\"\")\n",
    "            if check1 == check2:\n",
    "                self.document_pepare_set.add(sdl)\n",
    "                return True\n",
    "            check1 = sdl\n",
    "            check1 = check1.replace(\".js\",\"\")\n",
    "            check1 = check1.replace(\"js\",\"\")\n",
    "            check2 = text\n",
    "            check2 = check2.replace(\".js\",\"\")\n",
    "            check2 = check2.replace(\"js\",\"\")\n",
    "            if check1 == check2:\n",
    "                self.document_pepare_set.add(sdl)\n",
    "                return True\n",
    "   \n",
    "        found = False      \n",
    "        words = text.split()\n",
    "        # check word by word\n",
    "        for word in words:   \n",
    "            if word in self.skill_dict_list:\n",
    "                self.document_pepare_set.add(word)\n",
    "                found = True\n",
    "            elif word in self.group_dict_list:\n",
    "                self.document_pepare_set.add(word)\n",
    "                found = True\n",
    "        \n",
    "        return found \n",
    "        \n",
    "    def GroupTextVectorization(self):\n",
    "        for word in self.group_dict_list:\n",
    "            if self.nlp.vocab[word].has_vector == True:\n",
    "                vector_word = self.nlp(word)\n",
    "                if vector_word not in self.vector_group_dict_list:\n",
    "                    self.vector_group_dict_list[vector_word] = set()\n",
    "                self.vector_group_dict_list[vector_word].add(word)\n",
    "\n",
    "    def VectorSearch(self, word):\n",
    "        if self.nlp.vocab[word].has_vector == True:\n",
    "            vector_word = self.nlp(word)\n",
    "            for vw in self.vector_group_dict_list:\n",
    "                similarity_score = vector_word.similarity(vw)\n",
    "                if similarity_score >= 0.9:\n",
    "                    for w in vector_group_dict_list[vw]:\n",
    "                        print(w)\n",
    "\n",
    "    def CopyReplaceFolder(self, source_dir ,dest_dir , filename): \n",
    "        keyword = \"\"\n",
    "        if dest_dir == \"unknown\":\n",
    "            keyword = filename + \" in tech\"\n",
    "        else:\n",
    "            keyword = filename\n",
    "        self.ReClassificationSkillDictList(filename, keyword , {dest_dir})\n",
    "        dest_dir = \"skill classified/\" + dest_dir\n",
    "        if not os.path.exists(dest_dir):\n",
    "            os.makedirs(dest_dir)\n",
    "        source_path_doc = source_dir + \"/\" + filename + \".docx\"\n",
    "        source_path_html = source_dir + \"/\" + filename + \".html\"\n",
    "        destination_path_doc =  dest_dir + \"/\" + filename + \".docx\"\n",
    "        destination_path_html = dest_dir + \"/\" + filename + \".html\"\n",
    "        if source_path_doc != destination_path_doc:\n",
    "            shutil.copyfile(source_path_doc, destination_path_doc)\n",
    "        if source_path_html != destination_path_html:\n",
    "            shutil.copyfile(source_path_html, destination_path_html)\n",
    "\n",
    "    def MakeDocsFromHtml(self):\n",
    "        dir = 'skill unclassified/not tech/'\n",
    "        filenames = [f for f in listdir(dir) if isfile(join(dir, f))]\n",
    "        for f in filenames:\n",
    "            print(f)\n",
    "            words = f.rsplit(\".\")\n",
    "            extension = words[len(words)-1]\n",
    "            if extension ==\"html\":\n",
    "                filename = f.replace(\".html\",\"\")\n",
    "                output = pypandoc.convert_file(dir + \"/\" + f, 'docx', outputfile= dir + \"/\" + filename +\".docx\")\n",
    " \n",
    "    def DeleteAllSkillFile(self):\n",
    "        for dir in self.three_word_skill_classification_set:\n",
    "            path = \"skill classified/\" + dir\n",
    "            if os.path.isdir(path):\n",
    "                for filename in os.listdir(path):\n",
    "                    file_path = os.path.join(path, filename)\n",
    "                    try:\n",
    "                        if os.path.isfile(file_path) or os.path.islink(file_path):\n",
    "                            os.unlink(file_path)\n",
    "                        elif os.path.isdir(file_path):\n",
    "                            shutil.rmtree(file_path)\n",
    "                    except Exception as e:\n",
    "                        print(f'Failed to delete {file_path}. Reason: {e}')\n",
    "        for dir in self.two_word_skill_classification_set:\n",
    "            path = \"skill classified/\" + dir\n",
    "            if os.path.isdir(dir):\n",
    "                for filename in os.listdir(path):\n",
    "                    file_path = os.path.join(path, filename)\n",
    "                    try:\n",
    "                        if os.path.isfile(file_path) or os.path.islink(file_path):\n",
    "                            os.unlink(file_path)\n",
    "                        elif os.path.isdir(file_path):\n",
    "                            shutil.rmtree(file_path)\n",
    "                    except Exception as e:\n",
    "                        print(f'Failed to delete {file_path}. Reason: {e}')\n",
    "        for dir in self.one_word_skill_classification_set:\n",
    "            path = \"skill classified/\" + dir\n",
    "            if os.path.isdir(path):\n",
    "                for filename in os.listdir(path):\n",
    "                    file_path = os.path.join(path, filename)\n",
    "                    try:\n",
    "                        if os.path.isfile(file_path) or os.path.islink(file_path):\n",
    "                            os.unlink(file_path)\n",
    "                        elif os.path.isdir(file_path):\n",
    "                            shutil.rmtree(file_path)\n",
    "                    except Exception as e:\n",
    "                        print(f'Failed to delete {file_path}. Reason: {e}')\n",
    "        source_dir = 'skill'\n",
    "        destination_dir = 'skill classified/unknown'\n",
    "        os.makedirs(destination_dir, exist_ok=True)\n",
    "\n",
    "        for file_name in os.listdir(source_dir):\n",
    "            source_file = os.path.join(source_dir, file_name)\n",
    "            destination_file = os.path.join(destination_dir, file_name)\n",
    "            shutil.copy(source_file, destination_file)\n",
    "        \n",
    "    def SkillReClassification(self): \n",
    "        self.backup_keyword_dict_list.clear()\n",
    "        for s in self.skill_dict_list:\n",
    "            self.backup_keyword_dict_list[s] = self.skill_dict_list[s].keyword_search\n",
    "        \n",
    "        self.skill_dict_list.clear()\n",
    "        self.group_dict_list.clear()\n",
    "        self.vector_group_dict_list.clear()\n",
    "        self.DeleteAllSkillFile()\n",
    "        h = html2text.HTML2Text()\n",
    "        h.ignore_links = False\n",
    "        h.inline_links = False\n",
    "        h.reference_links = True\n",
    "        dir = 'skill classified/unknown'\n",
    "        filenames = [f for f in listdir(dir) if isfile(join(dir, f))]\n",
    "         \n",
    "        for f in filenames:\n",
    "            words = f.rsplit(\".\")\n",
    "            extension = words[len(words)-1]\n",
    "            if extension ==\"html\":\n",
    "                filename = f.replace(\".html\",\"\")\n",
    "                html_content = str(\"\")\n",
    "                with open(dir+\"/\"+ f, 'r', encoding=\"utf-8\") as file:\n",
    "                    html_content = file.read()\n",
    "                    file.close()\n",
    "                text_content = h.handle(html_content)\n",
    "                text_content = text_content.lower()\n",
    "                text_content = text_content.replace(\"[1]\",\"\")\n",
    "                text_content = text_content.replace(\"[2]\",\"\")\n",
    "                text_content = text_content.replace(\"[3]\",\"\")\n",
    "                text_content = text_content.replace(\"[4]\",\"\")\n",
    "                text_content = text_content.replace(\"[5]\",\"\")\n",
    "                text_content = text_content.replace(\"[6]\",\"\")\n",
    "                text_content = text_content.replace(\"[7]\",\"\")\n",
    "                text_content = text_content.replace(\"[8]\",\"\")\n",
    "                text_content = text_content.replace(\"[9]\",\"\")\n",
    "                text_content = text_content.replace(\"[0]\",\"\")\n",
    "                text_content = text_content.replace(\"[\",\"\")\n",
    "                text_content = text_content.replace(\"]\",\"\")\n",
    "                text_content = text_content.replace(\"(\",\"\")\n",
    "                text_content = text_content.replace(\")\",\"\")\n",
    "                text_content = text_content.replace(\"*\",\"\")\n",
    "                text_content = text_content.replace(\"\\\"\",\"\")\n",
    "                text_content = text_content.replace(\"’s\",\"\")\n",
    "                text_content = text_content.replace(\"!\",\"\")\n",
    "                text_content = text_content.replace(\":\",\"\")\n",
    "                text_content = text_content.replace(\",\",\"\")\n",
    "                text_content = text_content.replace(\"\\n\",\" \")\n",
    "                text_content = text_content.replace(\"/\",\" \")\n",
    "                text_content = text_content.replace(\"-\",\" \")\n",
    "              \n",
    "                words = text_content.split()\n",
    "                have_classific = False\n",
    "                for i in range(len(words)):\n",
    "                    first_word = words[i]\n",
    "                    if first_word.endswith('.'):\n",
    "                        first_word = first_word[:-1]\n",
    "                   \n",
    "                    one_word = first_word\n",
    "                    one_word = one_word.replace(\"microservices\",\"microservice\")\n",
    "                    one_word = one_word.replace(\"protocols\",\"protocol\")\n",
    "                    one_word = one_word.replace(\"networks\",\"network\")\n",
    "                    one_word = one_word.replace(\"website\",\"web\")\n",
    "                    one_word = one_word.replace(\"test\",\"testing\")\n",
    "                    one_word = one_word.replace(\"visualizations\",\"visualization\")\n",
    "                    one_word = one_word.replace(\"aws\",\"amazon\")\n",
    "        \n",
    "                    if one_word in self.one_word_skill_classification_set:\n",
    "                        self.CopyReplaceFolder(dir,one_word,filename)\n",
    "                        have_classific = True\n",
    "        \n",
    "                    if one_word ==\"ai\":\n",
    "                        one_word = \"artificial intelligence\"\n",
    "                        if one_word in self.two_word_skill_classification_set:\n",
    "                            self.CopyReplaceFolder(dir,one_word,filename)\n",
    "                            have_classific = True\n",
    "                    if one_word ==\"api\":\n",
    "                        one_word = \"application programming interface\"\n",
    "                        if one_word in self.three_word_skill_classification_set:\n",
    "                            self.CopyReplaceFolder(dir,one_word,filename)\n",
    "                            have_classific = True\n",
    "                    if one_word ==\"nlp\":\n",
    "                        one_word = \"natural language processing\"\n",
    "                        if one_word in self.three_word_skill_classification_set:\n",
    "                            self.CopyReplaceFolder(dir,one_word,filename)\n",
    "                            have_classific = True\n",
    "\n",
    "                    if i + 1 >= len(words):\n",
    "                        break\n",
    "                    second_word = words[i+1]\n",
    "                    if second_word.endswith('.'):\n",
    "                        second_word = second_word[:-1] \n",
    "                \n",
    "                    two_word = first_word + \" \" + second_word\n",
    "                    two_word = two_word.replace(\" servers\",\" server\")\n",
    "                    two_word = two_word.replace(\" services\",\" service\")\n",
    "                    two_word = two_word.replace(\" applications\",\" application\")\n",
    "                    two_word = two_word.replace(\" apps\",\" application\")\n",
    "                    two_word = two_word.replace(\" app\",\" application\")\n",
    "                    two_word = two_word.replace(\" databases\",\" database\")\n",
    "                    two_word = two_word.replace(\" machines\",\" machine\")\n",
    "                    two_word = two_word.replace(\"website\",\"web\")\n",
    "                      \n",
    "                    if two_word in self.two_word_skill_classification_set:\n",
    "                        self.CopyReplaceFolder(dir,two_word,filename)\n",
    "                        have_classific = True\n",
    "\n",
    "                    if i + 2 >= len(words):\n",
    "                        break\n",
    "                    third_word = words[i+2]\n",
    "                    if third_word.endswith('.'):\n",
    "                        third_word = third_word[:-1] \n",
    "                    three_word = first_word + \" \" + second_word + \" \" +  third_word\n",
    "                    if three_word in self.three_word_skill_classification_set:\n",
    "                        self.CopyReplaceFolder(dir,three_word,filename)\n",
    "                        have_classific = True\n",
    "                \n",
    "                if have_classific == True:\n",
    "                    file_path = dir +\"/\" + filename + \".html\"\n",
    "                    if os.path.isfile(file_path):\n",
    "                        os.remove(file_path)\n",
    "                    else:\n",
    "                        print(f\"The file {file_path} does not exist.\")\n",
    "                    file_path = dir +\"/\" + filename + \".docx\"\n",
    "                    if os.path.isfile(file_path):\n",
    "                        os.remove(file_path)\n",
    "                    else:\n",
    "                        print(f\"The file {file_path} does not exist.\")\n",
    "                else:\n",
    "                    self.ReClassificationSkillDictList(filename, filename + \" in tech\" , {\"unknown\"})\n",
    "                        \n",
    "        self.GroupTextVectorization()\n",
    "        self.ExportSkillDictList()\n",
    "        self.ExportGroupDictList()\n",
    "\n",
    "    def ClassificationUnClassifedSkill(self):\n",
    "        h = html2text.HTML2Text()\n",
    "        h.ignore_links = False\n",
    "        h.inline_links = False\n",
    "        h.reference_links = True\n",
    "        dir = 'skill unclassified/not tech'\n",
    "        filenames = [f for f in listdir(dir) if isfile(join(dir, f))]\n",
    "        one_word_dict_list = {}\n",
    "        two_word_dict_list = {}\n",
    "        three_word_dict_list = {}\n",
    "        ignore_word_list = [\"a\",\"an\",\"the\",\"of\",\"on\",\"as\",\"by\",\"to\",\"with\",\"for\",\"is\",\"are\",\"was\",\"were\", \"in\"]\n",
    "        tech_word_list = [\"software\" ,\"application\", \"applications\", \"platform\", \"platforms\",\"api\", \"web\", \"website\",\"network\",\"networks\",\"security\",\"architecture\", \"development\" , \"system\", \"systems\", \"language\", \"cloud\", \"data\", \"open\",\"source\", \"windows\"]\n",
    "        for f in filenames:\n",
    "            words = f.rsplit(\".\")\n",
    "            extension = words[len(words)-1]\n",
    "            if extension ==\"html\":\n",
    "                filename = f.replace(\".html\",\"\")\n",
    "                html_content = str(\"\")\n",
    "                with open(dir+\"/\"+ f, 'r', encoding=\"utf-8\") as file:\n",
    "                    html_content = file.read()\n",
    "                    file.close()\n",
    "                text_content = h.handle(html_content)\n",
    "                text_content = text_content.lower()\n",
    "                text_content = text_content.replace(\"[1]\",\"\")\n",
    "                text_content = text_content.replace(\"[2]\",\"\")\n",
    "                text_content = text_content.replace(\"[3]\",\"\")\n",
    "                text_content = text_content.replace(\"[4]\",\"\")\n",
    "                text_content = text_content.replace(\"[5]\",\"\")\n",
    "                text_content = text_content.replace(\"[6]\",\"\")\n",
    "                text_content = text_content.replace(\"[7]\",\"\")\n",
    "                text_content = text_content.replace(\"[8]\",\"\")\n",
    "                text_content = text_content.replace(\"[9]\",\"\")\n",
    "                text_content = text_content.replace(\"[0]\",\"\")\n",
    "                text_content = text_content.replace(\"[\",\"\")\n",
    "                text_content = text_content.replace(\"]\",\"\")\n",
    "                text_content = text_content.replace(\"(\",\"\")\n",
    "                text_content = text_content.replace(\")\",\"\")\n",
    "                text_content = text_content.replace(\"*\",\"\")\n",
    "                text_content = text_content.replace(\"\\\"\",\"\")\n",
    "                text_content = text_content.replace(\"’s\",\"\")\n",
    "                text_content = text_content.replace(\"!\",\"\")\n",
    "                text_content = text_content.replace(\":\",\"\")\n",
    "                text_content = text_content.replace(\",\",\"\")\n",
    "                text_content = text_content.replace(\"\\n\",\" \")\n",
    "                text_content = text_content.replace(\"/\",\" \")\n",
    "                text_content = text_content.replace(\"-\",\" \")\n",
    "                words = text_content.split()\n",
    "                is_tech = False\n",
    "                for i in range(len(words)):\n",
    "                    if words[i] in tech_word_list:\n",
    "                        is_tech = True\n",
    "                        break\n",
    "                if is_tech == True:\n",
    "                    source_file = os.path.join(\"skill unclassified/not tech\", file_name)\n",
    "                    destination_file = os.path.join(\"skill unclassified/tech\", file_name)\n",
    "                    shutil.copy(source_file, destination_file)\n",
    "                    \n",
    "    def FindClassificationKeyword(self):\n",
    "        h = html2text.HTML2Text()\n",
    "        h.ignore_links = False\n",
    "        h.inline_links = False\n",
    "        h.reference_links = True\n",
    "        dir = 'skill classified/unknown'\n",
    "        filenames = [f for f in listdir(dir) if isfile(join(dir, f))]\n",
    "        one_word_dict_list = {}\n",
    "        two_word_dict_list = {}\n",
    "        three_word_dict_list = {}\n",
    "        ignore_word_list = [\"a\",\"an\",\"the\",\"of\",\"on\",\"as\",\"by\",\"to\",\"with\",\"for\",\"is\",\"are\",\"was\",\"were\", \"in\"]\n",
    "        for f in filenames:\n",
    "            words = f.rsplit(\".\")\n",
    "            extension = words[len(words)-1]\n",
    "            if extension ==\"html\":\n",
    "                filename = f.replace(\".html\",\"\")\n",
    "                html_content = str(\"\")\n",
    "                with open(dir+\"/\"+ f, 'r', encoding=\"utf-8\") as file:\n",
    "                    html_content = file.read()\n",
    "                    file.close()\n",
    "                text_content = h.handle(html_content)\n",
    "                text_content = text_content.lower()\n",
    "                text_content = text_content.replace(\"[1]\",\"\")\n",
    "                text_content = text_content.replace(\"[2]\",\"\")\n",
    "                text_content = text_content.replace(\"[3]\",\"\")\n",
    "                text_content = text_content.replace(\"[4]\",\"\")\n",
    "                text_content = text_content.replace(\"[5]\",\"\")\n",
    "                text_content = text_content.replace(\"[6]\",\"\")\n",
    "                text_content = text_content.replace(\"[7]\",\"\")\n",
    "                text_content = text_content.replace(\"[8]\",\"\")\n",
    "                text_content = text_content.replace(\"[9]\",\"\")\n",
    "                text_content = text_content.replace(\"[0]\",\"\")\n",
    "                text_content = text_content.replace(\"[\",\"\")\n",
    "                text_content = text_content.replace(\"]\",\"\")\n",
    "                text_content = text_content.replace(\"(\",\"\")\n",
    "                text_content = text_content.replace(\")\",\"\")\n",
    "                text_content = text_content.replace(\"*\",\"\")\n",
    "                text_content = text_content.replace(\"\\\"\",\"\")\n",
    "                text_content = text_content.replace(\"’s\",\"\")\n",
    "                text_content = text_content.replace(\"!\",\"\")\n",
    "                text_content = text_content.replace(\":\",\"\")\n",
    "                text_content = text_content.replace(\",\",\"\")\n",
    "                text_content = text_content.replace(\"\\n\",\" \")\n",
    "                text_content = text_content.replace(\"/\",\" \")\n",
    "                text_content = text_content.replace(\"-\",\" \")\n",
    "                words = text_content.split()\n",
    "                for i in range(len(words)):\n",
    "                    first_word = words[i]\n",
    "                    if '1.' in first_word:\n",
    "                        break\n",
    "                    if first_word.endswith('.'):\n",
    "                        first_word = first_word[:-1]\n",
    "                    if first_word in ignore_word_list:\n",
    "                        continue\n",
    "                    one_word = first_word\n",
    "                    if one_word not in one_word_dict_list:\n",
    "                        one_word_dict_list[one_word] = 0\n",
    "                    one_word_dict_list[one_word]+=1\n",
    "                    \n",
    "                    second_word = words[i+1]\n",
    "                    if second_word.endswith('.'):\n",
    "                        second_word = second_word[:-1] \n",
    "                    if second_word in ignore_word_list:\n",
    "                        continue\n",
    "                    two_word = first_word + \" \" + second_word\n",
    "                    if two_word not in two_word_dict_list:\n",
    "                        two_word_dict_list[two_word] = 0\n",
    "                    two_word_dict_list[two_word]+=1\n",
    "\n",
    "                    third_word = words[i+2]\n",
    "                    if third_word.endswith('.'):\n",
    "                        third_word = third_word[:-1] \n",
    "                    if third_word in ignore_word_list:\n",
    "                        continue\n",
    "                    three_word = first_word + \" \" + second_word + \" \" +third_word\n",
    "                    if three_word not in three_word_dict_list:\n",
    "                        three_word_dict_list[three_word] = 0\n",
    "                    three_word_dict_list[three_word]+=1\n",
    "        with open('count one word.txt', 'w', encoding=\"utf-8\" ) as f:\n",
    "            for s in sorted(one_word_dict_list, key=one_word_dict_list.get, reverse=True):\n",
    "                f.write(str(s) + \" - \" + str(one_word_dict_list[s]))\n",
    "                f.write('\\n')\n",
    "            file.close()\n",
    "        with open('count two word.txt', 'w', encoding=\"utf-8\") as f:\n",
    "            for s in sorted(two_word_dict_list, key=two_word_dict_list.get, reverse=True):\n",
    "                f.write(str(s) + \" - \" + str(two_word_dict_list[s]))\n",
    "                f.write('\\n')\n",
    "            file.close()\n",
    "        with open('count three word.txt', 'w', encoding=\"utf-8\") as f:\n",
    "            for s in sorted(three_word_dict_list, key=three_word_dict_list.get, reverse=True):\n",
    "                f.write(str(s) + \" - \" + str(three_word_dict_list[s]))\n",
    "                f.write('\\n')\n",
    "            file.close()\n",
    "\n",
    "    def InitLeetCodeCompanyNameDictList(self):\n",
    "        f = open(\"leetcode/companies.txt\", \"r\")\n",
    "        for c in f:\n",
    "            c = c.replace(\"\\n\", \"\")\n",
    "            key = c\n",
    "            key = key.lower()\n",
    "            self.leetcode_company_dict_list[key] = c\n",
    "        f.close\n",
    "          \n",
    "    def AllThisWillBeRemoveOnceFinalize(self):\n",
    "        \n",
    "        self.exact_match_replace_dict_list[\"aws\"]=\"amazon web services\"\n",
    "        self.exact_match_replace_dict_list[\"tdd\"]=\"testing\"\n",
    "        self.exact_match_replace_dict_list[\"webdriver\"]=\"web crawler\"\n",
    "        self.exact_match_replace_dict_list[\"vbnet\"]=\"visual basic .net\"\n",
    "        self.exact_match_replace_dict_list[\"vb.net\"]=\"visual basic .net\"\n",
    "        self.exact_match_replace_dict_list[\"vb\"]=\"visual basic\"\n",
    "        self.exact_match_replace_dict_list[\"html5\"]=\"html\"\n",
    "        self.exact_match_replace_dict_list[\"svn\"]=\"subversion\"\n",
    "        self.exact_match_replace_dict_list[\"rdbms\"]=\"relational\"\n",
    "        self.exact_match_replace_dict_list[\"unity3d\"]=\"unity\"\n",
    "        self.exact_match_replace_dict_list[\"mssql\"]=\"microsoft sql\"\n",
    "        self.exact_match_replace_dict_list[\"shaders\"]=\"shader\"\n",
    "        self.exact_match_replace_dict_list[\"uat\"]=\"testing\"\n",
    "        self.exact_match_replace_dict_list[\"mui\"]=\"material ui\"\n",
    "        self.exact_match_replace_dict_list[\"gui\"]=\"graphical user interface\"\n",
    "        self.exact_match_replace_dict_list[\"ui\"]=\"user interface\"\n",
    "        self.exact_match_replace_dict_list[\"mq\"]=\"message queue\"\n",
    "        self.exact_match_replace_dict_list[\"aliyun\"]=\"alibaba cloud\"\n",
    "        self.exact_match_replace_dict_list[\"ali-cloud\"]=\"alibaba cloud\"\n",
    "        \n",
    "        self.partial_match_replace_dict_list[\"ms\"]=\"microsoft\"\n",
    "        self.partial_match_replace_dict_list[\"system\"]=\"systems\"\n",
    "        self.partial_match_replace_dict_list[\"window\"]=\"windows\"\n",
    "        self.partial_match_replace_dict_list[\"databases\"]=\"database\"\n",
    "        self.partial_match_replace_dict_list[\"website\"]=\"web\"\n",
    "        self.partial_match_replace_dict_list[\"test\"]=\"testing\"\n",
    "        self.partial_match_replace_dict_list[\"networking\"]=\"network\"\n",
    "        self.partial_match_replace_dict_list[\"solarwinds\"]=\"solarwind\"\n",
    "\n",
    "     \n",
    "        \n",
    "        self.ExportMatchReplaceDictList()\n",
    "     \n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b3ea5afc-91a8-450e-b689-2f8610dbd841",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " not found, Sonar not found, Bottle not found, Openauth not found, Container not found, Mantis not found, Jackson not found, Cvs not found, Edb not found, Segment not found, Dash not found, Abc not found, Charles not found, Eclipse not found, Canal not found, Entity not found, Graven not found, Scout not found, Xray not found, Espresso not found, Studs not found, Concourse not found, Iss not found, Zeppelin not found, Photoshop not found, Hooks not found, Jcr not found, Bamboo not found, Lora not found, Karate not found, Drone not found, Autonomy not found, Ecr not found, Polymer not found, Quasar not found, Stripe not found, Jersey not found, Code Climate not found, Viper not found, Epoxy not found, Ems not found, Apollo not found, Fission not found, Mode not found, Retrofit not found, Graphite not found, Tencent not found, Dojo not found, Modular not found, Cocoa Framework not found, Endur not found, Aquadata not found, Amplitude not found, Onemap not found, Trac not found, Adobe Experience Cloud (Aec) not found, Bourne not found, Swing not found, Insomnia not found, Flux not found, Ireport not found, Amber not found, Busted not found, Nexus not found, Mocha not found, Kvs not found, Hudson not found, Quartz not found, Fisheye not found, Enzyme not found, Dat not found, Adobe Xd not found, Kepler not found, Nose not found, Dapresy not found, Fn not found, Spa not found, Relay not found, Karma not found, Gauge not found, Ranger not found, Mvp not found, Metal not found, Fink not found, Yii Framework not found, Jws not found, Hyperion not found, Unicon not found, Fresco not found, Combine not found, Leaflet not found\n"
     ]
    }
   ],
   "source": [
    "test = TechStack()\n",
    "skills = set()\n",
    "f = open(\"nodeflair skill.txt\", \"r\")\n",
    "for c in f:\n",
    "    c = c.replace(\"\\n\", \"\")\n",
    "    skills.add(c)\n",
    "f.close\n",
    "\n",
    "result = test.GenerateLearningResource(None, skills, None)\n",
    "print(result[\"Skill Learning Resource Remarks\"])\n",
    "test.ExportNotFoundSet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "62e3f713-9098-41d2-ac39-22929b5945c7",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'flask'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mflask\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Flask, request, jsonify, send_file, after_this_request\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mzipfile\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'flask'"
     ]
    }
   ],
   "source": [
    "from flask import Flask, request, jsonify, send_file, after_this_request\n",
    "import zipfile\n",
    "import os\n",
    "from io import BytesIO\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "@app.route('/get_zip', methods=['GET'])\n",
    "def get_zip():\n",
    "    # Retrieve parameters from the GET request\n",
    "    param1 = request.args.get('param1')\n",
    "    param2 = request.args.get('param2')\n",
    "\n",
    "    # Create a zip file in memory\n",
    "    memory_file = BytesIO()\n",
    "    with zipfile.ZipFile(memory_file, 'w') as zf:\n",
    "        # Add files to the zip file using the parameters\n",
    "        zf.writestr(f'{param1}.txt', f'Content for {param1}')\n",
    "        zf.writestr(f'{param2}.txt', f'Content for {param2}')\n",
    "    memory_file.seek(0)\n",
    "\n",
    "    # Define a function to remove the zip file after sending it\n",
    "    @after_this_request\n",
    "    def remove_file(response):\n",
    "        try:\n",
    "            os.remove(zip_path)\n",
    "        except Exception as error:\n",
    "            app.logger.error(\"Error removing or closing downloaded file handle\", error)\n",
    "        return response\n",
    "\n",
    "    # Send the zip file\n",
    "    response = send_file(memory_file, attachment_filename='files.zip', as_attachment=True)\n",
    "\n",
    "    # Return the JSON response with the download link\n",
    "    return jsonify({'success': True, 'message': 'Files are ready for download', 'download_link': '/get_zip'})\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run(debug=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a4c4910-cb60-4ca0-b94f-8bf01f758b75",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
