{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4b9b981e-d994-41b8-81d8-8ff213a69c73",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import en_core_web_sm\n",
    "import pandas as pd\n",
    "import pypandoc\n",
    "from pypandoc.pandoc_download import download_pandoc\n",
    "#download_pandoc()\n",
    "import csv\n",
    "import docx\n",
    "import os\n",
    "from pathlib import Path\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import shutil\n",
    "import html2text\n",
    "\n",
    "class Skill:\n",
    "    def __init__(self,name, keyword , groups=None,prerequisites= None):\n",
    "        filename = name\n",
    "        filename = filename.replace('/','-')\n",
    "        filename = filename.replace(\"\\\\\",'-')\n",
    "        filename = filename + \".html\"\n",
    "        path = os.path.join(\"skill\", filename)\n",
    "        path = path.replace(\"\\\\\",'/')\n",
    "        self.resource_path = path # for the resource path\n",
    "        self.keyword_search = keyword  # keyword for searching LLM\n",
    "        self.group_set = set()\n",
    "        if groups is not None:    \n",
    "            self.UpdateGroupSet(groups)\n",
    "        \n",
    "    def UpdateGroupSet(self,groups):\n",
    "        self.group_set.update(groups)\n",
    "        #print(\"skill group set updated.\")\n",
    "\n",
    "    def ChangeKeyword(self,keyword):\n",
    "        self.keyword_search = keyword\n",
    "  \n",
    "class Group:\n",
    "    def __init__(self,name,skills):\n",
    "        filename = name\n",
    "        filename = filename.replace('/','-')\n",
    "        filename = filename.replace(\"\\\\\",'-')\n",
    "        filename = filename + \".html\"\n",
    "        path = os.path.join(\"group\", filename)\n",
    "        path = path.replace(\"\\\\\",'/')\n",
    "        self.resource_path = path # for the resource path\n",
    "        self.keyword_search = name + \" in tech\" # keyword for searching LLM\n",
    "        self.skill_set = skills\n",
    "\n",
    "    def UpdateSkillSet(self,skill):\n",
    "        self.skill_set.update(skill)\n",
    "        #print(\"group skill set updated.\")\n",
    "\n",
    "    def ChangeKeyword(self,keyword):\n",
    "        self.keyword_search = keyword\n",
    "\n",
    "class TechStack:\n",
    "    def __init__(self):\n",
    "        self.nlp = spacy.load('en_core_web_md')\n",
    "        self.skill_dict_list = {}\n",
    "        self.group_dict_list = {}\n",
    "        self.exact_match_replace_dict_list = {}\n",
    "        self.partial_match_replace_dict_list = {}\n",
    "        self.vector_group_dict_list = {}\n",
    "        self.ignore_set = set()\n",
    "        self.not_found_dict_list = {}\n",
    "        self.document_pepare_set = set()\n",
    "        self.three_word_skill_classification_set =set()\n",
    "        self.two_word_skill_classification_set =set()\n",
    "        self.one_word_skill_classification_set =set()\n",
    "        self.backup_keyword_dict_list={}\n",
    "        self.ImportIgnoreSet()\n",
    "        self.AllThisWillBeRemoveOnceFinalize()\n",
    "        self.ImportClassificationSet()\n",
    "        self.ImportSkillDictList()\n",
    "        self.GroupTextVectorization()\n",
    "          \n",
    "    def AddSkillDictList(self,name,keyword,groups=None):\n",
    "        if name not in self.skill_dict_list:\n",
    "            self.skill_dict_list[name] = Skill(name,keyword,groups)\n",
    "            #print(name,\"added in skill_dict_list.\")\n",
    "            if groups is not None:\n",
    "                for g in groups:\n",
    "                    if g in self.group_dict_list:\n",
    "                        self.group_dict_list.get(g).UpdateSkillSet({name})\n",
    "                        #print(name,\"added in\",g,\".\")\n",
    "                    else:\n",
    "                        self.group_dict_list[g] = Group(g,{name})\n",
    "                        #print(\"new group:\",g,\"have been created and added\",name,\".\")\n",
    "        else:\n",
    "            self.UpdateSkillDictList(name,groups)\n",
    "\n",
    "    def ReClassificationSkillDictList(self,name,keyword,groups):\n",
    "        search_keyword = keyword\n",
    "        if name in self.backup_keyword_dict_list:\n",
    "            search_keyword = self.backup_keyword_dict_list[name]\n",
    "        self.AddSkillDictList(name,search_keyword,groups)\n",
    "                    \n",
    "    def UpdateSkillDictList(self,name,groups):\n",
    "        if name in self.skill_dict_list:\n",
    "            self.skill_dict_list[name].UpdateGroupSet(groups)\n",
    "\n",
    "    def AddGroupDictList(self,name,skills):\n",
    "        if skills is not None:\n",
    "            if name in self.group_dict_list:\n",
    "                self.UpdateGroupDictList(name,skills)\n",
    "            else:\n",
    "                found_set = set()\n",
    "                for s in skills:\n",
    "                    if s in self.skill_dict_list:\n",
    "                        self.skill_dict_list[s].UpdateGroupSet({name})\n",
    "                        found_set.add(s)  \n",
    "                        #print(s,\"added in\",name,\"group set.\")\n",
    "                self.group_dict_list[name] = Group(name,found_set)\n",
    "\n",
    "    def UpdateGroupDictList(self,name,skills):\n",
    "        if name in self.group_dict_list:\n",
    "            found_set = set()\n",
    "            for s in skills:\n",
    "                if s in self.skill_dict_list:\n",
    "                      found_set.add(s)  \n",
    "            self.group_dict_list[name].UpdateSkillSet(found_set)\n",
    "        else:\n",
    "            self.AddGroupDictList(name,skills)\n",
    "\n",
    "    def AddNotFoundDictList(self,name,keyword):\n",
    "        if name not in self.not_found_dict_list:\n",
    "            path = \"unclassified\"\n",
    "            self.not_found_dict_list[name] =  Skill(name,path,keyword,None)   \n",
    "\n",
    "    def ImportIgnoreSet(self):\n",
    "        f = open(\"ignore.txt\", \"r\")\n",
    "        for c in f:\n",
    "            c = c.replace(\"\\n\", \"\")\n",
    "            self.ignore_set.add(c)\n",
    "        f.close()\n",
    "\n",
    "    def ImportClassificationSet(self):\n",
    "        f = open(\"three word skill classification.txt\", \"r\")\n",
    "        for l in f:\n",
    "            l = l.replace(\"\\n\", \"\")\n",
    "            self.three_word_skill_classification_set.add(l)\n",
    "        f.close()\n",
    "        f = open(\"two word skill classification.txt\", \"r\")\n",
    "        for l in f:\n",
    "            l = l.replace(\"\\n\", \"\")\n",
    "            self.two_word_skill_classification_set.add(l)\n",
    "        f.close()\n",
    "        f = open(\"one word skill classification.txt\", \"r\")\n",
    "        for l in f:\n",
    "            l = l.replace(\"\\n\", \"\")\n",
    "            self.one_word_skill_classification_set.add(l)\n",
    "        f.close()\n",
    "        \n",
    "    def ExportSkillDictList(self):\n",
    "        file_path = \"skills.csv\"\n",
    "        with open(file_path, 'w', newline='') as file:\n",
    "            writer = csv.writer(file)\n",
    "            writer.writerow([\"Name\", \"Search Keyword\",\"Resource Path\",\"Groups\"])\n",
    "            for key, value in self.skill_dict_list.items():\n",
    "                name=key\n",
    "                search = value.keyword_search\n",
    "                path = value.resource_path\n",
    "                groups =\"\"\n",
    "            \n",
    "                for g in value.group_set:\n",
    "                    groups += \"[\"\n",
    "                    groups += g\n",
    "                    groups +=\"]\"\n",
    "             \n",
    "                writer.writerow([name,search,path,groups])\n",
    "            file.close()\n",
    "        with open('skills.txt', 'w') as f:\n",
    "            for i in self.skill_dict_list:\n",
    "                f.write(i)\n",
    "                f.write(\"\\n\")\n",
    "            f.close()\n",
    "            \n",
    "    def ImportSkillDictList(self):\n",
    "        df = pd.read_csv(\"skills.csv\")\n",
    "        for index, row in df.iterrows():\n",
    "            name = str(row['Name'])\n",
    "            keyword = str(row['Search Keyword'])\n",
    "            groups = str(row['Groups'])\n",
    "            groups_set = None\n",
    "            groups = groups.replace('[', '')\n",
    "            groups_list = groups.split(']')\n",
    "            if len(groups_list) > 0 :\n",
    "                groups_list = groups_list[:-1]\n",
    "                groups_set = set()\n",
    "                for g in groups_list:\n",
    "                    groups_set.add(g)\n",
    "            # auto create group also\n",
    "            self.AddSkillDictList(name,keyword,groups_set)\n",
    "                \n",
    "    def ExportGroupDictList(self):\n",
    "        file_path = \"groups.csv\"\n",
    "        with open(file_path, 'w', newline='') as file:\n",
    "            writer = csv.writer(file)\n",
    "            writer.writerow([\"Name\", \"Search Keyword\",\"Resource Path\",\"skills\"])\n",
    "            for key, value in self.group_dict_list.items():\n",
    "                name=key\n",
    "                search = value.keyword_search\n",
    "                path = value.resource_path\n",
    "                skills =\"\"\n",
    "                for s in value.skill_set:\n",
    "                    skills += \"[\"\n",
    "                    skills += s\n",
    "                    skills +=\"]\"\n",
    "                writer.writerow([name,search,path,skills])\n",
    "            file.close()\n",
    "\n",
    "    def ExportMatchReplaceDictList(self):\n",
    "        file_path = \"exact match.csv\"\n",
    "        with open(file_path, 'w', newline='') as file:\n",
    "            writer = csv.writer(file)\n",
    "            writer.writerow([\"Word\", \"Replace\"])\n",
    "            for key, value in self.exact_match_replace_dict_list.items():\n",
    "                writer.writerow([key,value])\n",
    "            file.close()\n",
    "        file_path = \"partial match.csv\"\n",
    "        with open(file_path, 'w', newline='') as file:\n",
    "            writer = csv.writer(file)\n",
    "            writer.writerow([\"Word\", \"Replace\"])\n",
    "            for key, value in self.partial_match_replace_dict_list.items():\n",
    "                writer.writerow([key,value])\n",
    "            file.close()\n",
    "\n",
    "    def ExportNotFoundSet(self):\n",
    "        file_path = \"not found.csv\"\n",
    "        with open(file_path, 'w', newline='') as file:\n",
    "            writer = csv.writer(file)\n",
    "            writer.writerow([\"Name\", \"Search Keyword\",\"Resource Path\"])\n",
    "            for key, value in self.not_found_dict_list.items():\n",
    "                name=key\n",
    "                search = value.keyword_search\n",
    "                path = \"skill unclassified/not tech/\" + name + \".html\"\n",
    "             \n",
    "                writer.writerow([name,search,path])\n",
    "            file.close()\n",
    "     \n",
    "    def Filter(self, text):\n",
    "        text = text.lower()\n",
    "        text = text.replace(\"/\",\" \")\n",
    "        if text.find('(') != -1:\n",
    "            text = text.split(\"(\")[0]\n",
    "            text = text.rsplit()[0]\n",
    "            \n",
    "        words = text.split()\n",
    "    \n",
    "        if text in self.ignore_set:\n",
    "            return str(\"\")\n",
    "            \n",
    "        if text in self.exact_match_replace_dict_list:\n",
    "            text = self.exact_match_replace_dict_list.get(text)\n",
    "            \n",
    "        words = text.split()\n",
    "        new_text = \"\"\n",
    "        for word in words:\n",
    "            if word in self.partial_match_replace_dict_list:\n",
    "                new_text += self.partial_match_replace_dict_list.get(word) \n",
    "                new_text +=\" \"\n",
    "            else:\n",
    "                new_text += word \n",
    "                new_text +=\" \"\n",
    "        return new_text[:-1]\n",
    "\n",
    "    def Search(self,text):\n",
    "        if text in self.skill_dict_list:\n",
    "            self.document_pepare_set.add(text)\n",
    "            return True\n",
    "        if text in self.group_dict_list:\n",
    "            self.document_pepare_set.add(text)\n",
    "            return True\n",
    "        # check for . - space and .js js\n",
    "        for sdl in  self.skill_dict_list:\n",
    "            check1 = sdl\n",
    "            check1 = check1.replace(\".\",\"\")\n",
    "            check2 = text\n",
    "            check2 = check2.replace(\".\",\"\")\n",
    "            if check1 == check2:\n",
    "                self.document_pepare_set.add(sdl)\n",
    "                return True\n",
    "            check1 = sdl\n",
    "            check1 = check1.replace(\"-\",\" \")\n",
    "            check2 = text\n",
    "            check2 = check2.replace(\"-\",\" \")\n",
    "            if check1 == check2:\n",
    "                self.document_pepare_set.add(sdl)\n",
    "                return True\n",
    "            check1 = sdl\n",
    "            check1 = check1.replace(\" \",\"\")\n",
    "            check2 = text\n",
    "            check2 = check2.replace(\" \",\"\")\n",
    "            if check1 == check2:\n",
    "                self.document_pepare_set.add(sdl)\n",
    "                return True\n",
    "            check1 = sdl\n",
    "            check1 = check1.replace(\".js\",\"\")\n",
    "            check1 = check1.replace(\"js\",\"\")\n",
    "            check2 = text\n",
    "            check2 = check2.replace(\".js\",\"\")\n",
    "            check2 = check2.replace(\"js\",\"\")\n",
    "            if check1 == check2:\n",
    "                self.document_pepare_set.add(sdl)\n",
    "                return True\n",
    "   \n",
    "        found = False      \n",
    "        words = text.split()\n",
    "        # check word by word\n",
    "        for word in words:   \n",
    "            if word in self.skill_dict_list:\n",
    "                self.document_pepare_set.add(word)\n",
    "                found = True\n",
    "            elif word in self.group_dict_list:\n",
    "                self.document_pepare_set.add(word)\n",
    "                found = True\n",
    "        \n",
    "        return found \n",
    "        \n",
    "    def GroupTextVectorization(self):\n",
    "        for word in self.group_dict_list:\n",
    "            if self.nlp.vocab[word].has_vector == True:\n",
    "                vector_word = self.nlp(word)\n",
    "                if vector_word not in self.vector_group_dict_list:\n",
    "                    self.vector_group_dict_list[vector_word] = set()\n",
    "                self.vector_group_dict_list[vector_word].add(word)\n",
    "\n",
    "    def VectorSearch(self, word):\n",
    "        if self.nlp.vocab[word].has_vector == True:\n",
    "            vector_word = self.nlp(word)\n",
    "            for vw in self.vector_group_dict_list:\n",
    "                similarity_score = vector_word.similarity(vw)\n",
    "                if similarity_score >= 0.9:\n",
    "                    for w in vector_group_dict_list[vw]:\n",
    "                        print(w)\n",
    "\n",
    "    def CopyReplaceFolder(self, source_dir ,dest_dir , filename): \n",
    "        keyword = \"\"\n",
    "        if dest_dir == \"unknown\":\n",
    "            keyword = filename + \" in tech\"\n",
    "        else:\n",
    "            keyword = filename\n",
    "        self.ReClassificationSkillDictList(filename, keyword , {dest_dir})\n",
    "        dest_dir = \"skill classified/\" + dest_dir\n",
    "        if not os.path.exists(dest_dir):\n",
    "            os.makedirs(dest_dir)\n",
    "        source_path_doc = source_dir + \"/\" + filename + \".docx\"\n",
    "        source_path_html = source_dir + \"/\" + filename + \".html\"\n",
    "        destination_path_doc =  dest_dir + \"/\" + filename + \".docx\"\n",
    "        destination_path_html = dest_dir + \"/\" + filename + \".html\"\n",
    "        if source_path_doc != destination_path_doc:\n",
    "            shutil.copyfile(source_path_doc, destination_path_doc)\n",
    "        if source_path_html != destination_path_html:\n",
    "            shutil.copyfile(source_path_html, destination_path_html)\n",
    "\n",
    "    def MakeDocsFromHtml(self):\n",
    "        dir = 'skill unclassified/not tech/'\n",
    "        filenames = [f for f in listdir(dir) if isfile(join(dir, f))]\n",
    "        for f in filenames:\n",
    "            print(f)\n",
    "            words = f.rsplit(\".\")\n",
    "            extension = words[len(words)-1]\n",
    "            if extension ==\"html\":\n",
    "                filename = f.replace(\".html\",\"\")\n",
    "                output = pypandoc.convert_file(dir + \"/\" + f, 'docx', outputfile= dir + \"/\" + filename +\".docx\")\n",
    " \n",
    "    def DeleteAllSkillFile(self):\n",
    "        for dir in self.three_word_skill_classification_set:\n",
    "            path = \"skill classified/\" + dir\n",
    "            if os.path.isdir(path):\n",
    "                for filename in os.listdir(path):\n",
    "                    file_path = os.path.join(path, filename)\n",
    "                    try:\n",
    "                        if os.path.isfile(file_path) or os.path.islink(file_path):\n",
    "                            os.unlink(file_path)\n",
    "                        elif os.path.isdir(file_path):\n",
    "                            shutil.rmtree(file_path)\n",
    "                    except Exception as e:\n",
    "                        print(f'Failed to delete {file_path}. Reason: {e}')\n",
    "        for dir in self.two_word_skill_classification_set:\n",
    "            path = \"skill classified/\" + dir\n",
    "            if os.path.isdir(dir):\n",
    "                for filename in os.listdir(path):\n",
    "                    file_path = os.path.join(path, filename)\n",
    "                    try:\n",
    "                        if os.path.isfile(file_path) or os.path.islink(file_path):\n",
    "                            os.unlink(file_path)\n",
    "                        elif os.path.isdir(file_path):\n",
    "                            shutil.rmtree(file_path)\n",
    "                    except Exception as e:\n",
    "                        print(f'Failed to delete {file_path}. Reason: {e}')\n",
    "        for dir in self.one_word_skill_classification_set:\n",
    "            path = \"skill classified/\" + dir\n",
    "            if os.path.isdir(path):\n",
    "                for filename in os.listdir(path):\n",
    "                    file_path = os.path.join(path, filename)\n",
    "                    try:\n",
    "                        if os.path.isfile(file_path) or os.path.islink(file_path):\n",
    "                            os.unlink(file_path)\n",
    "                        elif os.path.isdir(file_path):\n",
    "                            shutil.rmtree(file_path)\n",
    "                    except Exception as e:\n",
    "                        print(f'Failed to delete {file_path}. Reason: {e}')\n",
    "        source_dir = 'skill'\n",
    "        destination_dir = 'skill classified/unknown'\n",
    "        os.makedirs(destination_dir, exist_ok=True)\n",
    "\n",
    "        for file_name in os.listdir(source_dir):\n",
    "            source_file = os.path.join(source_dir, file_name)\n",
    "            destination_file = os.path.join(destination_dir, file_name)\n",
    "            shutil.copy(source_file, destination_file)\n",
    "        \n",
    "    def SkillReClassification(self): \n",
    "        self.backup_keyword_dict_list.clear()\n",
    "        for s in self.skill_dict_list:\n",
    "            self.backup_keyword_dict_list[s] = self.skill_dict_list[s].keyword_search\n",
    "        \n",
    "        self.skill_dict_list.clear()\n",
    "        self.group_dict_list.clear()\n",
    "        self.vector_group_dict_list.clear()\n",
    "        self.DeleteAllSkillFile()\n",
    "        h = html2text.HTML2Text()\n",
    "        h.ignore_links = False\n",
    "        h.inline_links = False\n",
    "        h.reference_links = True\n",
    "        dir = 'skill classified/unknown'\n",
    "        filenames = [f for f in listdir(dir) if isfile(join(dir, f))]\n",
    "         \n",
    "        for f in filenames:\n",
    "            words = f.rsplit(\".\")\n",
    "            extension = words[len(words)-1]\n",
    "            if extension ==\"html\":\n",
    "                filename = f.replace(\".html\",\"\")\n",
    "                html_content = str(\"\")\n",
    "                with open(dir+\"/\"+ f, 'r', encoding=\"utf-8\") as file:\n",
    "                    html_content = file.read()\n",
    "                    file.close()\n",
    "                text_content = h.handle(html_content)\n",
    "                text_content = text_content.lower()\n",
    "                text_content = text_content.replace(\"[1]\",\"\")\n",
    "                text_content = text_content.replace(\"[2]\",\"\")\n",
    "                text_content = text_content.replace(\"[3]\",\"\")\n",
    "                text_content = text_content.replace(\"[4]\",\"\")\n",
    "                text_content = text_content.replace(\"[5]\",\"\")\n",
    "                text_content = text_content.replace(\"[6]\",\"\")\n",
    "                text_content = text_content.replace(\"[7]\",\"\")\n",
    "                text_content = text_content.replace(\"[8]\",\"\")\n",
    "                text_content = text_content.replace(\"[9]\",\"\")\n",
    "                text_content = text_content.replace(\"[0]\",\"\")\n",
    "                text_content = text_content.replace(\"[\",\"\")\n",
    "                text_content = text_content.replace(\"]\",\"\")\n",
    "                text_content = text_content.replace(\"(\",\"\")\n",
    "                text_content = text_content.replace(\")\",\"\")\n",
    "                text_content = text_content.replace(\"*\",\"\")\n",
    "                text_content = text_content.replace(\"\\\"\",\"\")\n",
    "                text_content = text_content.replace(\"â€™s\",\"\")\n",
    "                text_content = text_content.replace(\"!\",\"\")\n",
    "                text_content = text_content.replace(\":\",\"\")\n",
    "                text_content = text_content.replace(\",\",\"\")\n",
    "                text_content = text_content.replace(\"\\n\",\" \")\n",
    "                text_content = text_content.replace(\"/\",\" \")\n",
    "                text_content = text_content.replace(\"-\",\" \")\n",
    "              \n",
    "                words = text_content.split()\n",
    "                have_classific = False\n",
    "                for i in range(len(words)):\n",
    "                    first_word = words[i]\n",
    "                    if first_word.endswith('.'):\n",
    "                        first_word = first_word[:-1]\n",
    "                   \n",
    "                    one_word = first_word\n",
    "                    one_word = one_word.replace(\"microservices\",\"microservice\")\n",
    "                    one_word = one_word.replace(\"protocols\",\"protocol\")\n",
    "                    one_word = one_word.replace(\"networks\",\"network\")\n",
    "                    one_word = one_word.replace(\"website\",\"web\")\n",
    "                    one_word = one_word.replace(\"test\",\"testing\")\n",
    "                    one_word = one_word.replace(\"visualizations\",\"visualization\")\n",
    "                    one_word = one_word.replace(\"aws\",\"amazon\")\n",
    "        \n",
    "                    if one_word in self.one_word_skill_classification_set:\n",
    "                        self.CopyReplaceFolder(dir,one_word,filename)\n",
    "                        have_classific = True\n",
    "        \n",
    "                    if one_word ==\"ai\":\n",
    "                        one_word = \"artificial intelligence\"\n",
    "                        if one_word in self.two_word_skill_classification_set:\n",
    "                            self.CopyReplaceFolder(dir,one_word,filename)\n",
    "                            have_classific = True\n",
    "                    if one_word ==\"api\":\n",
    "                        one_word = \"application programming interface\"\n",
    "                        if one_word in self.three_word_skill_classification_set:\n",
    "                            self.CopyReplaceFolder(dir,one_word,filename)\n",
    "                            have_classific = True\n",
    "                    if one_word ==\"nlp\":\n",
    "                        one_word = \"natural language processing\"\n",
    "                        if one_word in self.three_word_skill_classification_set:\n",
    "                            self.CopyReplaceFolder(dir,one_word,filename)\n",
    "                            have_classific = True\n",
    "\n",
    "                    if i + 1 >= len(words):\n",
    "                        break\n",
    "                    second_word = words[i+1]\n",
    "                    if second_word.endswith('.'):\n",
    "                        second_word = second_word[:-1] \n",
    "                \n",
    "                    two_word = first_word + \" \" + second_word\n",
    "                    two_word = two_word.replace(\" servers\",\" server\")\n",
    "                    two_word = two_word.replace(\" services\",\" service\")\n",
    "                    two_word = two_word.replace(\" applications\",\" application\")\n",
    "                    two_word = two_word.replace(\" apps\",\" application\")\n",
    "                    two_word = two_word.replace(\" app\",\" application\")\n",
    "                    two_word = two_word.replace(\" databases\",\" database\")\n",
    "                    two_word = two_word.replace(\" machines\",\" machine\")\n",
    "                    two_word = two_word.replace(\"website\",\"web\")\n",
    "                      \n",
    "                    if two_word in self.two_word_skill_classification_set:\n",
    "                        self.CopyReplaceFolder(dir,two_word,filename)\n",
    "                        have_classific = True\n",
    "\n",
    "                    if i + 2 >= len(words):\n",
    "                        break\n",
    "                    third_word = words[i+2]\n",
    "                    if third_word.endswith('.'):\n",
    "                        third_word = third_word[:-1] \n",
    "                    three_word = first_word + \" \" + second_word + \" \" +  third_word\n",
    "                    if three_word in self.three_word_skill_classification_set:\n",
    "                        self.CopyReplaceFolder(dir,three_word,filename)\n",
    "                        have_classific = True\n",
    "                \n",
    "                if have_classific == True:\n",
    "                    file_path = dir +\"/\" + filename + \".html\"\n",
    "                    if os.path.isfile(file_path):\n",
    "                        os.remove(file_path)\n",
    "                    else:\n",
    "                        print(f\"The file {file_path} does not exist.\")\n",
    "                    file_path = dir +\"/\" + filename + \".docx\"\n",
    "                    if os.path.isfile(file_path):\n",
    "                        os.remove(file_path)\n",
    "                    else:\n",
    "                        print(f\"The file {file_path} does not exist.\")\n",
    "                else:\n",
    "                    self.ReClassificationSkillDictList(filename, filename + \" in tech\" , {\"unknown\"})\n",
    "                        \n",
    "        self.GroupTextVectorization()\n",
    "        self.ExportSkillDictList()\n",
    "        self.ExportGroupDictList()\n",
    "\n",
    "    def ClassificationUnClassifedSkill(self):\n",
    "        h = html2text.HTML2Text()\n",
    "        h.ignore_links = False\n",
    "        h.inline_links = False\n",
    "        h.reference_links = True\n",
    "        dir = 'skill unclassified/not tech'\n",
    "        filenames = [f for f in listdir(dir) if isfile(join(dir, f))]\n",
    "        one_word_dict_list = {}\n",
    "        two_word_dict_list = {}\n",
    "        three_word_dict_list = {}\n",
    "        ignore_word_list = [\"a\",\"an\",\"the\",\"of\",\"on\",\"as\",\"by\",\"to\",\"with\",\"for\",\"is\",\"are\",\"was\",\"were\", \"in\"]\n",
    "        tech_word_list = [\"software\" ,\"application\", \"applications\", \"platform\", \"platforms\",\"api\", \"web\", \"website\",\"network\",\"networks\",\"security\",\"architecture\", \"development\" , \"system\", \"systems\", \"language\", \"cloud\", \"data\", \"open\",\"source\", \"windows\"]\n",
    "        for f in filenames:\n",
    "            words = f.rsplit(\".\")\n",
    "            extension = words[len(words)-1]\n",
    "            if extension ==\"html\":\n",
    "                filename = f.replace(\".html\",\"\")\n",
    "                html_content = str(\"\")\n",
    "                with open(dir+\"/\"+ f, 'r', encoding=\"utf-8\") as file:\n",
    "                    html_content = file.read()\n",
    "                    file.close()\n",
    "                text_content = h.handle(html_content)\n",
    "                text_content = text_content.lower()\n",
    "                text_content = text_content.replace(\"[1]\",\"\")\n",
    "                text_content = text_content.replace(\"[2]\",\"\")\n",
    "                text_content = text_content.replace(\"[3]\",\"\")\n",
    "                text_content = text_content.replace(\"[4]\",\"\")\n",
    "                text_content = text_content.replace(\"[5]\",\"\")\n",
    "                text_content = text_content.replace(\"[6]\",\"\")\n",
    "                text_content = text_content.replace(\"[7]\",\"\")\n",
    "                text_content = text_content.replace(\"[8]\",\"\")\n",
    "                text_content = text_content.replace(\"[9]\",\"\")\n",
    "                text_content = text_content.replace(\"[0]\",\"\")\n",
    "                text_content = text_content.replace(\"[\",\"\")\n",
    "                text_content = text_content.replace(\"]\",\"\")\n",
    "                text_content = text_content.replace(\"(\",\"\")\n",
    "                text_content = text_content.replace(\")\",\"\")\n",
    "                text_content = text_content.replace(\"*\",\"\")\n",
    "                text_content = text_content.replace(\"\\\"\",\"\")\n",
    "                text_content = text_content.replace(\"â€™s\",\"\")\n",
    "                text_content = text_content.replace(\"!\",\"\")\n",
    "                text_content = text_content.replace(\":\",\"\")\n",
    "                text_content = text_content.replace(\",\",\"\")\n",
    "                text_content = text_content.replace(\"\\n\",\" \")\n",
    "                text_content = text_content.replace(\"/\",\" \")\n",
    "                text_content = text_content.replace(\"-\",\" \")\n",
    "                words = text_content.split()\n",
    "                is_tech = False\n",
    "                for i in range(len(words)):\n",
    "                    if words[i] in tech_word_list:\n",
    "                        is_tech = True\n",
    "                        break\n",
    "                if is_tech == True:\n",
    "                    source_file = os.path.join(\"skill unclassified/not tech\", file_name)\n",
    "                    destination_file = os.path.join(\"skill unclassified/tech\", file_name)\n",
    "                    shutil.copy(source_file, destination_file)\n",
    "                    \n",
    "    def FindClassificationKeyword(self):\n",
    "        h = html2text.HTML2Text()\n",
    "        h.ignore_links = False\n",
    "        h.inline_links = False\n",
    "        h.reference_links = True\n",
    "        dir = 'skill classified/unknown'\n",
    "        filenames = [f for f in listdir(dir) if isfile(join(dir, f))]\n",
    "        one_word_dict_list = {}\n",
    "        two_word_dict_list = {}\n",
    "        three_word_dict_list = {}\n",
    "        ignore_word_list = [\"a\",\"an\",\"the\",\"of\",\"on\",\"as\",\"by\",\"to\",\"with\",\"for\",\"is\",\"are\",\"was\",\"were\", \"in\"]\n",
    "        for f in filenames:\n",
    "            words = f.rsplit(\".\")\n",
    "            extension = words[len(words)-1]\n",
    "            if extension ==\"html\":\n",
    "                filename = f.replace(\".html\",\"\")\n",
    "                html_content = str(\"\")\n",
    "                with open(dir+\"/\"+ f, 'r', encoding=\"utf-8\") as file:\n",
    "                    html_content = file.read()\n",
    "                    file.close()\n",
    "                text_content = h.handle(html_content)\n",
    "                text_content = text_content.lower()\n",
    "                text_content = text_content.replace(\"[1]\",\"\")\n",
    "                text_content = text_content.replace(\"[2]\",\"\")\n",
    "                text_content = text_content.replace(\"[3]\",\"\")\n",
    "                text_content = text_content.replace(\"[4]\",\"\")\n",
    "                text_content = text_content.replace(\"[5]\",\"\")\n",
    "                text_content = text_content.replace(\"[6]\",\"\")\n",
    "                text_content = text_content.replace(\"[7]\",\"\")\n",
    "                text_content = text_content.replace(\"[8]\",\"\")\n",
    "                text_content = text_content.replace(\"[9]\",\"\")\n",
    "                text_content = text_content.replace(\"[0]\",\"\")\n",
    "                text_content = text_content.replace(\"[\",\"\")\n",
    "                text_content = text_content.replace(\"]\",\"\")\n",
    "                text_content = text_content.replace(\"(\",\"\")\n",
    "                text_content = text_content.replace(\")\",\"\")\n",
    "                text_content = text_content.replace(\"*\",\"\")\n",
    "                text_content = text_content.replace(\"\\\"\",\"\")\n",
    "                text_content = text_content.replace(\"â€™s\",\"\")\n",
    "                text_content = text_content.replace(\"!\",\"\")\n",
    "                text_content = text_content.replace(\":\",\"\")\n",
    "                text_content = text_content.replace(\",\",\"\")\n",
    "                text_content = text_content.replace(\"\\n\",\" \")\n",
    "                text_content = text_content.replace(\"/\",\" \")\n",
    "                text_content = text_content.replace(\"-\",\" \")\n",
    "                words = text_content.split()\n",
    "                for i in range(len(words)):\n",
    "                    first_word = words[i]\n",
    "                    if '1.' in first_word:\n",
    "                        break\n",
    "                    if first_word.endswith('.'):\n",
    "                        first_word = first_word[:-1]\n",
    "                    if first_word in ignore_word_list:\n",
    "                        continue\n",
    "                    one_word = first_word\n",
    "                    if one_word not in one_word_dict_list:\n",
    "                        one_word_dict_list[one_word] = 0\n",
    "                    one_word_dict_list[one_word]+=1\n",
    "                    \n",
    "                    second_word = words[i+1]\n",
    "                    if second_word.endswith('.'):\n",
    "                        second_word = second_word[:-1] \n",
    "                    if second_word in ignore_word_list:\n",
    "                        continue\n",
    "                    two_word = first_word + \" \" + second_word\n",
    "                    if two_word not in two_word_dict_list:\n",
    "                        two_word_dict_list[two_word] = 0\n",
    "                    two_word_dict_list[two_word]+=1\n",
    "\n",
    "                    third_word = words[i+2]\n",
    "                    if third_word.endswith('.'):\n",
    "                        third_word = third_word[:-1] \n",
    "                    if third_word in ignore_word_list:\n",
    "                        continue\n",
    "                    three_word = first_word + \" \" + second_word + \" \" +third_word\n",
    "                    if three_word not in three_word_dict_list:\n",
    "                        three_word_dict_list[three_word] = 0\n",
    "                    three_word_dict_list[three_word]+=1\n",
    "        with open('count one word.txt', 'w', encoding=\"utf-8\" ) as f:\n",
    "            for s in sorted(one_word_dict_list, key=one_word_dict_list.get, reverse=True):\n",
    "                f.write(str(s) + \" - \" + str(one_word_dict_list[s]))\n",
    "                f.write('\\n')\n",
    "            file.close()\n",
    "        with open('count two word.txt', 'w', encoding=\"utf-8\") as f:\n",
    "            for s in sorted(two_word_dict_list, key=two_word_dict_list.get, reverse=True):\n",
    "                f.write(str(s) + \" - \" + str(two_word_dict_list[s]))\n",
    "                f.write('\\n')\n",
    "            file.close()\n",
    "        with open('count three word.txt', 'w', encoding=\"utf-8\") as f:\n",
    "            for s in sorted(three_word_dict_list, key=three_word_dict_list.get, reverse=True):\n",
    "                f.write(str(s) + \" - \" + str(three_word_dict_list[s]))\n",
    "                f.write('\\n')\n",
    "            file.close()\n",
    "          \n",
    "    \n",
    "    def GenerateLearningResource(self,your_skills, job_skills):\n",
    "        skills = set()\n",
    "        if your_skills is not None:\n",
    "            skills =  job_skills -  your_skills \n",
    "        else:\n",
    "            skills = job_skills\n",
    "\n",
    "        if len(skills) == 0:\n",
    "            print(\"you are good.\")\n",
    "            return False\n",
    "        \n",
    "        self.document_pepare_set.clear()\n",
    "\n",
    "        for s in skills:\n",
    "            s = self.Filter(s)\n",
    "            if s != \"\":\n",
    "                found = self.Search(s)\n",
    "                if found == False:\n",
    "                    self.AddNotFoundDictList(s,s + \" in tech\")\n",
    "                    \n",
    "        if len(self.document_pepare_set) == 0 :\n",
    "            print(\"No any learning resource generated.\")\n",
    "            return False\n",
    "        print(\"not found\")\n",
    "        for d in self.not_found_dict_list:\n",
    "            print(d)\n",
    "        html_content = \"\"\n",
    "        for d in self.document_pepare_set:\n",
    "            path = \"\"\n",
    "            if d in self.skill_dict_list:\n",
    "                v = self.skill_dict_list.get(d)\n",
    "                path = v.resource_path\n",
    "            elif d in self.skill_dict_list:\n",
    "                v = self.group_dict_list.get(d)\n",
    "                path = v.resource_path\n",
    "            else:\n",
    "                continue\n",
    "\n",
    "            if os.path.isfile(path) == False:\n",
    "                print(d,\"not found in\",path)\n",
    "            else:\n",
    "                with open(path, \"r\", encoding=\"utf-8\") as file:\n",
    "                    title = d.title()\n",
    "                    html_content +=\"<h1><u><b>\"\n",
    "                    html_content += title\n",
    "                    html_content +=\"</b></u></h1>\"\n",
    "                    html_content += file.read()\n",
    "                file.close()\n",
    "        with open(\"learning resource.html\", 'w', encoding='utf-8') as file:\n",
    "            file.write(html_content)  \n",
    "            file.close()\n",
    "        output = pypandoc.convert_text(html_content, 'docx', format='html', outputfile='learning resource.docx')\n",
    "        if output == \"\":\n",
    "            print(\"Document output sucessfully.\")\n",
    "            return True\n",
    "        else:\n",
    "            print(\"Document output failed\")\n",
    "            return False\n",
    "                 \n",
    "            \n",
    "    def AllThisWillBeRemoveOnceFinalize(self):\n",
    "        \n",
    "        self.exact_match_replace_dict_list[\"aws\"]=\"amazon web services\"\n",
    "        self.exact_match_replace_dict_list[\"tdd\"]=\"testing\"\n",
    "        self.exact_match_replace_dict_list[\"webdriver\"]=\"web crawler\"\n",
    "        self.exact_match_replace_dict_list[\"vbnet\"]=\"visual basic .net\"\n",
    "        self.exact_match_replace_dict_list[\"vb.net\"]=\"visual basic .net\"\n",
    "        self.exact_match_replace_dict_list[\"vb\"]=\"visual basic\"\n",
    "        self.exact_match_replace_dict_list[\"html5\"]=\"html\"\n",
    "        self.exact_match_replace_dict_list[\"svn\"]=\"subversion\"\n",
    "        self.exact_match_replace_dict_list[\"rdbms\"]=\"relational\"\n",
    "        self.exact_match_replace_dict_list[\"unity3d\"]=\"unity\"\n",
    "        self.exact_match_replace_dict_list[\"mssql\"]=\"microsoft sql\"\n",
    "        self.exact_match_replace_dict_list[\"shaders\"]=\"shader\"\n",
    "        self.exact_match_replace_dict_list[\"uat\"]=\"testing\"\n",
    "        self.exact_match_replace_dict_list[\"mui\"]=\"material ui\"\n",
    "        self.exact_match_replace_dict_list[\"gui\"]=\"graphical user interface\"\n",
    "        self.exact_match_replace_dict_list[\"ui\"]=\"user interface\"\n",
    "        self.exact_match_replace_dict_list[\"mq\"]=\"message queue\"\n",
    "        self.exact_match_replace_dict_list[\"aliyun\"]=\"alibaba cloud\"\n",
    "        self.exact_match_replace_dict_list[\"ali-cloud\"]=\"alibaba cloud\"\n",
    "        \n",
    "        self.partial_match_replace_dict_list[\"ms\"]=\"microsoft\"\n",
    "        self.partial_match_replace_dict_list[\"system\"]=\"systems\"\n",
    "        self.partial_match_replace_dict_list[\"window\"]=\"windows\"\n",
    "        self.partial_match_replace_dict_list[\"databases\"]=\"database\"\n",
    "        self.partial_match_replace_dict_list[\"website\"]=\"web\"\n",
    "        self.partial_match_replace_dict_list[\"test\"]=\"testing\"\n",
    "        self.partial_match_replace_dict_list[\"networking\"]=\"network\"\n",
    "        self.partial_match_replace_dict_list[\"solarwinds\"]=\"solarwind\"\n",
    "\n",
    "     \n",
    "        \n",
    "        self.ExportMatchReplaceDictList()\n",
    "     \n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b3ea5afc-91a8-450e-b689-2f8610dbd841",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "not found\n",
      "canal\n",
      "ireport\n",
      "mantis\n",
      "cocoa framework\n",
      "jersey\n",
      "ranger\n",
      "gauge\n",
      "charles\n",
      "hooks\n",
      "iss\n",
      "quartz\n",
      "jws\n",
      "autonomy\n",
      "xray\n",
      "kepler\n",
      "bourne\n",
      "kvs\n",
      "onemap\n",
      "fission\n",
      "nose\n",
      "karate\n",
      "endur\n",
      "flux\n",
      "zeppelin\n",
      "dapresy\n",
      "lora\n",
      "spa\n",
      "polymer\n",
      "amber\n",
      "bamboo\n",
      "fresco\n",
      "hudson\n",
      "sonar\n",
      "ecr\n",
      "ems\n",
      "mode\n",
      "metal\n",
      "retrofit\n",
      "container\n",
      "combine\n",
      "bottle\n",
      "abc\n",
      "apollo\n",
      "aquadata\n",
      "fn\n",
      "stripe\n",
      "dash\n",
      "code climate\n",
      "dojo\n",
      "jackson\n",
      "enzyme\n",
      "adobe\n",
      "mocha\n",
      "concourse\n",
      "entity\n",
      "unicon\n",
      "swing\n",
      "fisheye\n",
      "graphite\n",
      "drone\n",
      "modular\n",
      "mvp\n",
      "scout\n",
      "fink\n",
      "karma\n",
      "photoshop\n",
      "tencent\n",
      "leaflet\n",
      "trac\n",
      "segment\n",
      "adobe xd\n",
      "busted\n",
      "hyperion\n",
      "jcr\n",
      "insomnia\n",
      "dat\n",
      "studs\n",
      "relay\n",
      "epoxy\n",
      "eclipse\n",
      "nexus\n",
      "yii framework\n",
      "amplitude\n",
      "viper\n",
      "cvs\n",
      "graven\n",
      "edb\n",
      "quasar\n",
      "openauth\n",
      "espresso\n",
      "Document output sucessfully.\n"
     ]
    }
   ],
   "source": [
    "test = TechStack()\n",
    "f = open(\"nodeflair skill.txt\", \"r\")\n",
    "skills = set()\n",
    "for c in f:\n",
    "    c = c.replace(\"\\n\", \"\")\n",
    "    if c == 'x':\n",
    "        continue\n",
    "    skills.add(c)\n",
    "f.close\n",
    "result = test.GenerateLearningResource(None, skills)\n",
    "test.ExportNotFoundSet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fc6e9d6-5b6b-48ba-a152-71f5b2d11f8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#openauth not found in unknown/openauth.html\n",
    "#elastic bean stalk not found in unknown/elastic bean stalk.html\n",
    "#https://stackoverflow.com/questions/75475470/how-to-extract-the-all-hyperlink-and-their-text-from-a-word-document-using-pytho"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "242a69d0-06d5-4df6-a57f-866c3b58c8ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "![C++][1]\n",
      "\n",
      "![C++][2]\n",
      "\n",
      "Explore\n",
      "\n",
      "Certainly! **C++** is a **cross-platform programming language** that extends\n",
      "the capabilities of the C language, providing high control over system\n",
      "resources and memory. [Itâ€™s widely used for creating high-performance\n",
      "applications, operating systems, and embedded systems][3][1][3][2][4][3][5].\n",
      "\n",
      "Here are **five free resources** where you can learn C++:\n",
      "\n",
      "  1. [****][3]**[W3Schools C++ Introduction][3]** : This tutorial covers the basics of C++, including syntax, variables, and development[1][3].\n",
      "  2. [****][3]**[LearnCpp.com][6]** : A comprehensive website with step-by-step tutorials, examples, and quizzes to help you master C++ programming[4][6].\n",
      "  3. [****][3]**[Programiz C++ Tutorial][7]** : Offers interactive lessons, examples, and references for learning C++[5][7].\n",
      "  4. [****][3]**[Codecademy C++ Course][8]** : A beginner-friendly course that covers C++ essentials for software development[6][8].\n",
      "  5. **Official C++ Documentation** : The official documentation provides in-depth information about C++ features, syntax, and libraries. You can find it on the C++ Standard website.\n",
      "\n",
      "Happy learning! ðŸš€ðŸ‘©â€ðŸ’»\n",
      "\n",
      "   [1]:\n",
      "https://www.bing.com/th?id=OSK.830992e6b8f0c7bc66cd3d6fa3db36b4&pid=cdx&w=320&h=189&c=7&rs=1\n",
      "\n",
      "   [2]:\n",
      "https://www.bing.com/th?id=OSK.830992e6b8f0c7bc66cd3d6fa3db36b4&pid=cdx&w=168&h=189&c=7\n",
      "\n",
      "   [3]: https://www.w3schools.com/cpp/cpp_intro.asp\n",
      "\n",
      "   [4]: https://en.wikipedia.org/wiki/C%2B%2B\n",
      "\n",
      "   [5]: https://www.geeksforgeeks.org/introduction-to-c-programming-language/\n",
      "\n",
      "   [6]: https://www.learncpp.com/\n",
      "\n",
      "   [7]: https://www.programiz.com/cpp-programming\n",
      "\n",
      "   [8]: https://www.codecademy.com/learn/learn-c-plus-plus\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import html2text\n",
    "\n",
    "html_content = str(\"\")\n",
    "with open('unknown/c++.html', 'r', encoding=\"utf-8\") as file:\n",
    "    html_content = file.read()\n",
    "file.close()\n",
    "\n",
    "h = html2text.HTML2Text()\n",
    "\n",
    "h.ignore_links = False\n",
    "h.inline_links = False\n",
    "h.reference_links = True\n",
    "\n",
    "# Convert HTML to text with separated links\n",
    "text_content = h.handle(html_content)\n",
    "\n",
    "print(text_content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "62e3f713-9098-41d2-ac39-22929b5945c7",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'flask'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mflask\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Flask, request, jsonify, send_file, after_this_request\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mzipfile\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'flask'"
     ]
    }
   ],
   "source": [
    "from flask import Flask, request, jsonify, send_file, after_this_request\n",
    "import zipfile\n",
    "import os\n",
    "from io import BytesIO\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "@app.route('/get_zip', methods=['GET'])\n",
    "def get_zip():\n",
    "    # Retrieve parameters from the GET request\n",
    "    param1 = request.args.get('param1')\n",
    "    param2 = request.args.get('param2')\n",
    "\n",
    "    # Create a zip file in memory\n",
    "    memory_file = BytesIO()\n",
    "    with zipfile.ZipFile(memory_file, 'w') as zf:\n",
    "        # Add files to the zip file using the parameters\n",
    "        zf.writestr(f'{param1}.txt', f'Content for {param1}')\n",
    "        zf.writestr(f'{param2}.txt', f'Content for {param2}')\n",
    "    memory_file.seek(0)\n",
    "\n",
    "    # Define a function to remove the zip file after sending it\n",
    "    @after_this_request\n",
    "    def remove_file(response):\n",
    "        try:\n",
    "            os.remove(zip_path)\n",
    "        except Exception as error:\n",
    "            app.logger.error(\"Error removing or closing downloaded file handle\", error)\n",
    "        return response\n",
    "\n",
    "    # Send the zip file\n",
    "    response = send_file(memory_file, attachment_filename='files.zip', as_attachment=True)\n",
    "\n",
    "    # Return the JSON response with the download link\n",
    "    return jsonify({'success': True, 'message': 'Files are ready for download', 'download_link': '/get_zip'})\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run(debug=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cba39eb0-2936-4fa2-a1ed-a2e88a6baf98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a4c4910-cb60-4ca0-b94f-8bf01f758b75",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
