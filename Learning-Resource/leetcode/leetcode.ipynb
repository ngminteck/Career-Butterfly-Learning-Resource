{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "de4d4246-9078-4ce6-aeda-5c76d29d51d5",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from seleniumbase import Driver\n",
    "from seleniumbase import page_actions\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import requests\n",
    "import time\n",
    "import csv\n",
    "import os\n",
    "from pathlib import Path\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "class LeetcodeScrapper:\n",
    "    def __init__(self):\n",
    "        self.driver = Driver(uc=True)\n",
    "        self.tag_list=[]\n",
    "        self.companies_list=[]\n",
    "        self.cno = 0\n",
    "        self.failed_list =[]\n",
    "        self.top_question_no_tag_list =[] \n",
    "        self.tno = 0\n",
    "        self.question_dict_list={}\n",
    "        self.question_queue =[]\n",
    "        self.qno = 0\n",
    "        self.qlno =1\n",
    "        self.find_question_tag_dict_list = {}\n",
    "        self.find_question_tag_queue = []\n",
    "        self.qtno = 0\n",
    "        \n",
    "\n",
    "    def Login(self,id,pw):\n",
    "        url = \"https://leetcode.com/accounts/login/\"\n",
    "        self.driver.get(url)\n",
    "        id_field = self.driver.find_element(by=By.ID, value=\"id_login\")\n",
    "        id_field.send_keys(id)\n",
    "        time.sleep(1)\n",
    "        pw_field = self.driver.find_element(by=By.ID, value=\"id_password\")\n",
    "        pw_field.send_keys(pw)\n",
    "        #no need check ctp\n",
    "        WebDriverWait(self.driver, 5).until(EC.element_to_be_clickable((By.ID, \"signin_btn\"))).click()\n",
    "        time.sleep(5)\n",
    "\n",
    "    def SetTopNo(self,no):\n",
    "        self.tno = no\n",
    "\n",
    "    def GetTitleToWebText(self,text):\n",
    "        text = text.lower()\n",
    "        text = text.replace('`', '')\n",
    "        text = text.replace(\"(\", '')\n",
    "        text = text.replace(\")\", '')\n",
    "        text = text.replace(\":\", '')\n",
    "        text = text.replace(\",\", '-')\n",
    "        text = text.replace(\"'\", '')\n",
    "        text = text.replace(\"%\", '')\n",
    "        text = text.replace(\"&\", '')\n",
    "        text = text.replace(' ', '-')\n",
    "        text = re.sub(r'(-{2,})', '-', text)\n",
    "        return text\n",
    "\n",
    "    def GetQuestionList(self):\n",
    "        if self.qlno < 29:\n",
    "            url =\"https://leetcode.com/problemset/?sorting=W3sic29ydE9yZGVyIjoiREVTQ0VORElORyIsIm9yZGVyQnkiOiJGUkVRVUVOQ1kifV0%3D&page=\" + str(self.qlno)\n",
    "            self.driver.get(url)\n",
    "            time.sleep(10)\n",
    "            with open(\"Leetcode Overall Question List/\"+ str(self.qlno) + \".csv\", 'w', newline='') as file:\n",
    "                writer = csv.writer(file)\n",
    "                writer.writerow([\"No\", \"Title\",\"Link\",\"Tags\",\"Acceptance\",\"Difficulty\",\"Frequency\"])\n",
    "                cols = self.driver.find_elements(by = By.XPATH,value=\"(//div[@role='cell'])\")\n",
    "                no = str(\"\")\n",
    "                title = str(\"\")\n",
    "                link = str(\"\")\n",
    "                acceptance = str(\"\")\n",
    "                difficulty = str(\"\")\n",
    "                i = 1\n",
    "                for c in cols:\n",
    "                    column = i % 6\n",
    "                    if column == 2:\n",
    "                        text = c.text\n",
    "                        no = text.split('. ')[0]\n",
    "                        title = text.split('. ')[1]\n",
    "                        link = \"https://leetcode.com/problems/\" + self.GetTitleToWebText(title) +\"/description/\"\n",
    "                    elif column == 4 :\n",
    "                        acceptance = c.text\n",
    "                    elif column == 5:\n",
    "                        difficulty = c.text\n",
    "                    elif column == 0:\n",
    "                        if no == \"2764\":\n",
    "                            writer.writerow([\"2764\", \"is-array-a-preorder-of-some-binary-tree\" ,\"https://leetcode.com/problems/is-array-a-preorder-of-some-binary-tree/description/\",\"\",\"65.9%\",\"Medium\",target_text])\n",
    "                        else:\n",
    "                            html_text = c.get_attribute(\"innerHTML\")\n",
    "                            target_text = html_text.rsplit(\"style\")[1]\n",
    "                            target_text = target_text.split(\";\")[0]\n",
    "                            target_text = target_text.replace('\"','')\n",
    "                            target_text = target_text.replace('=','')\n",
    "                            target_text = target_text.replace('width','')\n",
    "                            target_text = target_text.replace(':','')\n",
    "                            target_text = target_text.replace(' ','')\n",
    "                            writer.writerow([no, title ,link,\"\",acceptance,difficulty,target_text])\n",
    "                    i +=1\n",
    "                file.close()\n",
    "            print(self.qlno)\n",
    "            self.qlno +=1\n",
    "            self.GetQuestionList()\n",
    "              \n",
    "\n",
    "    def GetAllTagAndCompaniesList(self):\n",
    "        url = \"https://leetcode.com/problemset/\"\n",
    "        self.driver.get(url)\n",
    "        WebDriverWait(self.driver, 5).until(EC.element_to_be_clickable((By.XPATH, \"(//button[@id='headlessui-popover-button-:r5:'])[1]\"))).click()\n",
    "        WebDriverWait(self.driver, 2).until(EC.element_to_be_clickable((By.XPATH, \"(//div[@class='text-blue dark:text-dark-blue m-1 flex cursor-pointer items-center px-1'][normalize-space()='Expand'])[1]\"))).click()\n",
    "        tag_elements_parent = self.driver.find_element(by = By.XPATH, value=\"(//div[@class='-m-1 mt-1 flex max-h-[400px] flex-wrap overflow-auto py-4'])[1]\")\n",
    "        tag_elements = tag_elements_parent.find_elements(by = By.TAG_NAME, value=\"span\")\n",
    "        with open('tag.txt', 'w') as f:\n",
    "            for e in tag_elements:\n",
    "                self.tag_list.append(e.text)\n",
    "                f.write(e.text)\n",
    "                f.write('\\n')\n",
    "        f.close()\n",
    "        WebDriverWait(self.driver, 2).until(EC.element_to_be_clickable((By.XPATH, \"(//div[@class='text-sm leading-5 font-normal text-label-2 dark:text-dark-label-2'])[1]\"))).click()\n",
    "        WebDriverWait(self.driver, 2).until(EC.element_to_be_clickable((By.XPATH, \"(//div[contains(text(),'Expand')])[1]\"))).click()\n",
    "        companies_elements_parent = self.driver.find_element(by = By.XPATH, value=\"(//div[@class='-m-1 mt-1 flex max-h-[400px] flex-wrap overflow-auto py-4'])[2]\")\n",
    "        companies_elements = companies_elements_parent.find_elements(by = By.TAG_NAME, value=\"span\")\n",
    "        with open('companies.txt', 'w') as f:\n",
    "            for e in companies_elements:\n",
    "                self.companies_list.append(e.text)\n",
    "                f.write(e.text)\n",
    "                f.write('\\n')\n",
    "        f.close()\n",
    "        time.sleep(2)\n",
    "        self.GetCompaniesQuestion()\n",
    "\n",
    "    def TextToWebText(self,text):\n",
    "        if text == \"Quip (Salesforce)\":\n",
    "            return \"quip\"\n",
    "\n",
    "        if text == \"Virtu Financial\":\n",
    "            return \"virtu\"\n",
    "            \n",
    "        text = text.lower()\n",
    "        text = text.replace(' ', '-')\n",
    "        text = text.replace('.', '')\n",
    "        return text\n",
    "\n",
    "    def GetCompaniesQuestion(self):\n",
    "        dest_folder = 'Companies Leetcode'\n",
    "        if not os.path.exists(dest_folder):\n",
    "            os.makedirs(dest_folder)\n",
    "        \n",
    "        if self.cno < len(self.companies_list):\n",
    "            company_name = self.companies_list[self.ccno]\n",
    "            file_name = company_name + \".csv\"\n",
    "            file_path = os.path.join(dest_folder, file_name)\n",
    "            url = \"https://leetcode.com/company/\" + self.TextToWebText(company_name) + \"/\"\n",
    "            self.driver.get(url)\n",
    "            WebDriverWait(self.driver, 2).until(EC.element_to_be_clickable((By.XPATH, \"(//input[@type='checkbox'])[1]\"))).click()\n",
    "            WebDriverWait(self.driver, 2).until(EC.element_to_be_clickable((By.XPATH, \"(//th[normalize-space()='Frequency'])[1]\"))).click()\n",
    "            WebDriverWait(self.driver, 1).until(EC.element_to_be_clickable((By.XPATH, \"(//th[normalize-space()='Frequency'])[1]\"))).click()\n",
    "            table = self.driver.find_element(by = By.CSS_SELECTOR, value=\".reactable-data\")\n",
    "            rows = table.find_elements(by = By.TAG_NAME, value=\"tr\")\n",
    "            with open(file_path, 'w', newline='') as file:\n",
    "                writer = csv.writer(file)\n",
    "                writer.writerow([\"No\", \"Title\",\"Link\",\"Tags\",\"Acceptance\",\"Difficulty\",\"Frequency\"])\n",
    "\n",
    "                error =False\n",
    "                for r in rows:\n",
    "                    cols = r.find_elements(by = By.TAG_NAME, value=\"td\")\n",
    "                    if len(cols) == 7:\n",
    "                        no = cols[1].text\n",
    "                        title = cols[2].text\n",
    "                        url = \"https://leetcode.com/problems/\" + self.GetTitleToWebText(title) +\"/description/\"\n",
    "                        tags_list = cols[3].find_elements(by = By.TAG_NAME, value=\"a\")\n",
    "                        tags = \"\"\n",
    "                        for t in tags_list:\n",
    "                            tags = tags + \"[\" + t.text + \"]\"\n",
    "                        acceptance = cols[4].text\n",
    "                        difficulty = cols[5].text\n",
    "                        frequency = cols[6].get_attribute(\"value\")\n",
    "                        \n",
    "                        writer.writerow([no, title ,url,tags,acceptance,difficulty,frequency])\n",
    "                    else:\n",
    "                        error = True\n",
    "                file.close()\n",
    "            if error == True:\n",
    "                self.failed_list.append(company_name)\n",
    "                print(\"Data mining failed.\",company_name)\n",
    "            else:\n",
    "                print(\"Done data mining\",company_name)\n",
    "                \n",
    "            time.sleep(2)\n",
    "            self.cno += 1\n",
    "            self.GetCompaniesQuestion()\n",
    "        else:\n",
    "            self.driver.quit()\n",
    "                    \n",
    "    def InitQuestionDictList(self):\n",
    "        dir = 'Companies Leetcode'\n",
    "        filenames = [f for f in listdir(dir) if isfile(join(dir, f))]\n",
    "        for f in filenames:\n",
    "            words = f.rsplit(\".\")\n",
    "            extension = words[len(words)-1]\n",
    "            if extension ==\"csv\":\n",
    "                read_file_path = os.path.join(dir, f)\n",
    "                df = pd.read_csv(read_file_path)\n",
    "                for index, row in df.iterrows():\n",
    "                    no = str(row[\"No\"])\n",
    "                    title = str(row[\"Title\"])\n",
    "                    if no not in self.question_dict_list:\n",
    "                        self.question_dict_list[no] = title\n",
    "                        self.question_queue.append(no)\n",
    "        with open(\"question.csv\", 'w', newline='') as file:\n",
    "            writer = csv.writer(file)\n",
    "            writer.writerow([\"No\", \"Title\"])\n",
    "            for q in self.question_dict_list:\n",
    "                 writer.writerow([q, self.question_dict_list[q]])\n",
    "       \n",
    "            file.close()\n",
    "            \n",
    "    def GetQuestion(self):\n",
    "        if self.qno < len(self.question_queue):\n",
    "            key = self.question_queue[self.qno]\n",
    "            title = self.question_dict_list[key]\n",
    "            path = \"question/\" + key + \".html\"\n",
    "            url = \"https://leetcode.com/problems/\" + self.GetTitleToWebText(title) +\"/description/\"\n",
    "            self.driver.get(url)\n",
    "            time.sleep(5)\n",
    "            with open(path, 'w', encoding='utf-8') as file:\n",
    "                question_div = self.driver.find_element(by = By.CSS_SELECTOR, value=\".elfjS\")\n",
    "                content = question_div.get_attribute(\"innerHTML\")\n",
    "                file.write(content)  \n",
    "                file.close()\n",
    "            print(self.qno,\"no\",key)  \n",
    "            self.qno += 1\n",
    "            time.sleep(1)\n",
    "            self.GetQuestion()\n",
    "\n",
    "    def MergeQuestionList(self):\n",
    "         with open(\"Question List Without Tag.csv\", 'w', newline='',encoding='utf-8') as file:\n",
    "            writer = csv.writer(file)\n",
    "            writer.writerow([\"No\", \"Title\",\"Link\",\"Tags\",\"Acceptance\",\"Difficulty\",\"Frequency\"])\n",
    "            for i in range(1, 32):\n",
    "                path = \"Leetcode Overall Question List/\" + str(i) + \".csv\"\n",
    "                df = pd.read_csv(path, encoding='latin-1')\n",
    "                for index, row in df.iterrows():\n",
    "                    if i == 18:\n",
    "                        print(index)\n",
    "                    writer.writerow([str(row['No']), str(row['Title']), str(row['Link']),str(row['Tags']),str(row['Acceptance']),str(row['Difficulty']),str(row['Frequency'])])\n",
    "             \n",
    "            file.close()\n",
    "\n",
    "    def InitFindQuestionTagList(self):\n",
    "        df = pd.read_csv(\"Question List - Copy.csv\", encoding='latin-1')\n",
    "        for index, row in df.iterrows():\n",
    "            tags = str(row['Tags'])\n",
    "            if tags == \"nan\":\n",
    "                link = str(row['Link'])\n",
    "                if link not in self.find_question_tag_dict_list:\n",
    "                    self.find_question_tag_dict_list[link] = \"\"\n",
    "                    self.find_question_tag_queue.append(link)\n",
    "        print(len(self.find_question_tag_queue))\n",
    "\n",
    "    def GetTagForTheQuestion(self, file_path):\n",
    "        if self.qtno < len(self.find_question_tag_queue):\n",
    "            tag = \"\"\n",
    "            url = self.find_question_tag_queue[self.qtno]\n",
    "            self.driver.get(url)\n",
    "            try:\n",
    "                WebDriverWait(self.driver, 5).until(EC.element_to_be_clickable((By.CSS_SELECTOR, \"div[class='flex gap-1'] div:nth-child(2)\"))).click()\n",
    "                tag_elements_parent = self.driver.find_element(by = By.CSS_SELECTOR, value=\".mt-2.flex.flex-wrap.gap-1.pl-7\")\n",
    "                time.sleep(1)\n",
    "                tag_elements = tag_elements_parent.find_elements(by = By.TAG_NAME, value=\"a\")\n",
    "                for e in tag_elements:\n",
    "                    text = \"[\" + e.text + \"]\"\n",
    "                    tag += text\n",
    "                file_exists = os.path.exists(file_path)\n",
    "                if file_exists == False:\n",
    "                    with open(file_path, 'w', newline='',encoding='utf-8') as file:\n",
    "                        writer = csv.writer(file)\n",
    "                        writer.writerow([\"Link\",\"Tags\"])\n",
    "                        writer = csv.writer(file)\n",
    "                        writer.writerow([url,tag])\n",
    "                        file.close()\n",
    "                else:\n",
    "                    with open(file_path, 'a', newline='',encoding='utf-8') as file:\n",
    "                        writer = csv.writer(file)\n",
    "                        writer.writerow([url,tag])\n",
    "                        file.close()\n",
    "            except:\n",
    "                print(url,\"no tag\")\n",
    "                file_exists = os.path.exists(file_path)\n",
    "                if file_exists == False:\n",
    "                    with open(file_path, 'w', newline='',encoding='utf-8') as file:\n",
    "                        writer = csv.writer(file)\n",
    "                        writer.writerow([\"Link\",\"Tags\"])\n",
    "                        writer = csv.writer(file)\n",
    "                        writer.writerow([url,\"\"])\n",
    "                        file.close()\n",
    "                else:\n",
    "                    with open(file_path, 'a', newline='',encoding='utf-8') as file:\n",
    "                        writer = csv.writer(file)\n",
    "                        writer.writerow([url,\"\"])\n",
    "                        file.close()\n",
    "            time.sleep(1)\n",
    "            print(self.qtno) \n",
    "            self.qtno += 1\n",
    "            self.GetTagForTheQuestion(file_path)\n",
    "\n",
    "    def MergeQuestionTag(self):\n",
    "        df = pd.read_csv(\"Question Tag.csv\", encoding='latin-1')\n",
    "        for index, row in df.iterrows():\n",
    "            link = str(row['Link'])\n",
    "            if link not in self.find_question_tag_dict_list:\n",
    "                self.find_question_tag_dict_list[link] = str(row['Tags'])\n",
    "        with open(\"Question List.csv\", 'w', newline='',encoding='utf-8') as file:\n",
    "            writer = csv.writer(file)\n",
    "            writer.writerow([\"No\", \"Title\",\"Link\",\"Tags\",\"Acceptance\",\"Difficulty\",\"Frequency\"])\n",
    "            df = pd.read_csv(\"Question List - Copy.csv\", encoding='latin-1')\n",
    "            for index, row in df.iterrows():\n",
    "                link = str(row['Link'])\n",
    "                tags = str(row['Tags'])\n",
    "                if link in self.find_question_tag_dict_list:\n",
    "                    tags = self.find_question_tag_dict_list[link]\n",
    "                writer.writerow([str(row['No']), str(row['Title']), str(row['Link']),tags,str(row['Acceptance']),str(row['Difficulty']),str(row['Frequency'])])\n",
    "            file.close()\n",
    "                \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cec95d08-1c9f-4855-ac3a-335e1043bac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from seleniumbase import Driver\n",
    "from seleniumbase import page_actions\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import os\n",
    "import requests\n",
    "import time\n",
    "import csv\n",
    "import pandas as pd\n",
    "import multiprocessing \n",
    "import threading\n",
    "import random\n",
    "import concurrent.futures\n",
    "\n",
    "class Copliot:\n",
    "    def __init__(self):\n",
    "        self.driver = Driver(uc=True)\n",
    "        self.queue = []\n",
    "        self.start =0\n",
    "        self.end = 0\n",
    "        self.InitQueryList()\n",
    "\n",
    "    def InitQueryList(self):   \n",
    "        cf = open(\"tag.txt\", \"r\")\n",
    "        for c in cf:\n",
    "            c = c.replace(\"\\n\", \"\")\n",
    "            self.queue.append(c)\n",
    "        cf.close\n",
    "        self.end =len(self.queue)\n",
    "        print(self.end)\n",
    "        \n",
    "    def Login(self,id,pw):\n",
    "        url = \"https://login.live.com/\"\n",
    "        try:\n",
    "            t = random.uniform(0.0, 2.0)\n",
    "            print(t,\"\\n\")\n",
    "            time.sleep(t)\n",
    "            self.driver.get(url)\n",
    "            #time.sleep(3)\n",
    "            #id_field = self.driver.find_element(by=By.XPATH, value=\"(//input[@id='i0116'])[1]\")\n",
    "            #id_field.send_keys(id)\n",
    "            #WebDriverWait(self.driver, 1).until(EC.element_to_be_clickable((By.XPATH, \"(//button[normalize-space()='Next'])[1]\"))).click()\n",
    "            #time.sleep(2)\n",
    "            #pw_field = self.driver.find_element(by=By.XPATH, value=\"(//input[@id='i0118'])[1]\")\n",
    "            #pw_field.send_keys(pw)\n",
    "            #WebDriverWait(self.driver, 1).until(EC.element_to_be_clickable((By.XPATH, \"(//button[normalize-space()='Sign in'])[1]\"))).click()\n",
    "            #time.sleep(2)\n",
    "        except:\n",
    "            return False\n",
    "\n",
    "        return True\n",
    "        \n",
    "    def GoToCopliot(self):\n",
    "        url = \"https://www.bing.com/search?q=Bing%20AI&showconv=1&form=MG0AUO\"\n",
    "        # go 3 time to bypass the popup\n",
    "        self.driver.get(url)\n",
    "        time.sleep(2)\n",
    "        self.driver.get(url)\n",
    "        time.sleep(2)\n",
    "        return True\n",
    "\n",
    "    def QueryCopliot(self):\n",
    "        if self.start < self.end:\n",
    "            keyword = self.queue[self.start]\n",
    "            path = \"Leetcode Learning Resource/\"+keyword+\".html\"\n",
    "            url = \"https://www.bing.com/search?q=Bing%20AI&showconv=1&form=MG0AUO\"\n",
    "            query = \"what is \"+ keyword +\" in leetcode in one sentence and give me 5 reference links which I can learn for free.\" \n",
    "            dir = path.rsplit(\"/\")[0]\n",
    "            if not os.path.exists(dir):\n",
    "                os.makedirs(dir)\n",
    "            with open(path, 'w', encoding='utf-8') as file:\n",
    "                self.driver.get(url)\n",
    "                time.sleep(5)\n",
    "                dom1 = self.driver.find_element(by=By.CSS_SELECTOR, value=\".cib-serp-main\").shadow_root\n",
    "                input_shadow_dom2 = dom1.find_element(by=By.CSS_SELECTOR, value=\"#cib-action-bar-main\").shadow_root\n",
    "                input_shadow_dom3 = input_shadow_dom2.find_element(by=By.CSS_SELECTOR, value=\"cib-text-input[serp-slot='none']\").shadow_root\n",
    "                text_field = input_shadow_dom3.find_element(by=By.CSS_SELECTOR, value=\"#searchbox\")\n",
    "                text_field.send_keys(query)\n",
    "                time.sleep(1)\n",
    "                input_shadow_dom2.find_element(by=By.CSS_SELECTOR, value=\"button[aria-label='Submit']\").click()\n",
    "                time.sleep(30)\n",
    "                response_shadow_dom2 = dom1.find_element(by=By.CSS_SELECTOR, value=\"#cib-conversation-main\").shadow_root\n",
    "                response_shadow_dom3 = response_shadow_dom2.find_element(by=By.CSS_SELECTOR, value=\"cib-chat-turn[serp-slot='none']\").shadow_root\n",
    "                response_shadow_dom4 = response_shadow_dom3.find_element(by=By.CSS_SELECTOR, value=\".response-message-group\").shadow_root\n",
    "                response_shadow_dom5 = response_shadow_dom4.find_element(by=By.CSS_SELECTOR, value=\"cib-message:nth-child(2)\").shadow_root\n",
    "                response = response_shadow_dom5.find_element(by=By.CSS_SELECTOR, value=\"div[class='content']\")\n",
    "                content = response.get_attribute(\"innerHTML\")\n",
    "                file.write(content)  \n",
    "                file.close()\n",
    "                print(self.start,keyword,\"\\n\")\n",
    "            file.close()\n",
    "            self.start += 1\n",
    "            self.QueryCopliot()\n",
    "              \n",
    "\n",
    "    def CloseDriver(self):\n",
    "        print(\"run\")\n",
    "        self.driver.Quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e1889622-36b1-4d48-b17e-b7a103427db1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pypandoc\n",
    "from pypandoc.pandoc_download import download_pandoc\n",
    "import csv\n",
    "import os\n",
    "from pathlib import Path\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "class LeetcodeDataProcessing:\n",
    "    def __init__(self):\n",
    "        self.companies_list=[]\n",
    "        self.all_tags_list=[]\n",
    "        self.InitTagsList()\n",
    "        self.InitCompaniesList()\n",
    "\n",
    "    def InitTagsList(self):\n",
    "        cf = open(\"tag.txt\", \"r\")\n",
    "        for c in cf:\n",
    "            c = c.replace(\"\\n\", \"\")\n",
    "            self.all_tags_list.append(c)\n",
    "        cf.close\n",
    "\n",
    "    def GetTitleToWebText(self,text):\n",
    "        text = text.lower()\n",
    "        text = text.replace('`', '')\n",
    "        text = text.replace(\"(\", '')\n",
    "        text = text.replace(\")\", '')\n",
    "        text = text.replace(\":\", '')\n",
    "        text = text.replace(\",\", '-')\n",
    "        text = text.replace(\"'\", '')\n",
    "        text = text.replace(\"%\", '')\n",
    "        text = text.replace(\"&\", '')\n",
    "        text = text.replace(' ', '-')\n",
    "        text = re.sub(r'(-{2,})', '-', text)\n",
    "        return text\n",
    "\n",
    "    \n",
    "    def InitCompaniesList(self):\n",
    "        cf = open(\"companies.txt\", \"r\")\n",
    "        for c in cf:\n",
    "            c = c.replace(\"\\n\", \"\")\n",
    "            self.companies_list.append(c)\n",
    "        cf.close\n",
    "\n",
    "    def GenerateLeetCodeLearningResource(self):\n",
    "        html_content = \"\"\n",
    "        html_content +=\"<h1><u><b>\"\n",
    "        html_content += \"Overall Leetcode Tag Type Appear in the Question Count\"\n",
    "        html_content +=\"</b></u></h1>\\n\"\n",
    "        html_content +=\"<table>\\n\"\n",
    "        html_content +=\"<tr>\\n\"\n",
    "        html_content +=\"  <th>Tag</th>\\n\"\n",
    "        html_content +=\"  <th>Count</th>\\n\"\n",
    "        html_content +=\"</tr>\\n\"\n",
    "        df = pd.read_csv(\"Question List Tag Count.csv\")\n",
    "        for index, row in df.iterrows():\n",
    "            html_content += \"<tr>\\n\" \n",
    "            tag_html =\"  <td>\" + str(row[\"Tag\"]) + \"</td>\\n\" \n",
    "            count_html =\"  <td>\" + str(row[\"Appearance\"]) + \"</td>\\n\" \n",
    "            html_content += tag_html\n",
    "            html_content += count_html\n",
    "            html_content += \"</tr>\\n\"\n",
    "        html_content +=\"</table>\\n\"\n",
    "\n",
    "        html_content +=\"<h1><u><b>\"\n",
    "        html_content += \"Top 100 Leetcode Question Tag Type Appear in the Question Count\"\n",
    "        html_content +=\"</b></u></h1>\\n\"\n",
    "        html_content +=\"<table>\\n\"\n",
    "        html_content +=\"<tr>\\n\"\n",
    "        html_content +=\"  <th>Tag</th>\\n\"\n",
    "        html_content +=\"  <th>Count</th>\\n\"\n",
    "        html_content +=\"</tr>\\n\"\n",
    "        df = pd.read_csv(\"Top 100 Question List Tag Count.csv\")\n",
    "        for index, row in df.iterrows():\n",
    "            html_content += \"<tr>\\n\" \n",
    "            tag_html =\"  <td>\" + str(row[\"Tag\"]) + \"</td>\\n\" \n",
    "            count_html =\"  <td>\" + str(row[\"Appearance\"]) + \"</td>\\n\" \n",
    "            html_content += tag_html\n",
    "            html_content += count_html\n",
    "            html_content += \"</tr>\\n\"\n",
    "        html_content +=\"</table>\\n\"\n",
    "\n",
    "        for i in self.all_tags_list:\n",
    "            path = \"Leetcode Learning Resource/\"+i+\".html\"\n",
    "            if os.path.isfile(path) == False:\n",
    "                print(d,\"not found in\",path)\n",
    "            else:\n",
    "                with open(path, \"r\", encoding=\"utf-8\") as file:\n",
    "                    title = i\n",
    "                    html_content +=\"<h1><u><b>\"\n",
    "                    html_content += title\n",
    "                    html_content +=\"</b></u></h1>\"\n",
    "                    html_content += file.read()\n",
    "                    file.close()\n",
    "        with open(\"leetcode learning resource.html\", 'w', encoding='utf-8') as file:\n",
    "            file.write(html_content)  \n",
    "            file.close()\n",
    "        output = pypandoc.convert_text(html_content, 'docx', format='html', outputfile='leetcode learning resource.docx')\n",
    "        if output == \"\":\n",
    "            print(\"Document output sucessfully.\")\n",
    "        else:\n",
    "            print(\"Document output failed\")\n",
    "\n",
    "    def ConvertQuestionListToDataframeAndCountTag(self):\n",
    "        tag_count_dict_list = {}\n",
    "        for t in self.all_tags_list:\n",
    "            tag_count_dict_list[t] = 0\n",
    "        df = pd.read_csv(\"Question List.csv\")\n",
    "        #difficulty = pd.get_dummies(df['Difficulty']).astype(int)\n",
    "        #df = df.drop(columns=['Difficulty'])\n",
    "        #df = pd.concat([df,difficulty], axis= 1)\n",
    "        tags_header_list = []\n",
    "        for index, row in df.iterrows():\n",
    "            tags = str(row['Tags'])\n",
    "            tags = tags.replace('[', '')\n",
    "            tags_list = tags.split(']')\n",
    "            if len(tags_list) != 0 and tags_list[len(tags_list)-1]==\"\":\n",
    "                tags_list= tags_list[:-1]\n",
    "            if len(tags_list) == 0 or tags_list[0] ==\"nan\":\n",
    "                continue\n",
    "            for tag in tags_list:\n",
    "                if tag not in tags_header_list:\n",
    "                    tags_header_list.append(tag)\n",
    "                if tag in tag_count_dict_list:\n",
    "                    tag_count_dict_list[tag]+= 1\n",
    "        for tag in tags_header_list:\n",
    "            df[tag] = 0\n",
    "        df2 = df\n",
    "        for index, row in df2.iterrows():\n",
    "            tags = str(row['Tags'])\n",
    "            tags = tags.replace('[', '')\n",
    "            tags_list = tags.split(']')\n",
    "            if len(tags_list) != 0 and tags_list[len(tags_list)-1]==\"\":\n",
    "                tags_list= tags_list[:-1]\n",
    "            if len(tags_list) == 0 or tags_list[0] ==\"nan\":\n",
    "                continue\n",
    "            for tag in tags_list:\n",
    "                df.loc[index, tag] = 1\n",
    "        df = df.drop(columns=['Tags'])\n",
    "        write_file_path = \"Question List Dataframe\" + \".csv\"\n",
    "        df.to_csv(write_file_path, encoding='utf-8', index=False)\n",
    "        with open(\"Question List Tag Count\" + \".csv\", 'w', newline='') as file:\n",
    "            writer = csv.writer(file)\n",
    "            writer.writerow([\"Tag\", \"Appearance\"])\n",
    "            for s in sorted(tag_count_dict_list, key=tag_count_dict_list.get, reverse=True):\n",
    "                writer.writerow([s, tag_count_dict_list[s]])\n",
    "            file.close()\n",
    "            \n",
    "    def MakeTop100QuestionTag(self):\n",
    "        tag_count_dict_list = {}\n",
    "        for t in self.all_tags_list:\n",
    "            tag_count_dict_list[t] = 0\n",
    "        df_a = pd.read_csv(\"Question List.csv\")\n",
    "        df = df_a.head(100)\n",
    "        df.to_csv(\"Top 100 Question List.csv\", encoding='utf-8', index=False)\n",
    "        #difficulty = pd.get_dummies(df['Difficulty']).astype(int)\n",
    "        #df = df.drop(columns=['Difficulty'])\n",
    "        #df = pd.concat([df,difficulty], axis= 1)\n",
    "        tags_header_list = []\n",
    "        for index, row in df.iterrows():\n",
    "            tags = str(row['Tags'])\n",
    "            tags = tags.replace('[', '')\n",
    "            tags_list = tags.split(']')\n",
    "            if len(tags_list) != 0 and tags_list[len(tags_list)-1]==\"\":\n",
    "                tags_list= tags_list[:-1]\n",
    "            if len(tags_list) == 0 or tags_list[0] ==\"nan\":\n",
    "                continue\n",
    "            for tag in tags_list:\n",
    "                if tag not in tags_header_list:\n",
    "                    tags_header_list.append(tag)\n",
    "                if tag in tag_count_dict_list:\n",
    "                    tag_count_dict_list[tag]+= 1\n",
    "        for tag in tags_header_list:\n",
    "            df[tag] = 0\n",
    "        df2 = df\n",
    "        for index, row in df2.iterrows():\n",
    "            tags = str(row['Tags'])\n",
    "            tags = tags.replace('[', '')\n",
    "            tags_list = tags.split(']')\n",
    "            if len(tags_list) != 0 and tags_list[len(tags_list)-1]==\"\":\n",
    "                tags_list= tags_list[:-1]\n",
    "            if len(tags_list) == 0 or tags_list[0] ==\"nan\":\n",
    "                continue\n",
    "            for tag in tags_list:\n",
    "                df.loc[index, tag] = 1\n",
    "        df = df.drop(columns=['Tags'])\n",
    "        write_file_path = \"Top 100 Question List Dataframe\" + \".csv\"\n",
    "        df.to_csv(write_file_path, encoding='utf-8', index=False)\n",
    "        with open(\"Top 100 Question List Tag Count\" + \".csv\", 'w', newline='') as file:\n",
    "            writer = csv.writer(file)\n",
    "            writer.writerow([\"Tag\", \"Appearance\"])\n",
    "            for s in sorted(tag_count_dict_list, key=tag_count_dict_list.get, reverse=True):\n",
    "                writer.writerow([s, tag_count_dict_list[s]])\n",
    "            file.close()\n",
    "\n",
    "\n",
    "    def ConvertToDataframe(self):\n",
    "        dest_folder = 'Companies Leetcode DataFrame'\n",
    "        if not os.path.exists(dest_folder):\n",
    "            os.makedirs(dest_folder)\n",
    "                       \n",
    "        for c in self.companies_list:\n",
    "            read_filename = c\n",
    "            read_filename +='.csv'\n",
    "            read_file_path = os.path.join('Companies Leetcode', read_filename)\n",
    "            df = pd.read_csv(read_file_path)\n",
    "            #difficulty = pd.get_dummies(df['Difficulty']).astype(int)\n",
    "            #df = df.drop(columns=['Difficulty'])\n",
    "            #df = pd.concat([df,difficulty], axis= 1)\n",
    "            tags_header_list = []\n",
    "            for index, row in df.iterrows():\n",
    "                tags = str(row['Tags'])\n",
    "                tags = tags.replace('[', '')\n",
    "                tags_list = tags.split(']')\n",
    "                if len(tags_list) != 0 and tags_list[len(tags_list)-1]==\"\":\n",
    "                    tags_list= tags_list[:-1]\n",
    "                if len(tags_list) == 0 or tags_list[0] ==\"nan\":\n",
    "                    continue\n",
    "                for tag in tags_list:\n",
    "                    if tag not in tags_header_list:\n",
    "                        tags_header_list.append(tag)\n",
    "            for tag in tags_header_list:\n",
    "                df[tag] = 0\n",
    "            df2 = df\n",
    "            for index, row in df2.iterrows():\n",
    "                tags = str(row['Tags'])\n",
    "                tags = tags.replace('[', '')\n",
    "                tags_list = tags.split(']')\n",
    "                if len(tags_list) != 0 and tags_list[len(tags_list)-1]==\"\":\n",
    "                    tags_list= tags_list[:-1]\n",
    "                if len(tags_list) == 0 or tags_list[0] ==\"nan\":\n",
    "                    continue\n",
    "                for tag in tags_list:\n",
    "                    df.loc[index, tag] = 1\n",
    "            df = df.drop(columns=['Tags','Link'])\n",
    "            file_name = c + \".csv\"\n",
    "            write_file_path = os.path.join(dest_folder, file_name)\n",
    "            df.to_csv(write_file_path, encoding='utf-8', index=False)\n",
    "            print(c,\"file successfully converted to data frame format.\")\n",
    "\n",
    "    def MakeDocsFromHtml(self):\n",
    "        dir = 'Question'\n",
    "        filenames = [f for f in listdir(dir) if isfile(join(dir, f))]\n",
    "        for f in filenames:\n",
    "            print(f)\n",
    "            words = f.rsplit(\".\")\n",
    "            extension = words[len(words)-1]\n",
    "            if extension ==\"html\":\n",
    "                filename = f.replace(\".html\",\"\")\n",
    "                output = pypandoc.convert_file(dir + \"/\" + f, 'docx', outputfile= dir + \"/\" + filename +\".docx\")\n",
    "\n",
    " \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c098ef73-2e90-49d0-9091-a73c4db11015",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document output sucessfully.\n"
     ]
    }
   ],
   "source": [
    "test = LeetcodeDataProcessing()\n",
    "test.GenerateLeetCodeLearningResource()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "210d806a-87ec-4c75-8d55-739548d0002e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "\n",
    "class LeetcodeAnalytics:\n",
    "    def __init__(self):\n",
    "        self.model_param={\n",
    "            'LinearRegression': {\n",
    "                'model': LinearRegression(),\n",
    "                'param':{\n",
    "                    'criterion': ['gini'],\n",
    "                    'max_depth': range(2, 10),\n",
    "                    'min_samples_split': range(2,100),\n",
    "                }\n",
    "            },\n",
    "            'DecisionTreeRegressor': {\n",
    "                'model': DecisionTreeRegressor(),\n",
    "                'param': {\n",
    "                    'criterion': ['squared_error','friedman_mse'],\n",
    "                    'max_depth': range(2, 20),\n",
    "                    'min_samples_split': range(2, 50),\n",
    "                }\n",
    "            },\n",
    "            'RandomForestClassifier': {\n",
    "                'model': RandomForestClassifier(),\n",
    "                'param':{\n",
    "                    'criterion':['gini'],\n",
    "                    'max_depth': range(2, 4),\n",
    "                    'n_estimators': [10, 50, 100, 130],\n",
    "                }\n",
    "            },\n",
    "            'XGBClassifier': {\n",
    "                'model': XGBClassifier(objective='binary:logistic'),\n",
    "                'param':{\n",
    "                    'learning_rate': [0.5, 0.1, 0.01, 0.001],\n",
    "                    'max_depth': range(2, 20),\n",
    "                    'n_estimators': range(10, 100,10),\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    def FindHardestTag(self):\n",
    "       \n",
    "        df = pd.read_csv(\"Question List.csv\")\n",
    "        tags_header_list = []\n",
    "        top_dict = {}\n",
    "        for index, row in df.iterrows():\n",
    "            tags = str(row['Tags'])\n",
    "            tags = tags.replace('[', '')\n",
    "            tags_list = tags.split(']')\n",
    "            if len(tags_list) != 0 and tags_list[len(tags_list)-1]==\"\":\n",
    "                tags_list= tags_list[:-1]\n",
    "            if len(tags_list) == 0 or tags_list[0] ==\"nan\":\n",
    "                continue\n",
    "            for tag in tags_list:\n",
    "                if tag not in tags_header_list:\n",
    "                    tags_header_list.append(tag)\n",
    "        \n",
    "        df = pd.read_csv(\"Question List Dataframe.csv\")\n",
    "        df[\"Acceptance\"] = df[\"Acceptance\"].str.replace('%', '').astype(float)\n",
    "        df[\"Acceptance\"] = 100 - df[\"Acceptance\"]\n",
    "        df[\"Acceptance\"] = df[\"Acceptance\"] / 100\n",
    "        difficulty = pd.get_dummies(df['Difficulty']).astype(int)\n",
    "        #df = pd.concat([df,difficulty], axis= 1)\n",
    "        df = df.drop(columns=['No','Title','Link', 'Difficulty', 'Frequency'])\n",
    "        y = df[\"Acceptance\"]\n",
    "        df = df.drop(labels='Acceptance', axis=1)\n",
    "        df = df.astype('int64')\n",
    "        x = df\n",
    "       \n",
    "        X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=0)\n",
    "        model = LinearRegression(n_jobs=-1)\n",
    "        model.fit(X_train, y_train)\n",
    "        predictions = model.predict(X_test)\n",
    "        mae = mean_absolute_error(y_test, predictions)\n",
    "        mape = mean_absolute_percentage_error(y_test, predictions)\n",
    "        print(f'Mean Absolute Error: {mae}')\n",
    "        print(f'Mean Absolute Percent Error: {mape}')\n",
    "\n",
    "        hard_dict = {}\n",
    "        new_df = x.head(1).copy()\n",
    "        new_df.iloc[0] = 0\n",
    "        new_df = new_df.astype('int64')\n",
    "        for tag in tags_header_list:\n",
    "            new_df.iloc[0] = 0\n",
    "            new_df.at[0,tag]= 1\n",
    "            predicted_score = model.predict(new_df)\n",
    "            hard_dict[tag] = predicted_score\n",
    "\n",
    "\n",
    "        #new_df.iloc[0] = 0\n",
    "        #new_df = new_df.astype('int64')\n",
    "        #for i in range(0,2361183241434822606847):\n",
    "         #   binary_str = bin(i)\n",
    "          #  binary_digits = binary_str[2:]\n",
    "           # current_bit = len(binary_digits)\n",
    "            #current_bit -= 1\n",
    "            #c =0\n",
    "            #while current_bit > -1:\n",
    "             #   binary = int(binary_digits[current_bit])\n",
    "              #  new_df.iloc[0, c] = binary\n",
    "               # c+= 1\n",
    "                #current_bit -= 1\n",
    "           # new_df = new_df.astype('int64')\n",
    "            #predicted_score = model.predict(new_df)\n",
    "            #print(binary_digits, predicted_score)\n",
    "\n",
    "    \n",
    "        write_file_path = \"Question List Hardest Tag\" + \".csv\"\n",
    "        with open(write_file_path, 'w', newline='') as file:\n",
    "            writer = csv.writer(file)\n",
    "            writer.writerow([\"Tag\", \"Minus Acceptance rate\"])\n",
    "            for s in sorted(hard_dict, key=hard_dict.get, reverse=True):\n",
    "                #print(s, hard_dict[s])\n",
    "                writer.writerow([s, hard_dict[s]])\n",
    "            file.close()\n",
    "           \n",
    "   \n",
    "    def Analytics(self,name):\n",
    "        dest_folder = 'Leetcode Analytics'\n",
    "        if not os.path.exists(dest_folder):\n",
    "            os.makedirs(dest_folder)\n",
    "        read_filename = name\n",
    "        read_filename +='.csv'\n",
    "        read_file_path = os.path.join('Companies Leetcode', read_filename)\n",
    "        df = pd.read_csv(read_file_path)\n",
    "        tags_header_list = []\n",
    "        top_dict = {}\n",
    "        for index, row in df.iterrows():\n",
    "            tags = str(row['Tags'])\n",
    "            tags = tags.replace('[', '')\n",
    "            tags_list = tags.split(']')\n",
    "            if len(tags_list) != 0 and tags_list[len(tags_list)-1]==\"\":\n",
    "                tags_list= tags_list[:-1]\n",
    "            if len(tags_list) == 0 or tags_list[0] ==\"nan\":\n",
    "                continue\n",
    "            for tag in tags_list:\n",
    "                if tag not in tags_header_list:\n",
    "                    tags_header_list.append(tag)\n",
    "                    top_dict[tag]=0\n",
    "                top_dict[tag] += 1\n",
    "\n",
    "        print(name)\n",
    "        dest_folder = 'Top Tag'\n",
    "        if not os.path.exists(dest_folder):\n",
    "            os.makedirs(dest_folder)\n",
    "        file_name = name + \".csv\"\n",
    "        write_file_path = os.path.join(dest_folder, file_name)\n",
    "        with open(write_file_path, 'w', newline='') as file:\n",
    "            writer = csv.writer(file)\n",
    "            writer.writerow([\"Tag\", \"Appearance\"])\n",
    "            print(\"Top tag appear in the question.\")\n",
    "            for s in sorted(top_dict, key=top_dict.get, reverse=True):\n",
    "                #print(s, top_dict[s])\n",
    "                writer.writerow([s, top_dict[s]])\n",
    "            file.close()\n",
    "        top = sorted(top_dict, key=top_dict.get, reverse=True)[:5]\n",
    "        print(top)\n",
    "        read_file_path = os.path.join('Companies Leetcode DataFrame', read_filename)\n",
    "        df = pd.read_csv(read_file_path)\n",
    "        \n",
    "        if df['No'].count() <= 3:\n",
    "            print(\"\\n\")\n",
    "            return  \n",
    "        \n",
    "        df[\"Acceptance\"] = df[\"Acceptance\"].str.replace('%', '').astype(float)\n",
    "        df[\"Acceptance\"] = df[\"Acceptance\"] / 100\n",
    "        difficulty = pd.get_dummies(df['Difficulty']).astype(int)\n",
    "        #df = pd.concat([df,difficulty], axis= 1)\n",
    "        df = df.drop(columns=['Title', 'Difficulty', 'Frequency'])\n",
    "\n",
    "        #df.drop_duplicates(subset=['A', 'C'], keep=False)\n",
    "        y = df[\"Acceptance\"]\n",
    "        x = df.drop(labels='Acceptance', axis=1)\n",
    "      \n",
    "        X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=0)\n",
    "        model = LinearRegression(n_jobs=-1)\n",
    "        model.fit(X_train, y_train)\n",
    "        predictions = model.predict(X_test)\n",
    "        mae = mean_absolute_error(y_test, predictions)\n",
    "        mape = mean_absolute_percentage_error(y_test, predictions)\n",
    "        print(f'Mean Absolute Error: {mae}')\n",
    "        print(f'Mean Absolute Percent Error: {mape}')\n",
    "        column_names = df.columns\n",
    "        hard_dict = {}\n",
    "\n",
    "        for tag in tags_header_list:\n",
    "            new_df = pd.DataFrame(columns=column_names)\n",
    "            new_row = pd.Series(0, index=new_df.columns)\n",
    "            new_df = pd.concat([new_df, pd.DataFrame([new_row])], ignore_index=True)\n",
    "            new_df.at[0,tag]= 1\n",
    "            #if 'Hard' in new_df.columns:\n",
    "            #    new_df.at[0,'Hard']= 1\n",
    "            #elif 'Medium' in new_df.columns:\n",
    "            #    new_df.at[0,'Medium']= 1\n",
    "           # else:\n",
    "             #   new_df.at[0,'Easy']= 1\n",
    "                   \n",
    "            new_df = new_df.drop(labels='Acceptance', axis=1)\n",
    "            first_row = new_df.iloc[[0]]\n",
    "          \n",
    "               \n",
    "            predicted_score = model.predict(first_row)\n",
    "            hard_dict[tag] = predicted_score\n",
    "\n",
    "    \n",
    "\n",
    "        dest_folder = 'Hardest Tag'\n",
    "        if not os.path.exists(dest_folder):\n",
    "            os.makedirs(dest_folder)\n",
    "        file_name = name + \".csv\"\n",
    "        write_file_path = os.path.join(dest_folder, file_name)\n",
    "        with open(write_file_path, 'w', newline='') as file:\n",
    "            writer = csv.writer(file)\n",
    "            writer.writerow([\"Tag\", \"Acceptance rate\"])\n",
    "            print(\"Hardest tag quesion.\")\n",
    "            for s in sorted(hard_dict, key=hard_dict.get, reverse=False):\n",
    "                #print(s, hard_dict[s])\n",
    "                writer.writerow([s, hard_dict[s]])\n",
    "            file.close()\n",
    "            hardest = sorted(hard_dict, key=hard_dict.get, reverse=False)[:5]\n",
    "            print(hardest)\n",
    "        print(\"\\n\")\n",
    "\n",
    "    def AnalyticsAllLeetcode(self):\n",
    "        cf = open(\"companies.txt\", \"r\")\n",
    "        for c in cf:\n",
    "            c = c.replace(\"\\n\", \"\")\n",
    "            companies_list.append(c)\n",
    "        cf.close\n",
    "\n",
    "        for c in companies_list:\n",
    "            self.Analytics(c)\n",
    "        print(\"Done\")\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4f65019f-32b7-44c5-831e-15ebb1d19714",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error: 0.12057996962313869\n",
      "Mean Absolute Percent Error: 0.38229830825311323\n"
     ]
    }
   ],
   "source": [
    "test =LeetcodeAnalytics()\n",
    "test.FindHardestTag()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99fa6948-29c3-44f4-b9f8-a39fc06a3e24",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63aaa0ca-b88f-4100-8fe9-3f29103695a8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
