{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b9b981e-d994-41b8-81d8-8ff213a69c73",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import pandas as pd\n",
    "import pypandoc\n",
    "import csv\n",
    "import os\n",
    "import glob\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import shutil\n",
    "import zipfile\n",
    "import html2text\n",
    "import json\n",
    "import re\n",
    "from flask import Flask, send_file, request,jsonify\n",
    "from spacy.matcher import PhraseMatcher\n",
    "from skillNer.general_params import SKILL_DB\n",
    "from skillNer.skill_extractor_class import SkillExtractor\n",
    "from werkzeug.serving import run_simple\n",
    "from waitress import serve\n",
    "\n",
    "\"\"\"\n",
    "Sorry did not follow in python, all method also lower case.\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "Skill class are basically just a custom type to wrap all the data info\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "class Skill:\n",
    "\n",
    "    def __init__(self, name, keyword, groups=None):\n",
    "        filename = name\n",
    "        filename = filename.replace('/', '-')\n",
    "        filename = filename.replace(\"\\\\\", '-')\n",
    "        filename = filename + \".html\"\n",
    "        path = os.path.join(\"skill\", filename)\n",
    "        path = path.replace(\"\\\\\", '/')\n",
    "        self.resource_path = path  # for the resource path\n",
    "        self.keyword_search = keyword  # keyword for searching LLM\n",
    "        self.group_set = set()\n",
    "        if groups is not None:\n",
    "            self.UpdateGroupSet(groups)\n",
    "\n",
    "    def UpdateGroupSet(self, groups):\n",
    "        self.group_set.update(groups)\n",
    "        # print(\"skill group set updated.\")\n",
    "\n",
    "    def ChangeKeyword(self, keyword):\n",
    "        self.keyword_search = keyword\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Learning Resource Service as a an object that handle everything about generate learning resource\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "class LearningResourceService:\n",
    "    def __init__(self):\n",
    "        self.nlp = spacy.load('en_core_web_lg')\n",
    "        self.skill_extractor = SkillExtractor(self.nlp, SKILL_DB, PhraseMatcher)\n",
    "        self.skill_dict_list = {}\n",
    "        self.group_dict_list = {}\n",
    "        self.exact_match_replace_dict_list = {}\n",
    "        self.partial_match_replace_dict_list = {}\n",
    "        self.not_found_dict_list = {}\n",
    "        self.three_word_skill_classification_set = set()\n",
    "        self.two_word_skill_classification_set = set()\n",
    "        self.one_word_skill_classification_set = set()\n",
    "        self.backup_keyword_dict_list = {}\n",
    "        self.partial_search_ignore_list = [\"apache\", \"microsoft\", \"google\", \"amazon\", \"apple\", \"vmware\", \"ibm\",\n",
    "                                           \"oracle\", \"sap\"]\n",
    "        self.leetcode_list = [\"c++\", \"c\", \"c#\", \"python\", \"java\", \"javascript\", \"typescript\", \"php\", \"swift\", \"kotlin\",\n",
    "                              \"go\", \"ruby\", \"scala\", \"rust\", \"racket\"]\n",
    "        self.one_keyword_dict_list = {}\n",
    "        self.two_keyword_dict_list = {}\n",
    "        self.three_keyword_dict_list = {}\n",
    "        self.leetcode_company_dict_list = {}\n",
    "        self.leetcode_overall_frequency_dict_list = {}\n",
    "        self.AllThisWillBeRemoveOnceFinalize()\n",
    "        self.ImportClassificationSet()\n",
    "        self.ImportSkillDictList()\n",
    "        self.InitKeywordDictList()\n",
    "        self.InitLeetCodeCompanyNameDictList()\n",
    "        self.InitLeetcodeOverallFrequencyDictList()\n",
    "        self.request_queue_no = 0\n",
    "\n",
    "    \"\"\"\n",
    "    Take in any number of string,\n",
    "    lower case all word and keep only 1 space in between the word,\n",
    "    remove all the symbol,\n",
    "    except, dash which keep only if in between 2 word, \n",
    "    dot if in between 2 word and if . is the first character of the word\n",
    "    \"\"\"\n",
    "\n",
    "    @staticmethod\n",
    "    def WordPreprocessing(string_text):\n",
    "        string_text = string_text.replace(\"[\", \"\")\n",
    "        string_text = string_text.replace(\"]\", \"\")\n",
    "        string_text = string_text.replace(\"(\", \"\")\n",
    "        string_text = string_text.replace(\")\", \"\")\n",
    "        string_text = string_text.replace(\":\", \"\")\n",
    "        string_text = string_text.replace(\"*\", \"\")\n",
    "        string_text = string_text.replace(\"\\\\\", \"\")\n",
    "        string_text = string_text.replace(\"\\\"\", \"\")\n",
    "        string_text = string_text.replace(\"â€™s\", \"\")\n",
    "        string_text = string_text.replace(\"?\", \"\")\n",
    "        string_text = string_text.replace(\"!\", \"\")\n",
    "        string_text = string_text.replace(\"&\", \"\")\n",
    "        string_text = string_text.replace(\"%\", \"\")\n",
    "        string_text = string_text.replace(\"_\", \"\")\n",
    "        string_text = string_text.replace(\",\", \"\")\n",
    "        string_text = string_text.replace(\"*\", \"\")\n",
    "        string_text = string_text.replace(\"\\n\", \" \")\n",
    "        string_text = string_text.replace(\"/\", \" \")\n",
    "        string_text = re.sub(r'\\s+', ' ', string_text)\n",
    "        string_text = re.sub(r'\\s-\\s', ' ', string_text)\n",
    "        string_text = re.sub(r'\\s\\.\\s', ' ', string_text)\n",
    "        string_text = string_text.replace(\" -\", \" \")\n",
    "        string_text = string_text.replace(\"- \", \" \")\n",
    "        string_text = string_text.replace(\". \", \" \")\n",
    "        string_text = string_text.lower()\n",
    "        return string_text\n",
    "\n",
    "    \"\"\"\n",
    "    Convert HTML to text format, remove all image, link and rich text format\n",
    "    \"\"\"\n",
    "\n",
    "    def ConvertHtmlToString(self, html_text):\n",
    "        h = html2text.HTML2Text()\n",
    "        h.ignore_images = True\n",
    "        h.ignore_links = False\n",
    "        h.inline_links = True\n",
    "        h.reference_links = False\n",
    "        string_text = h.handle(html_text)\n",
    "        string_text = re.sub(r'https://\\S+', '', string_text)\n",
    "        string_text = re.sub(r'[^\\x00-\\x7F]+', '', string_text)\n",
    "        string_text = re.sub(r'\\[\\d+]\\s*', '', string_text)\n",
    "        string_text = self.WordPreprocessing(string_text)\n",
    "        return string_text\n",
    "\n",
    "    \"\"\"\n",
    "    Convert HTML to text format, keep all image and link, but remove rich text format\n",
    "    \"\"\"\n",
    "\n",
    "    @staticmethod\n",
    "    def ConvertHtmlToString2(html_text):\n",
    "        h = html2text.HTML2Text()\n",
    "        h.ignore_images = True\n",
    "        h.ignore_links = False\n",
    "        h.inline_links = False\n",
    "        h.reference_links = False\n",
    "        string_text = h.handle(html_text)\n",
    "        string_text = re.sub(r'[^\\x00-\\x7F]+', '', string_text)\n",
    "        string_text = re.sub(r'\\[\\d+]\\s*', '', string_text)\n",
    "        string_text = string_text.replace(\"**\", \"\")\n",
    "        return string_text\n",
    "\n",
    "    \"\"\"\n",
    "    Below method just how construct the skill dict list, import & export data\n",
    "    \"\"\"\n",
    "\n",
    "    def AddSkillDictList(self, name, keyword, groups=None):\n",
    "        if name not in self.skill_dict_list:\n",
    "            self.skill_dict_list[name] = Skill(name, keyword, groups)\n",
    "            if groups is not None:\n",
    "                for g in groups:\n",
    "                    if g in self.group_dict_list:\n",
    "                        self.group_dict_list.get(g).add(name)\n",
    "                    else:\n",
    "                        new_set = set()\n",
    "                        new_set.add(name)\n",
    "                        self.group_dict_list[g] = new_set\n",
    "\n",
    "        else:\n",
    "            self.skill_dict_list[name].UpdateGroupSet(groups)\n",
    "\n",
    "    def ReClassificationSkillDictList(self, name, keyword, groups):\n",
    "        search_keyword = keyword\n",
    "        if name in self.backup_keyword_dict_list:\n",
    "            search_keyword = self.backup_keyword_dict_list[name]\n",
    "        self.AddSkillDictList(name, search_keyword, groups)\n",
    "\n",
    "    def ImportClassificationSet(self):\n",
    "        file = open(\"word classification/classification words.txt\", \"r\")\n",
    "        for word in file:\n",
    "            word = word.replace(\"\\n\", \"\")\n",
    "            word_list = word.split()\n",
    "            if len(word_list) == 1:\n",
    "                self.one_word_skill_classification_set.add(word)\n",
    "            elif len(word_list) == 2:\n",
    "                self.two_word_skill_classification_set.add(word)\n",
    "            else:\n",
    "                self.three_word_skill_classification_set.add(word)\n",
    "        file.close()\n",
    "\n",
    "    def ExportSkillDictList(self):\n",
    "        file_path = \"skills.csv\"\n",
    "        with open(file_path, 'w', newline='') as file:\n",
    "            writer = csv.writer(file)\n",
    "            writer.writerow([\"Name\", \"Search Keyword\", \"Resource Path\", \"Groups\"])\n",
    "            for key, value in self.skill_dict_list.items():\n",
    "                name = key\n",
    "                search = value.keyword_search\n",
    "                path = value.resource_path\n",
    "                groups = \"\"\n",
    "\n",
    "                for g in value.group_set:\n",
    "                    groups += \"[\"\n",
    "                    groups += g\n",
    "                    groups += \"]\"\n",
    "\n",
    "                writer.writerow([name, search, path, groups])\n",
    "            file.close()\n",
    "        with open('skills.txt', 'w') as f:\n",
    "            for i in self.skill_dict_list:\n",
    "                f.write(i)\n",
    "                f.write(\"\\n\")\n",
    "            f.close()\n",
    "\n",
    "    def ImportSkillDictList(self):\n",
    "        df = pd.read_csv(\"skills.csv\")\n",
    "        for index, row in df.iterrows():\n",
    "            name = str(row['Name'])\n",
    "            keyword = str(row['Search Keyword'])\n",
    "            groups = str(row['Groups'])\n",
    "            groups_set = None\n",
    "            groups = groups.replace('[', '')\n",
    "            groups_list = groups.split(']')\n",
    "            if len(groups_list) > 0:\n",
    "                groups_list = groups_list[:-1]\n",
    "                groups_set = set()\n",
    "                for g in groups_list:\n",
    "                    groups_set.add(g)\n",
    "            # auto create group also\n",
    "            self.AddSkillDictList(name, keyword, groups_set)\n",
    "\n",
    "    def ExportGroupDictList(self):\n",
    "        file_path = \"groups.csv\"\n",
    "        with open(file_path, 'w', newline='') as file:\n",
    "            writer = csv.writer(file)\n",
    "            writer.writerow([\"Name\", \"skills\"])\n",
    "            for key, value in self.group_dict_list.items():\n",
    "                name = key\n",
    "                skills = \"\"\n",
    "                for s in value:\n",
    "                    skills += \"[\"\n",
    "                    skills += s\n",
    "                    skills += \"]\"\n",
    "                writer.writerow([name, skills])\n",
    "            file.close()\n",
    "\n",
    "    def ExportNotFoundSet(self):\n",
    "        file_path = \"not found.csv\"\n",
    "        with open(file_path, 'w', newline='') as file:\n",
    "            writer = csv.writer(file)\n",
    "            writer.writerow([\"Name\", \"Search Keyword\", \"Resource Path\"])\n",
    "            for key, value in self.not_found_dict_list.items():\n",
    "                name = key\n",
    "                search = value.keyword_search\n",
    "                path = \"skill unclassified/not tech/\" + name + \".html\"\n",
    "\n",
    "                writer.writerow([name, search, path])\n",
    "            file.close()\n",
    "\n",
    "    def InitKeywordDictList(self):\n",
    "        self.one_keyword_dict_list.clear()\n",
    "        self.two_keyword_dict_list.clear()\n",
    "        self.three_keyword_dict_list.clear()\n",
    "        for s in self.skill_dict_list:\n",
    "            words = s.split()\n",
    "            if len(words) == 1:\n",
    "                self.one_keyword_dict_list[s] = s\n",
    "            elif len(words) == 2:\n",
    "                self.two_keyword_dict_list[s] = s\n",
    "            else:\n",
    "                self.three_keyword_dict_list[s] = s\n",
    "\n",
    "    def InitLeetCodeCompanyNameDictList(self):\n",
    "        f = open(\"leetcode/companies.txt\", \"r\")\n",
    "\n",
    "        for c in f:\n",
    "            c = c.replace(\"\\n\", \"\")\n",
    "            key = c\n",
    "            key = key.lower()\n",
    "            self.leetcode_company_dict_list[key] = c\n",
    "        f.close()\n",
    "\n",
    "    def InitLeetcodeOverallFrequencyDictList(self):\n",
    "        df = pd.read_csv(\"leetcode/Question List.csv\")\n",
    "        for index, row in df.iterrows():\n",
    "            self.leetcode_overall_frequency_dict_list[str(row[\"No\"])] = str(row[\"Frequency\"])\n",
    "\n",
    "    def AllThisWillBeRemoveOnceFinalize(self):\n",
    "\n",
    "        self.exact_match_replace_dict_list[\"tdd\"] = \"testing\"\n",
    "        self.exact_match_replace_dict_list[\"webdriver\"] = \"web crawler\"\n",
    "        self.exact_match_replace_dict_list[\"vbnet\"] = \"visual basic .net\"\n",
    "        self.exact_match_replace_dict_list[\"vb.net\"] = \"visual basic .net\"\n",
    "        self.exact_match_replace_dict_list[\"vb\"] = \"visual basic\"\n",
    "        self.exact_match_replace_dict_list[\"html5\"] = \"html\"\n",
    "        self.exact_match_replace_dict_list[\"svn\"] = \"subversion\"\n",
    "        self.exact_match_replace_dict_list[\"unity3d\"] = \"unity\"\n",
    "        self.exact_match_replace_dict_list[\"mssql\"] = \"microsoft sql\"\n",
    "        self.exact_match_replace_dict_list[\"shaders\"] = \"shader\"\n",
    "        self.exact_match_replace_dict_list[\"uat\"] = \"testing\"\n",
    "        self.exact_match_replace_dict_list[\"mui\"] = \"material ui\"\n",
    "        self.exact_match_replace_dict_list[\"gui\"] = \"graphical user interface\"\n",
    "        self.exact_match_replace_dict_list[\"ui\"] = \"user interface\"\n",
    "        self.exact_match_replace_dict_list[\"aliyun\"] = \"alibaba cloud\"\n",
    "        self.exact_match_replace_dict_list[\"ali-cloud\"] = \"alibaba cloud\"\n",
    "        self.exact_match_replace_dict_list[\"asp.net mvc 5\"] = \"asp.net mvc\"\n",
    "\n",
    "        self.partial_match_replace_dict_list[\"ms\"] = \"microsoft\"\n",
    "        self.partial_match_replace_dict_list[\"db\"] = \"database\"\n",
    "\n",
    "    \"\"\"\n",
    "    not in use, this for if handle more than 1 request\n",
    "    \"\"\"\n",
    "\n",
    "    def GetRequestQueueNo(self):\n",
    "        # self.request_queue_no += 1\n",
    "        return self.request_queue_no\n",
    "\n",
    "    \"\"\"\n",
    "    This function for finding all technical term keyword from all skill the learning resource, \n",
    "    so that we can group those skill by relation.\n",
    "    \"\"\"\n",
    "\n",
    "    def FindClassificationKeyword(self):\n",
    "        directory = 'skill'\n",
    "        filenames = [f for f in listdir(directory) if isfile(join(directory, f))]\n",
    "        skillNer_dict_list = {}\n",
    "\n",
    "        for f in filenames:\n",
    "            words = f.rsplit(\".\")\n",
    "            extension = words[len(words) - 1]\n",
    "            if extension == \"html\":\n",
    "                print(f)\n",
    "                with open(directory + \"/\" + f, 'r', encoding=\"utf-8\") as file:\n",
    "                    html_content = file.read()\n",
    "                    file.close()\n",
    "                string_text = self.ConvertHtmlToString(html_content)\n",
    "\n",
    "                try:\n",
    "                    annotations = self.skill_extractor.annotate(string_text)\n",
    "                    # self.skill_extractor.describe(annotations)\n",
    "                    result = annotations[\"results\"]\n",
    "                    skill_list_1 = result[\"full_matches\"]\n",
    "                    skill_list_2 = result[\"ngram_scored\"]\n",
    "\n",
    "                    for i in range(len(skill_list_1)):\n",
    "                        info = skill_list_1[i]\n",
    "                        skill = info[\"doc_node_value\"]\n",
    "                        skill = skill.lower()\n",
    "                        if skill not in skillNer_dict_list:\n",
    "                            skillNer_dict_list[skill] = 0\n",
    "                        skillNer_dict_list[skill] += 1\n",
    "                    for i in range(len(skill_list_2)):\n",
    "                        info = skill_list_2[i]\n",
    "                        skill = info[\"doc_node_value\"]\n",
    "                        skill = skill.lower()\n",
    "                        if skill not in skillNer_dict_list:\n",
    "                            skillNer_dict_list[skill] = 0\n",
    "                        skillNer_dict_list[skill] += 1\n",
    "                except:\n",
    "                    print(f, \"error.\")\n",
    "\n",
    "        with open('word classification/skillNer word.txt', 'w', encoding=\"utf-8\") as f:\n",
    "            for s in sorted(skillNer_dict_list, key=skillNer_dict_list.get, reverse=True):\n",
    "                f.write(str(s) + \" - \" + str(skillNer_dict_list[s]))\n",
    "                f.write('\\n')\n",
    "            file.close()\n",
    "\n",
    "    \"\"\"\n",
    "    This function for classified all skill in the relation keyword.\n",
    "    \"\"\"\n",
    "\n",
    "    def SkillReClassification(self):\n",
    "        self.backup_keyword_dict_list.clear()\n",
    "        for s in self.skill_dict_list:\n",
    "            self.backup_keyword_dict_list[s] = self.skill_dict_list[s].keyword_search\n",
    "        self.skill_dict_list.clear()\n",
    "        self.group_dict_list.clear()\n",
    "        directory = 'skill'\n",
    "        filenames = [f for f in listdir(directory) if isfile(join(directory, f))]\n",
    "\n",
    "        for f in filenames:\n",
    "            words = f.rsplit(\".\")\n",
    "            extension = words[len(words) - 1]\n",
    "            if extension == \"html\":\n",
    "                print(f)\n",
    "                filename = f.replace(\".html\", \"\")\n",
    "                with open(directory + \"/\" + f, 'r', encoding=\"utf-8\") as file:\n",
    "                    html_content = file.read()\n",
    "                    file.close()\n",
    "                text_content = self.ConvertHtmlToString(html_content)\n",
    "\n",
    "                words = text_content.split()\n",
    "                have_classified = False\n",
    "                for i in range(len(words)):\n",
    "                    first_word = words[i]\n",
    "                    if first_word.endswith('.'):\n",
    "                        first_word = first_word[:-1]\n",
    "\n",
    "                    one_word = first_word\n",
    "\n",
    "                    if one_word in self.one_word_skill_classification_set:\n",
    "                        self.ReClassificationSkillDictList(filename, filename, {one_word})\n",
    "                        have_classified = True\n",
    "\n",
    "                    if i + 1 >= len(words):\n",
    "                        break\n",
    "                    second_word = words[i + 1]\n",
    "                    if second_word.endswith('.'):\n",
    "                        second_word = second_word[:-1]\n",
    "\n",
    "                    two_word = first_word + \" \" + second_word\n",
    "\n",
    "                    if two_word in self.two_word_skill_classification_set:\n",
    "                        self.ReClassificationSkillDictList(filename, filename, {two_word})\n",
    "                        have_classified = True\n",
    "\n",
    "                    if i + 2 >= len(words):\n",
    "                        break\n",
    "                    third_word = words[i + 2]\n",
    "                    if third_word.endswith('.'):\n",
    "                        third_word = third_word[:-1]\n",
    "                    three_word = first_word + \" \" + second_word + \" \" + third_word\n",
    "                    if three_word in self.three_word_skill_classification_set:\n",
    "                        self.ReClassificationSkillDictList(filename, filename, {three_word})\n",
    "                        have_classified = True\n",
    "\n",
    "                if not have_classified:\n",
    "                    self.ReClassificationSkillDictList(filename, filename + \" in tech\", {\"unknown\"})\n",
    "\n",
    "        self.InitKeywordDictList()\n",
    "        self.ExportSkillDictList()\n",
    "        self.ExportGroupDictList()\n",
    "\n",
    "    \"\"\"\n",
    "    This function for extract the technical skill in the description.\n",
    "    Two stages are used to extract the technical skill in the description,\n",
    "    the first stage are using the existing skill keyword (skill_dict_list) and do the extract matching.\n",
    "    the second stage is using spacy skillNer model to extract all the hard skill and soft skill are not in the \n",
    "    skill_dict_list\n",
    "    \"\"\"\n",
    "\n",
    "    def ExtractSkillKeyword(self, text):\n",
    "        skill_set = set()\n",
    "        text = self.WordPreprocessing(text)\n",
    "        words = text.split()\n",
    "\n",
    "        for i in range(2, len(words)):\n",
    "            search_word = words[i - 2] + \" \" + words[i - 1] + \" \" + words[i]\n",
    "            if search_word in self.three_keyword_dict_list:\n",
    "                skill_set.add(self.three_keyword_dict_list[search_word])\n",
    "        for i in range(1, len(words)):\n",
    "            search_word = words[i - 1] + \" \" + words[i]\n",
    "            if search_word in self.two_keyword_dict_list:\n",
    "                skill_set.add(self.two_keyword_dict_list[search_word])\n",
    "        for i in range(len(words)):\n",
    "            if words[i] in self.one_keyword_dict_list:\n",
    "                skill_set.add(self.one_keyword_dict_list[words[i]])\n",
    "\n",
    "        try:\n",
    "            annotations = self.skill_extractor.annotate(text)\n",
    "            # self.skill_extractor.describe(annotations)\n",
    "            result = annotations[\"results\"]\n",
    "            skill_list_1 = result[\"full_matches\"]\n",
    "            skill_list_2 = result[\"ngram_scored\"]\n",
    "\n",
    "            for i in range(len(skill_list_1)):\n",
    "                info = skill_list_1[i]\n",
    "                skill = info[\"doc_node_value\"]\n",
    "                skill = skill.lower()\n",
    "                skill = re.sub(r'\\bdatum\\b', 'data', skill)\n",
    "                skill_set.add(skill)\n",
    "            for i in range(len(skill_list_2)):\n",
    "                info = skill_list_2[i]\n",
    "                skill = info[\"doc_node_value\"]\n",
    "                skill = skill.lower()\n",
    "                skill = re.sub(r'\\bdatum\\b', 'data', skill)\n",
    "                skill_set.add(skill)\n",
    "        except:\n",
    "            print(\"skillNer error.\")\n",
    "\n",
    "        return list(skill_set)\n",
    "\n",
    "    \"\"\"\n",
    "    This function for compare both user and job description skill \n",
    "    \"\"\"\n",
    "\n",
    "    def GenerateSkillMatchScore(self, your_skill, job_skill):\n",
    "        result_dict = {\"Your Skills List\": None, \"Job Skills List\": None, \"Match Score\": None}\n",
    "        print(\"extract resume skill...\")\n",
    "        result_dict[\"Your Skills List\"] = self.ExtractSkillKeyword(your_skill)\n",
    "        print(\"extract job skill...\")\n",
    "        result_dict[\"Job Skills List\"] = self.ExtractSkillKeyword(job_skill)\n",
    "\n",
    "        match_list = []\n",
    "\n",
    "        for js in result_dict[\"Job Skills List\"]:\n",
    "            info = {\"Skill\": str(js), \"Score\": 0.0, \"Remarks\": str(\"\")}\n",
    "            if js in result_dict[\"Your Skills List\"]:\n",
    "                info[\"Score\"] = 1.0\n",
    "                info[\"Remarks\"] = \"Exact match with one of the user skill.\"\n",
    "                match_list.append(info)\n",
    "                continue\n",
    "\n",
    "            found = False\n",
    "            related_text = \"\"\n",
    "            if js in self.group_dict_list:\n",
    "                group_skill_set = self.group_dict_list[js]\n",
    "                for gss in group_skill_set:\n",
    "                    if gss in result_dict[\"Your Skills List\"]:\n",
    "                        related_text += js.title()\n",
    "                        related_text += \" is a related with \"\n",
    "                        related_text += gss.title()\n",
    "                        related_text += \", which the user have it. \"\n",
    "                        found = True\n",
    "\n",
    "            if found:\n",
    "                info[\"Score\"] = 0.5\n",
    "                info[\"Remarks\"] = related_text[:-2]\n",
    "                match_list.append(info)\n",
    "                continue\n",
    "\n",
    "            # future implement for comparing related functional user skills like mysql and oracle SQL,\n",
    "            # which both are sql will have some score point\n",
    "            # if js in self.skill_dict_list:\n",
    "            # group_skill_set = self.skill_dict_list[js]\n",
    "\n",
    "            info[\"Remarks\"] = js.title() + \" not found within the user skill.\"\n",
    "            match_list.append(info)\n",
    "\n",
    "        result_dict[\"Match Score\"] = match_list\n",
    "        return result_dict\n",
    "\n",
    "    \"\"\"\n",
    "    This function do all the necessary to generate leetcode learning content,\n",
    "    which consist frequency question from the company and\n",
    "    learning resource to learn all different type of question tag.\n",
    "    \"\"\"\n",
    "\n",
    "    def GenerateLeetcodeResource(self, company, generated_directory):\n",
    "\n",
    "        check_company = company\n",
    "        check_company = check_company.lower()\n",
    "        company_name_to_search = str(\"\")\n",
    "\n",
    "        for c in self.leetcode_company_dict_list:\n",
    "            if c == check_company:\n",
    "                company_name_to_search = self.leetcode_company_dict_list[c]\n",
    "                break\n",
    "\n",
    "        if company_name_to_search == \"\":\n",
    "            file_to_open = \"leetcode/Top 100 Question List.csv\"\n",
    "            if os.path.exists(file_to_open):\n",
    "                df = pd.read_csv(file_to_open)\n",
    "                df[company + \" Company Frequency\"] = 0\n",
    "                df[\"Overall Frequency\"] = df[\"Frequency\"]\n",
    "                df = df.drop(columns=['Frequency'])\n",
    "                df.to_csv(\"output/\" + generated_directory + \"/leetcode question list.csv\", encoding='utf-8',\n",
    "                          index=False)\n",
    "            else:\n",
    "                return \"IF BLOCK - Generate leetcode question list failed.\"\n",
    "            try:\n",
    "                shutil.copyfile(\"leetcode/leetcode learning resource.html\", \"output/\" + generated_directory +\n",
    "                                \"/leetcode learning resource.html\")\n",
    "            except:\n",
    "                return \"IF BLOCK - Generate leetcode learning resource.html failed.\"\n",
    "        else:\n",
    "            file_to_open = \"company-leetcode-question-list/\" + company_name_to_search + \".csv\"\n",
    "            if os.path.exists(file_to_open):\n",
    "                df1 = pd.read_csv(file_to_open)\n",
    "                df1[company + \" Company Frequency\"] = df1[\"Frequency\"]\n",
    "                df1 = df1.drop(columns=['Frequency'])\n",
    "                df1[\"Overall Frequency\"] = str(\"\")\n",
    "                for index, row in df1.iterrows():\n",
    "                    no = str(row['No'])\n",
    "                    if no in self.leetcode_overall_frequency_dict_list:\n",
    "                        df1.at[index, \"Overall Frequency\"] = self.leetcode_overall_frequency_dict_list[no]\n",
    "            else:\n",
    "                return file_to_open + \"not exist.\"\n",
    "\n",
    "            file_to_open = \"leetcode/Top 100 Question List.csv\"\n",
    "            if os.path.exists(file_to_open):\n",
    "                df = pd.read_csv(file_to_open)\n",
    "                df[company + \" Company Frequency\"] = 0\n",
    "                df[\"Overall Frequency\"] = df['Frequency']\n",
    "                df = df.drop(columns=['Frequency'])\n",
    "                appended_df = pd.concat([df1, df], ignore_index=True)\n",
    "                appended_df = appended_df.drop_duplicates(keep='first')\n",
    "                final_df = appended_df.head(100).copy()\n",
    "                final_df.to_csv(\"output/\" + generated_directory + \"/leetcode question list.csv\", encoding='utf-8',\n",
    "                                index=False)\n",
    "            else:\n",
    "                return file_to_open + \" not exist.\"\n",
    "\n",
    "            file_to_open = \"company-leetcode-question-tag-count/\" + company_name_to_search + \".csv\"\n",
    "            if os.path.exists(file_to_open):\n",
    "                df = pd.read_csv(file_to_open)\n",
    "                html_content = \"\"\n",
    "                title = \"<h1><u><b>\" + company + \" Leetcode Tag Type Appear in the Question Count</b></u></h1>\\n\"\n",
    "                html_content += title\n",
    "                html_content += \"<table>\\n\"\n",
    "                html_content += \"<tr>\\n\"\n",
    "                html_content += \"  <th>Tag</th>\\n\"\n",
    "                html_content += \"  <th>Count</th>\\n\"\n",
    "                html_content += \"</tr>\\n\"\n",
    "                for index, row in df.iterrows():\n",
    "                    html_content += \"<tr>\\n\"\n",
    "                    tag_html = \"  <td>\" + str(row[\"Tag\"]) + \"</td>\\n\"\n",
    "                    count_html = \"  <td>\" + str(row[\"Appearance\"]) + \"</td>\\n\"\n",
    "                    html_content += tag_html\n",
    "                    html_content += count_html\n",
    "                    html_content += \"</tr>\\n\"\n",
    "                html_content += \"</table>\\n\"\n",
    "                file_to_open = \"leetcode/leetcode learning resource.html\"\n",
    "                if os.path.exists(file_to_open):\n",
    "                    with open(file_to_open, \"r\", encoding=\"utf-8\") as file:\n",
    "                        html_content += file.read()\n",
    "                        file.close()\n",
    "                    with (open(\"output/\" + generated_directory + \"/leetcode learning resource.html\", 'w',\n",
    "                               encoding='utf-8') as file):\n",
    "                        file.write(html_content)\n",
    "                        file.close()\n",
    "                else:\n",
    "                    return \"ELSE BLOCK - in reading leetcode resource.html error.\"\n",
    "            else:\n",
    "                return file_to_open + \" not exist.\"\n",
    "            return \"Getting leetcode resource successfully.\"\n",
    "\n",
    "    \"\"\"\n",
    "    This method is generate the skill learning resource which the job description required and the user did not \n",
    "    have the skill.\n",
    "    It chopped up 3 stages, preprocessing which consist (filter and search) and generate the skill learning resource\n",
    "    content.\n",
    "    \"\"\"\n",
    "\n",
    "    def GenerateSkillResource(self, skills, generated_directory):\n",
    "        result_dict = {\"Skill Learning Resource Content\": None, \"Skill Learning Resource Remarks\": None}\n",
    "        remarks_list = []\n",
    "        remarks, document_prepare_set = self.GenerateSkillResourcePreProcessing(skills)\n",
    "        remarks_list.extend(remarks)\n",
    "        if len(document_prepare_set) == 0:\n",
    "            return result_dict\n",
    "\n",
    "        remarks, result_dict[\"Skill Learning Resource Content\"] = (\n",
    "            self.GenerateSkillResourceContent(document_prepare_set, generated_directory))\n",
    "        remarks_list.extend(remarks)\n",
    "        result_dict[\"Skill Learning Resource Remarks\"] = remarks_list\n",
    "        return result_dict\n",
    "\n",
    "    def GenerateSkillResourcePreProcessing(self, skills):\n",
    "        document_prepare_set = set()\n",
    "        remarks_list = []\n",
    "        for key, value in skills.items():\n",
    "            remarks, skills[key] = self.SkillLearningResourceFilter(key, value)\n",
    "            remarks_list.extend(remarks)\n",
    "            if skills[key] != \"\":\n",
    "                remarks, document_prepare_set = self.SkillLearningResourceSearch(key, skills[key], document_prepare_set)\n",
    "                remarks_list.extend(remarks)\n",
    "        return remarks_list, document_prepare_set\n",
    "\n",
    "    def SkillLearningResourceFilter(self, key, text):\n",
    "        remark_list = []\n",
    "        text = text.lower()\n",
    "        text = text.replace(\"/\", \" \")\n",
    "        if text.find('(') != -1:\n",
    "            text = text.split(\"(\")[0]\n",
    "            text = text.rsplit()[0]\n",
    "\n",
    "        if text in self.exact_match_replace_dict_list:\n",
    "            text = self.exact_match_replace_dict_list.get(text)\n",
    "        words = text.split()\n",
    "        new_text = \"\"\n",
    "        for word in words:\n",
    "            if word in self.partial_match_replace_dict_list:\n",
    "                new_text += self.partial_match_replace_dict_list.get(word)\n",
    "                new_text += \" \"\n",
    "            else:\n",
    "                new_text += word\n",
    "                new_text += \" \"\n",
    "        new_text = new_text[:-1]\n",
    "        lower_key = key.lower()\n",
    "        if lower_key != new_text:\n",
    "            remark_list.append(key.title() + \"also known as \" + new_text.title())\n",
    "        return remark_list, new_text\n",
    "\n",
    "    def SkillLearningResourceSearch(self, key, text, document_prepare_set):\n",
    "        remark_list = []\n",
    "        if text in self.skill_dict_list:\n",
    "            document_prepare_set.add(text)\n",
    "            return remark_list, document_prepare_set\n",
    "\n",
    "        # check for . - space and .js\n",
    "        for sdl in self.skill_dict_list:\n",
    "\n",
    "            check1 = sdl\n",
    "            check1 = re.sub(r'\\b(\\w+)s\\b', r'\\1', check1)\n",
    "            check2 = text\n",
    "            check2 = re.sub(r'\\b(\\w+)s\\b', r'\\1', check2)\n",
    "            if check1 == check2:\n",
    "                document_prepare_set.add(sdl)\n",
    "                return remark_list, document_prepare_set\n",
    "            check1 = sdl\n",
    "            check1 = check1.replace(\".\", \"\")\n",
    "            check2 = text\n",
    "            check2 = check2.replace(\".\", \"\")\n",
    "            if check1 == check2:\n",
    "                document_prepare_set.add(sdl)\n",
    "                return remark_list, document_prepare_set\n",
    "            check1 = sdl\n",
    "            check1 = check1.replace(\"-\", \" \")\n",
    "            check2 = text\n",
    "            check2 = check2.replace(\"-\", \" \")\n",
    "            if check1 == check2:\n",
    "                document_prepare_set.add(sdl)\n",
    "                return remark_list, document_prepare_set\n",
    "            check1 = sdl\n",
    "            check1 = check1.replace(\" \", \"\")\n",
    "            check2 = text\n",
    "            check2 = check2.replace(\" \", \"\")\n",
    "            if check1 == check2:\n",
    "                document_prepare_set.add(sdl)\n",
    "                return remark_list, document_prepare_set\n",
    "            check1 = sdl\n",
    "            check1 = check1.replace(\".js\", \"\")\n",
    "            check1 = check1.replace(\"js\", \"\")\n",
    "            check2 = text\n",
    "            check2 = check2.replace(\".js\", \"\")\n",
    "            check2 = check2.replace(\"js\", \"\")\n",
    "            if check1 == check2:\n",
    "                document_prepare_set.add(sdl)\n",
    "                return remark_list, document_prepare_set\n",
    "\n",
    "        found = False\n",
    "        words = text.split()\n",
    "        # check word by word\n",
    "        for word in words:\n",
    "            if word not in self.partial_search_ignore_list:\n",
    "                if word in self.skill_dict_list:\n",
    "                    document_prepare_set.add(word)\n",
    "                    remark_list.append(key.title() + \" also known as \" + word.title())\n",
    "                    found = True\n",
    "\n",
    "        if not found:\n",
    "            remark_list.append(key.title() + \" not found in learning resource database.\")\n",
    "        return remark_list, document_prepare_set\n",
    "\n",
    "    def GenerateSkillResourceContent(self, document_prepare_set, generated_directory):\n",
    "        skill_dict = {}\n",
    "        html_content = \"\"\n",
    "        remark_list = []\n",
    "        for d in document_prepare_set:\n",
    "            if d in self.skill_dict_list:\n",
    "                v = self.skill_dict_list.get(d)\n",
    "                path = v.resource_path\n",
    "            else:\n",
    "                continue\n",
    "            if not os.path.isfile(path):\n",
    "                remark_list.append(d.title() + \" not found in learning resource database.\")\n",
    "            else:\n",
    "                with open(path, \"r\", encoding=\"utf-8\") as file:\n",
    "                    title = d.title()\n",
    "                    html_content += \"<h1><u><b>\"\n",
    "                    html_content += title\n",
    "                    html_content += \"</b></u></h1>\"\n",
    "                    file_content = file.read()\n",
    "                    html_content += file_content\n",
    "                    skill_dict[title] = self.ConvertHtmlToString2(file_content)\n",
    "                file.close()\n",
    "        with open(\"output/\" + generated_directory + \"/skill learning resource.html\", 'w',\n",
    "                  encoding='utf-8') as file:\n",
    "            file.write(html_content)\n",
    "            file.close()\n",
    "\n",
    "        return remark_list, skill_dict\n",
    "\n",
    "    \"\"\"\n",
    "    This method to zip all the file and ready to send to the user\n",
    "    \"\"\"\n",
    "\n",
    "    @staticmethod\n",
    "    def ZipLearningResource(generated_directory):\n",
    "        directory_path = \"output/\" + generated_directory\n",
    "        zip_filename = \"output/\" + generated_directory + \"/learning resource.zip\"\n",
    "        valid_extensions = ('.html', '.docx', '.csv', '.json')\n",
    "\n",
    "        with zipfile.ZipFile(zip_filename, 'w') as zipf:\n",
    "            for folder_name, sub_folders, filenames in os.walk(directory_path):\n",
    "                for filename in filenames:\n",
    "                    if filename.endswith(valid_extensions):\n",
    "                        file_path = os.path.join(folder_name, filename)\n",
    "                        zipf.write(file_path, arcname=filename)\n",
    "\n",
    "    \"\"\"\n",
    "    The main function which the user will call from the flask.\n",
    "    \"\"\"\n",
    "\n",
    "    def GenerateLearningResource(self, resume, job_description, company_name, generated_directory):\n",
    "\n",
    "        result_dict = {\"Skill Learning Resource Content\": None,\n",
    "                       \"Leetcode Question List\": None,\n",
    "                       \"Leetcode Learning Resource Content\": None}\n",
    "\n",
    "        debug_list = {\"Skill Learning Resource Remarks\": None,\n",
    "                      \"Match Score\": None}\n",
    "\n",
    "        if not os.path.exists(\"output\"):\n",
    "            os.makedirs(\"output\")\n",
    "        if not os.path.exists(\"output/\" + generated_directory):\n",
    "            os.makedirs(\"output/\" + generated_directory)\n",
    "\n",
    "        # Path to the specific folder\n",
    "        folder_path = \"output/\" + generated_directory\n",
    "\n",
    "        # List all files in the folder\n",
    "        files = glob.glob(folder_path + '/*')\n",
    "\n",
    "        # Loop through the list and delete each file\n",
    "        for f in files:\n",
    "            try:\n",
    "                os.remove(f)\n",
    "            except OSError as e:\n",
    "                print(f\"Error: {f} : {e.strerror}\")\n",
    "\n",
    "        result = self.GenerateSkillMatchScore(resume, job_description)\n",
    "\n",
    "        job_skills = result[\"Job Skills List\"]\n",
    "        debug_list[\"Match Score\"] = result[\"Match Score\"]\n",
    "\n",
    "        ms_list = result[\"Match Score\"]\n",
    "        difference_skill_dict_list = {}\n",
    "        for i in range(len(ms_list)):\n",
    "            info = ms_list[i]\n",
    "            if info[\"Score\"] != 1:\n",
    "                key = info[\"Skill\"]\n",
    "                difference_skill_dict_list[key] = key\n",
    "\n",
    "        if len(difference_skill_dict_list) != 0:\n",
    "            print(\"Getting skill learning resource..\")\n",
    "            skill_result_dict = self.GenerateSkillResource(difference_skill_dict_list, generated_directory)\n",
    "            result_dict[\"Skill Learning Resource Content\"] = skill_result_dict[\"Skill Learning Resource Content\"]\n",
    "            debug_list[\"Skill Learning Resource Remarks\"] = skill_result_dict[\"Skill Learning Resource Remarks\"]\n",
    "\n",
    "        for i in range(len(job_skills)):\n",
    "            text = job_skills[i]\n",
    "            text = text.lower()\n",
    "            if text in self.leetcode_list:\n",
    "                print(\"Getting leetcode learning resource..\")\n",
    "                debug_result = self.GenerateLeetcodeResource(company_name, generated_directory)\n",
    "                if debug_result != \"Getting leetcode resource successfully.\":\n",
    "                    return debug_result\n",
    "                file_to_open = \"output/\" + generated_directory + \"/leetcode question list.csv\"\n",
    "                if os.path.exists(file_to_open):\n",
    "                    with open(file_to_open, mode='r') as infile:\n",
    "                        reader = csv.DictReader(infile)\n",
    "                        result_dict[\"Leetcode Question List\"] = [row for row in reader]\n",
    "\n",
    "                file_to_open = \"output/\" + generated_directory + \"/leetcode learning resource.html\"\n",
    "                if os.path.exists(file_to_open):\n",
    "                    with open(file_to_open, mode='r', encoding=\"utf-8\") as file:\n",
    "                        html_content = file.read()\n",
    "                        result_dict[\"Leetcode Learning Resource Content\"] = self.ConvertHtmlToString2(html_content)\n",
    "                break\n",
    "\n",
    "        filename = \"output/\" + generated_directory + \"/debug.json\"\n",
    "        with open(filename, 'w') as file:\n",
    "            json.dump(debug_list, file, indent=4)\n",
    "\n",
    "        return \"success\", result_dict\n",
    "\n",
    "    def DownloadSkillResourceContent(self, generated_directory, docx_format):\n",
    "        if docx_format:\n",
    "            file_to_open = \"output/\" + generated_directory + \"/skill learning resource.html\"\n",
    "            if os.path.exists(file_to_open):\n",
    "                with open(file_to_open, mode='r', encoding=\"utf-8\") as file:\n",
    "                    html_content = file.read()\n",
    "                    pypandoc.convert_text(html_content, 'docx', format='html',\n",
    "                                          outputfile=\"output/\" + generated_directory + \"/skill learning resource.docx\")\n",
    "\n",
    "            file_to_open = \"output/\" + generated_directory + \"/leetcode learning resource.html\"\n",
    "            if os.path.exists(file_to_open):\n",
    "                with open(file_to_open, mode='r', encoding=\"utf-8\") as file:\n",
    "                    html_content = file.read()\n",
    "                    pypandoc.convert_text(html_content, 'docx', format='html',\n",
    "                                          outputfile=\"output/\" + generated_directory\n",
    "                                                     + \"/leetcode learning resource.docx\")\n",
    "\n",
    "        self.ZipLearningResource(generated_directory)\n",
    "\n",
    "\n",
    "app = Flask(__name__)\n",
    "learning_resource = LearningResourceService()\n",
    "\n",
    "\n",
    "# learning_resource.SkillReClassification()\n",
    "\n",
    "\n",
    "# @app.route('/generate_learning_resource', methods=['GET'])\n",
    "@app.route('/generate_learning_resource_text_format')\n",
    "def generate_learning_resource_text_format():\n",
    "    print(\"triggered\")\n",
    "\n",
    "    resume_sample = \"\"\"\n",
    "\n",
    "Programming languages: C/C++, C#, Java, Python, Groovy, JavaScript, Typescript\n",
    "Frameworks & Lib: .NET, Spring, Angular, Cuda, Imgui, WPF, OpenGL, Vulkan, Nvidia PhysX, Pandas, NumPy,\n",
    "Scikit learn, Spacy, NLTK, PySpark, Seaborn, Matplotlib, Selenium Base, Junit, PyTest, streamlit, transformers,\n",
    "PyTorch, xgboost, restful\n",
    "Databases: MS SQL, MySQL, JPA, Cassandra, SQLite, Neo4j\n",
    "Cloud: Azure, AWS\n",
    "Platform: Window, Linux, Ubuntu, Databricks\n",
    "Game Engine: Unreal Engine, Unity\n",
    "Web Development: HTML, CSS\n",
    "IDE:VS Code, IntelliJ, Anaconda, Pycharm\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    job_description_sample = \"\"\"\n",
    "    Responsibilities:\\nCollaborate with business stakeholders to understand their data needs and objectives.\\n\n",
    "    Collect, clean, and preprocess data from various sources for analysis.\\n\n",
    "    Perform exploratory data analysis to identify trends, patterns, and correlations.\\n\n",
    "    Develop and implement predictive models and machine learning algorithms to solve business challenges.\\n\n",
    "    Apply statistical analysis techniques to analyze complex datasets and draw meaningful conclusions.\\n\n",
    "    Create data visualizations and reports to communicate insights effectively to non-technical audiences.\\n\n",
    "    Collaborate with data engineers to optimize data pipelines for efficient data processing.\\n\n",
    "    Conduct A/B testing and experimentation to evaluate the effectiveness of different strategies.\\n\n",
    "    Stay up-to-date with advancements in data science, machine learning, and artificial intelligence.\\n\n",
    "    Assist in the development and deployment of machine learning models into production environments.\\n\n",
    "    Provide data-driven insights and recommendations to support strategic decision-making.\\n\n",
    "    Collaborate with other data scientists, analysts, and cross-functional teams to drive data initiatives.\\n\n",
    "    Requirements:\\n\n",
    "    Bachelor's degree in Data Science, Computer Science, Statistics, Mathematics, or a related field \n",
    "    (or equivalent practical experience).\\n\n",
    "    Proven experience as a Data Scientist or similar role, with a portfolio of data science projects that \n",
    "    demonstrate your analytical skills.\\n\n",
    "    Proficiency in programming languages such as Python or R for data manipulation and analysis.\\n\n",
    "    Strong understanding of statistical analysis, machine learning algorithms, and data visualization techniques.\\n\n",
    "    Experience with machine learning frameworks and libraries (e.g., scikit-learn, TensorFlow, PyTorch).\\n\n",
    "    Familiarity with data manipulation libraries (e.g., Pandas, NumPy) and data visualization tools (e.g.,\n",
    "     Matplotlib, Seaborn).\\nSolid understanding of SQL and database concepts for querying and extracting data.\\n\n",
    "     Excellent problem-solving skills and the ability to work with complex, unstructured datasets.\\n\n",
    "     Effective communication skills to explain technical concepts to non-technical stakeholders.\\n\n",
    "     Experience with big data technologies (e.g., Hadoop, Spark) is a plus.\\n\n",
    "     Knowledge of cloud platforms and services for data analysis (e.g., AWS, Azure) is advantageous.\\n\n",
    "     Familiarity with natural language processing (NLP) and text analysis is a plus.\\n\n",
    "     Advanced degree (Master's or PhD) in a related field is beneficial but not required.\n",
    "    \"\"\"\n",
    "    company_sample = \"JPMorgan\"\n",
    "\n",
    "    resume = request.args.get('param1', default=None, type=str)\n",
    "    job_description = request.args.get('param2', default=None, type=str)\n",
    "    company = request.args.get('param3', default=None, type=str)\n",
    "\n",
    "    if resume is None:\n",
    "        resume = resume_sample\n",
    "\n",
    "    if job_description is None:\n",
    "        job_description = job_description_sample\n",
    "\n",
    "    if company is None:\n",
    "        company = company_sample\n",
    "\n",
    "    generated_directory = str(learning_resource.GetRequestQueueNo())\n",
    "    result, learning_resource_content = learning_resource.GenerateLearningResource(resume, job_description, company,\n",
    "                                                                                   generated_directory)\n",
    "    if result != \"success\":\n",
    "        return result\n",
    "\n",
    "    return jsonify(learning_resource_content)\n",
    "\n",
    "\n",
    "@app.route('/generate_learning_resource_html_format')\n",
    "def generate_learning_resource_html_format():\n",
    "    print(\"triggered\")\n",
    "\n",
    "    resume_sample = \"\"\"\n",
    "\n",
    "Programming languages: C/C++, C#, Java, Python, Groovy, JavaScript, Typescript\n",
    "Frameworks & Lib: .NET, Spring, Angular, Cuda, Imgui, WPF, OpenGL, Vulkan, Nvidia PhysX, Pandas, NumPy,\n",
    "Scikit learn, Spacy, NLTK, PySpark, Seaborn, Matplotlib, Selenium Base, Junit, PyTest, streamlit, transformers,\n",
    "PyTorch, xgboost, restful\n",
    "Databases: MS SQL, MySQL, JPA, Cassandra, SQLite, Neo4j\n",
    "Cloud: Azure, AWS\n",
    "Platform: Window, Linux, Ubuntu, Databricks\n",
    "Game Engine: Unreal Engine, Unity\n",
    "Web Development: HTML, CSS\n",
    "IDE:VS Code, IntelliJ, Anaconda, Pycharm\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    job_description_sample = \"\"\"\n",
    "    Responsibilities:\\nCollaborate with business stakeholders to understand their data needs and objectives.\\n\n",
    "    Collect, clean, and preprocess data from various sources for analysis.\\n\n",
    "    Perform exploratory data analysis to identify trends, patterns, and correlations.\\n\n",
    "    Develop and implement predictive models and machine learning algorithms to solve business challenges.\\n\n",
    "    Apply statistical analysis techniques to analyze complex datasets and draw meaningful conclusions.\\n\n",
    "    Create data visualizations and reports to communicate insights effectively to non-technical audiences.\\n\n",
    "    Collaborate with data engineers to optimize data pipelines for efficient data processing.\\n\n",
    "    Conduct A/B testing and experimentation to evaluate the effectiveness of different strategies.\\n\n",
    "    Stay up-to-date with advancements in data science, machine learning, and artificial intelligence.\\n\n",
    "    Assist in the development and deployment of machine learning models into production environments.\\n\n",
    "    Provide data-driven insights and recommendations to support strategic decision-making.\\n\n",
    "    Collaborate with other data scientists, analysts, and cross-functional teams to drive data initiatives.\\n\n",
    "    Requirements:\\n\n",
    "    Bachelor's degree in Data Science, Computer Science, Statistics, Mathematics, or a related field \n",
    "    (or equivalent practical experience).\\n\n",
    "    Proven experience as a Data Scientist or similar role, with a portfolio of data science projects that \n",
    "    demonstrate your analytical skills.\\n\n",
    "    Proficiency in programming languages such as Python or R for data manipulation and analysis.\\n\n",
    "    Strong understanding of statistical analysis, machine learning algorithms, and data visualization techniques.\\n\n",
    "    Experience with machine learning frameworks and libraries (e.g., scikit-learn, TensorFlow, PyTorch).\\n\n",
    "    Familiarity with data manipulation libraries (e.g., Pandas, NumPy) and data visualization tools (e.g.,\n",
    "     Matplotlib, Seaborn).\\nSolid understanding of SQL and database concepts for querying and extracting data.\\n\n",
    "     Excellent problem-solving skills and the ability to work with complex, unstructured datasets.\\n\n",
    "     Effective communication skills to explain technical concepts to non-technical stakeholders.\\n\n",
    "     Experience with big data technologies (e.g., Hadoop, Spark) is a plus.\\n\n",
    "     Knowledge of cloud platforms and services for data analysis (e.g., AWS, Azure) is advantageous.\\n\n",
    "     Familiarity with natural language processing (NLP) and text analysis is a plus.\\n\n",
    "     Advanced degree (Master's or PhD) in a related field is beneficial but not required.\n",
    "    \"\"\"\n",
    "    company_sample = \"JPMorgan\"\n",
    "\n",
    "    resume = request.args.get('param1', default=None, type=str)\n",
    "    job_description = request.args.get('param2', default=None, type=str)\n",
    "    company = request.args.get('param3', default=None, type=str)\n",
    "\n",
    "    if resume is None:\n",
    "        resume = resume_sample\n",
    "\n",
    "    if job_description is None:\n",
    "        job_description = job_description_sample\n",
    "\n",
    "    if company is None:\n",
    "        company = company_sample\n",
    "\n",
    "    generated_directory = str(learning_resource.GetRequestQueueNo())\n",
    "    result, learning_resource_content = learning_resource.GenerateLearningResource(resume, job_description, company,\n",
    "                                                                                   generated_directory)\n",
    "    if result != \"success\":\n",
    "        return result\n",
    "\n",
    "    html_content = \"\"\n",
    "    file_to_open = \"output/\" + generated_directory + \"/skill learning resource.html\"\n",
    "    if os.path.exists(file_to_open):\n",
    "        with open(file_to_open, \"r\", encoding=\"utf-8\") as file:\n",
    "            html_content = file.read()\n",
    "\n",
    "    file_to_open = \"output/\" + generated_directory + \"/leetcode question list.csv\"\n",
    "    if os.path.exists(file_to_open):\n",
    "        df = pd.read_csv(file_to_open)\n",
    "        html_content += \"<h1><u><b>\"\n",
    "        html_content += company\n",
    "        html_content += \" 100 Leetcode QuestionList</b></u></h1>\"\n",
    "        html_content += df.to_html()\n",
    "\n",
    "    file_to_open = \"output/\" + generated_directory + \"/leetcode learning resource.html\"\n",
    "    if os.path.exists(file_to_open):\n",
    "        with open(file_to_open, \"r\", encoding=\"utf-8\") as file:\n",
    "            html_content += file.read()\n",
    "\n",
    "    return html_content\n",
    "\n",
    "\n",
    "@app.route('/download_learning_resource')\n",
    "def download_learning_resource():\n",
    "    with_docx_format = request.args.get('param1', default=None, type=str)\n",
    "    if with_docx_format is None:\n",
    "        with_docx_format = False\n",
    "\n",
    "    generated_directory = str(learning_resource.GetRequestQueueNo())\n",
    "    learning_resource.DownloadSkillResourceContent(generated_directory, True)\n",
    "    learning_resource_zip_path = \"output/\" + generated_directory + \"/learning resource.zip\"\n",
    "    return send_file(learning_resource_zip_path, as_attachment=True, download_name='learning resource.zip')\n",
    "\n",
    "\n",
    "@app.route(\"/ping\")\n",
    "def ping():\n",
    "    return 'ping'\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    serve(app, host='0.0.0.0', port=5000)\n",
    "    # run_simple('localhost', 5000, app)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b2819df6-722a-4d9e-ba0e-bc56fca7a474",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DeltaGenerator()"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "import streamlit as st\n",
    "\n",
    "# Define the base URL of your Flask app\n",
    "base_url = 'http://144.126.241.79/learning_resource'\n",
    "\n",
    "# Define the route endpoint and parameters\n",
    "route = '/generate_learning_resource_html_format'\n",
    "params = {\n",
    "    'param1': 'python',\n",
    "    'param2': None,\n",
    "    'param3': 'microsoft'\n",
    "}\n",
    "\n",
    "# Make a GET request to the Flask route with the parameters\n",
    "response = requests.get(f\"{base_url}{route}\", params=params)\n",
    "\n",
    "# Print the response text (or process it in another way)\n",
    "st.markdown(response.text, unsafe_allow_html=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b6c426e-98d9-485d-9795-73d5de1a2cf9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
