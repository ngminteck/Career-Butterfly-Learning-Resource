{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b9b981e-d994-41b8-81d8-8ff213a69c73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading full_matcher ...\n",
      "loading abv_matcher ...\n",
      "loading full_uni_matcher ...\n",
      "loading low_form_matcher ...\n",
      "loading token_matcher ...\n",
      ".net core.html\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ng_mi\\anaconda3\\lib\\site-packages\\skillNer\\utils.py:99: UserWarning: [W008] Evaluating Token.similarity based on empty vectors.\n",
      "  vec_similarity = token1.similarity(token2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".net maui.html\n",
      ".net.html\n",
      "abstraction.html\n",
      "access control.html\n",
      "accumulo.html\n",
      "acronis cyber protect.html\n",
      "activemq.html\n",
      "activiti.html\n",
      "actors.html\n",
      "ada.html\n",
      "adapter.html\n",
      "adf.html\n",
      "ado.net.html\n",
      "aerospike.html\n",
      "afnetworking.html\n",
      "agile.html\n",
      "aiops.html\n",
      "airavata.html\n",
      "airflow.html\n",
      "ajax.html\n",
      "akamai.html\n",
      "akka.html\n",
      "aks.html\n",
      "alamofire.html\n",
      "alerta.html\n",
      "alfresco.html\n",
      "algosec.html\n",
      "alibaba cloud.html\n",
      "alloydb.html\n",
      "allura.html\n",
      "alluxio.html\n",
      "alteryx.html\n",
      "amazon codepipeline.html\n",
      "amazon file cache.html\n",
      "amazon lake formation.html\n",
      "amazon lambda.html\n",
      "amazon vpc.html\n",
      "ambari.html\n",
      "amcharts.html\n",
      "amplify.html\n",
      "amqp.html\n",
      "anaconda.html\n",
      "andriod jetpack.html\n",
      "android ndk.html\n",
      "android sdk.html\n",
      "android studio.html\n",
      "android.html\n",
      "angular native.html\n",
      "angular.html\n",
      "angular.js.html\n",
      "ansible.html\n",
      "ant.html\n",
      "antd.html\n",
      "apache atlas.html\n",
      "apache common.html\n",
      "apache.html\n",
      "api gateway.html\n",
      "api.html\n",
      "apigee.html\n",
      "apisix.html\n",
      "apl.html\n",
      "appcheck.html\n",
      "appdna.html\n",
      "appdynamics.html\n",
      "appium.html\n",
      "appkit.html\n",
      "aptos.html\n",
      "aquasec.html\n",
      "arcgis server.html\n",
      "architecture.html\n",
      "arduino ide.html\n",
      "area network.html\n",
      "argocd.html\n",
      "aries.html\n",
      "arkit.html\n",
      "arm.html\n",
      "array.html\n",
      "arrow.html\n",
      "artifactory.html\n",
      "asp.mvc.html\n",
      "asp.net core.html\n",
      "asp.net mvc.html\n",
      "asp.net.html\n",
      "aspnet mvc.html\n",
      "aspx.html\n",
      "assembly.html\n",
      "assertj.html\n",
      "assimp.html\n",
      "ast.html\n",
      "astra security.html\n",
      "astra.html\n",
      "asynchronous.html\n",
      "asyncio.html\n",
      "athena.html\n",
      "attunity.html\n",
      "aurora.html\n",
      "automated testing.html\n",
      "autoprefixer.html\n",
      "auvik.html\n",
      "availability.html\n",
      "avalonia ui.html\n",
      "avro.html\n",
      "awk.html\n",
      "aws appsync.html\n",
      "aws cdk.html\n",
      "aws device farm.html\n",
      "aws mobile hub.html\n",
      "aws sam.html\n",
      "aws.html\n",
      "axiom.html\n",
      "axios.html\n",
      "axis.html\n",
      "axway.html\n",
      "azkaban.html\n",
      "azure ai.html\n",
      "azure blobs.html\n",
      "azure container storage.html\n",
      "azure container.html\n",
      "azure data lake.html\n",
      "azure elastic san.html\n",
      "azure file.html\n",
      "azure managed disks.html\n",
      "azure migration.html\n",
      "azure montior.html\n",
      "azure pipelines.html\n",
      "azure queues.html\n",
      "azure sql database.html\n",
      "azure synapse analytics.html\n",
      "azure tables.html\n",
      "azure virtual machines.html\n",
      "azure.html\n",
      "babel.html\n",
      "babylon.js.html\n",
      "backblaze.html\n",
      "backbone.html\n",
      "bash scripting.html\n",
      "bash.html\n",
      "batik.html\n",
      "bazel.html\n",
      "bcel.html\n",
      "beam.html\n",
      "beautiful soup.html\n",
      "beelin.html\n",
      "behat.html\n",
      "behavioral.html\n",
      "bigquery.html\n",
      "bigtable.html\n",
      "binance smart chain.html\n",
      "binary.html\n",
      "birt report.html\n",
      "bitbucket.html\n",
      "bitrise.html\n",
      "blackduck.html\n",
      "blazor.html\n",
      "ble.html\n",
      "block storage.html\n",
      "bloodhound.html\n",
      "boofcv.html\n",
      "boomi.html\n",
      "boost.html\n",
      "bootstrap.html\n",
      "bower.html\n",
      "brooklyn.html\n",
      "browserstack.html\n",
      "bsd.html\n",
      "buddy.html\n",
      "bugzilla.html\n",
      "builder.html\n",
      "buildforge.html\n",
      "buildkite.html\n",
      "bullet.html\n",
      "bulma.html\n",
      "butterknife.html\n",
      "c#.html\n",
      "c++.html\n",
      "c.html\n",
      "c4.js.html\n",
      "caches.html\n",
      "caching.html\n",
      "cacoon.html\n",
      "caffe.html\n",
      "cakephp.html\n",
      "calabash.html\n",
      "calcite.html\n",
      "camel.html\n",
      "camunda.html\n",
      "canvasjs.html\n",
      "capacitor.html\n",
      "carbondata.html\n",
      "carthage.html\n",
      "casperjs.html\n",
      "cassandra.html\n",
      "cayenne.html\n",
      "ccna.html\n",
      "celery.html\n",
      "celix.html\n",
      "centos.html\n",
      "ceph.html\n",
      "cesiumjs.html\n",
      "cft.html\n",
      "chai.html\n",
      "chainer.html\n",
      "chakra ui.html\n",
      "chart.js.html\n",
      "chartblocks.html\n",
      "charts.js.html\n",
      "checkmarx.html\n",
      "checkmk.html\n",
      "checksum.html\n",
      "chef.html\n",
      "chroma.html\n",
      "ci.html\n",
      "circleci.html\n",
      "cisco stealthwatch.html\n",
      "citrix.html\n",
      "clair.html\n",
      "class.html\n",
      "clearcase.html\n",
      "clearquest.html\n",
      "clickhouse.html\n",
      "clion.html\n",
      "clojure.html\n",
      "cloud bees flow.html\n",
      "cloud build.html\n",
      "cloud dataprep.html\n",
      "cloud sql.html\n",
      "cloud tasks.html\n",
      "cloudera.html\n",
      "cloudflare.html\n",
      "cloudformation.html\n",
      "cloudfoundry.html\n",
      "cloudfront.html\n",
      "cloudsfer.html\n",
      "cloudstack.html\n",
      "cloudwatch.html\n",
      "cmake.html\n",
      "cnn.html\n",
      "cntk.html\n",
      "cobalt.html\n",
      "cocoa framework.html\n",
      "cocoa touch.html\n",
      "cocos2d.html\n",
      "code commit.html\n",
      "codebuild.html\n",
      "codedeploy.html\n",
      "codeigniter.html\n",
      "codelgniter.html\n",
      "codepipeline.html\n",
      "codepush.html\n",
      "cognito.html\n",
      "cognos tm1.html\n",
      "commons.html\n",
      "component.html\n",
      "composer.html\n",
      "computer vision.html\n",
      "conan.html\n",
      "concurrency.html\n",
      "consul.html\n",
      "container linux.html\n",
      "container.html\n",
      "containerization.html\n",
      "control m.html\n",
      "corda.html\n",
      "cordova.html\n",
      "core animation.html\n",
      "core data.html\n",
      "coredns.html\n",
      "coreos.html\n",
      "corona.html\n",
      "coroutines.html\n",
      "cosmodb.html\n",
      "couchbase.html\n",
      "couchdb.html\n",
      "cpanel.html\n",
      "cplex.html\n",
      "crashlytics.html\n",
      "creational.html\n",
      "crystal.html\n",
      "css.html\n",
      "csv.html\n",
      "cucumber.html\n",
      "cuda.html\n",
      "cuquantum.html\n",
      "cxf.html\n",
      "cypress.html\n",
      "d.html\n",
      "d3.html\n",
      "dagger.html\n",
      "dapper.html\n",
      "dart.html\n",
      "dask.html\n",
      "data analysis.html\n",
      "data extraction.html\n",
      "data manpulation.html\n",
      "data mart.html\n",
      "data mining.html\n",
      "data modeling.html\n",
      "data structure.html\n",
      "data visualization.html\n",
      "database sharding.html\n",
      "databricks.html\n",
      "datadog.html\n",
      "dataflow.html\n",
      "dataframe.html\n",
      "datagrip.html\n",
      "dataiku.html\n",
      "datalake.html\n",
      "datalore.html\n",
      "dataproc.html\n",
      "datarobot.html\n",
      "dataset.html\n",
      "datastage.html\n",
      "datastax.html\n",
      "datawrapper.html\n",
      "datax.html\n",
      "dax.html\n",
      "db2.html\n",
      "dbaas.html\n",
      "dbeaver.html\n",
      "dbms.html\n",
      "dds.html\n",
      "debian.html\n",
      "decorator.html\n",
      "decrypt.html\n",
      "deepface.html\n",
      "delphi.html\n",
      "delta lake.html\n",
      "deno.html\n",
      "dependency injection.html\n",
      "derby.html\n",
      "deserialization.html\n",
      "design pattern.html\n",
      "devexpress.html\n",
      "dhcp.html\n",
      "dhtml.html\n",
      "digitalocean.html\n",
      "directx.html\n",
      "distributed systems.html\n",
      "django rest.html\n",
      "django.html\n",
      "dl4j.html\n",
      "dlp.html\n",
      "docker compose.html\n",
      "docker swarm.html\n",
      "docker.html\n",
      "document database.html\n",
      "document databaset.html\n",
      "documentdb.html\n",
      "dom.html\n",
      "domain name system.html\n",
      "domo.html\n",
      "dotnetnuke.html\n",
      "doxia.html\n",
      "dremio.html\n",
      "drill.html\n",
      "drools.html\n",
      "drs.html\n",
      "druid.html\n",
      "drupal.html\n",
      "druva.html\n",
      "dubbo.html\n",
      "durandaljs.html\n",
      "dynamics.html\n",
      "dynamodb.html\n",
      "dynatrace.html\n",
      "easeus.html\n",
      "ebs.html\n",
      "ec2.html\n",
      "ecmascript.html\n",
      "ecs.html\n",
      "efs.html\n",
      "eg innovations.html\n",
      "ehcache.html\n",
      "eigrp.html\n",
      "ejb.html\n",
      "eks.html\n",
      "elastalert.html\n",
      "elastic apm.html\n",
      "elastic bean stalk.html\n",
      "elastic.html\n",
      "elasticache.html\n",
      "elasticcache.html\n",
      "elasticip.html\n",
      "elasticsearch.html\n",
      "elb.html\n",
      "electron.html\n",
      "elementor.html\n",
      "elixir.html\n",
      "elk.html\n",
      "ember.html\n",
      "empire-db.html\n",
      "emr.html\n",
      "encapsulation.html\n",
      "encrypt.html\n",
      "envoy.html\n",
      "eos.html\n",
      "epm.html\n",
      "erlang.html\n",
      "es2015.html\n",
      "es5.html\n",
      "es6.html\n",
      "es7.html\n",
      "eslint.html\n",
      "esp32.html\n",
      "espresso .html\n",
      "esri-leaflet.html\n",
      "esri.html\n",
      "essbase.html\n",
      "esxi.html\n",
      "etcd.html\n",
      "ethereum.html\n",
      "etl.html\n",
      "eventbus.html\n",
      "excel.html\n",
      "exchange.html\n",
      "experian.html\n",
      "exploratory data analysis.html\n",
      "express.html\n",
      "expressjs.html\n",
      "extjs.html\n",
      "f#.html\n",
      "fabric.html\n",
      "facade.html\n",
      "factory.html\n",
      "faiss.html\n",
      "fantom.html\n",
      "fargate.html\n",
      "fastapi.html\n",
      "fastify.html\n",
      "fastlane.html\n",
      "fbackup.html\n",
      "fcm.html\n",
      "featherjs.html\n",
      "fedora.html\n",
      "felix.html\n",
      "fiddler.html\n",
      "figma.html\n",
      "file io.html\n",
      "file storage.html\n",
      "filebeat.html\n",
      "filezilla.html\n",
      "firebase realtime database.html\n",
      "firebase.html\n",
      "firebirdsql.html\n",
      "firestore.html\n",
      "firewall.html\n",
      "fivetran.html\n",
      "flask.html\n",
      "flaskapi.html\n",
      "flex.html\n",
      "flink.html\n",
      "flow.html\n",
      "fluentd.html\n",
      "flume.html\n",
      "fluo.html\n",
      "flutter.html\n",
      "fmod.html\n",
      "fop.html\n",
      "fortify.html\n",
      "fortran.html\n",
      "fortress.html\n",
      "foundation.html\n",
      "foundationdb.html\n",
      "freemarker.html\n",
      "frontend.html\n",
      "fsx.html\n",
      "ftp server.html\n",
      "ftp.html\n",
      "fullstack.html\n",
      "fusioncharts.html\n",
      "galen.html\n",
      "garden.html\n",
      "gatling.html\n",
      "gatsby.html\n",
      "gdscript.html\n",
      "gemalto.html\n",
      "gemfire.html\n",
      "gemnasium.html\n",
      "geneos.html\n",
      "gensim.html\n",
      "geojson.html\n",
      "geopandas.html\n",
      "geoserver.html\n",
      "gephi.html\n",
      "geronimmo.html\n",
      "geronimo.html\n",
      "ggplot.html\n",
      "gherkin.html\n",
      "gis.html\n",
      "git.html\n",
      "github.html\n",
      "gitlab.html\n",
      "gke.html\n",
      "glacier.html\n",
      "glassfish.html\n",
      "glide.html\n",
      "glm.html\n",
      "glue.html\n",
      "glusterfs.html\n",
      "go kit.html\n",
      "go.html\n",
      "gocd.html\n",
      "godot.html\n",
      "gogs.html\n",
      "goland.html\n",
      "google analytics.html\n",
      "google big query.html\n",
      "google cloud monitoring.html\n",
      "google cloud storage.html\n",
      "google cloud.html\n",
      "google compute engine.html\n",
      "google docs.html\n",
      "google kubernetes engine.html\n",
      "google sheets.html\n",
      "google slides.html\n",
      "gradio.html\n",
      "gradle.html\n",
      "grafana.html\n",
      "grails.html\n",
      "graph database.html\n",
      "graph.html\n",
      "graphical user interface.html\n",
      "graphql.html\n",
      "graylog.html\n",
      "greenplum.html\n",
      "greensock.html\n",
      "groovy.html\n",
      "grpc.html\n",
      "grunt.html\n",
      "gstreamer.html\n",
      "gtk.html\n",
      "guava.html\n",
      "gulp.html\n",
      "gump.html\n",
      "gurobi.html\n",
      "gwt.html\n",
      "h2o.html\n",
      "hadoop.html\n",
      "hal.html\n",
      "hana.html\n",
      "haproxy.html\n",
      "hash table.html\n",
      "hashicorp.html\n",
      "haskell.html\n",
      "hazelcast.html\n",
      "hbase.html\n",
      "hd insights.html\n",
      "hdfs.html\n",
      "hdinsight.html\n",
      "hdp.html\n",
      "hedera.html\n",
      "helidon.html\n",
      "helix.html\n",
      "helm.html\n",
      "heroku.html\n",
      "heron.html\n",
      "hevo data.html\n",
      "hexadecimal.html\n",
      "hibernate.html\n",
      "high charts.html\n",
      "hilt.html\n",
      "hive.html\n",
      "hortonworks.html\n",
      "hpux.html\n",
      "html.html\n",
      "htmlunit.html\n",
      "http server.html\n",
      "http.html\n",
      "httpunit.html\n",
      "hybrid cloud.html\n",
      "hyperledger.html\n",
      "hyperv.html\n",
      "hysterix.html\n",
      "iam.html\n",
      "ibatis.html\n",
      "ibm blockchain.html\n",
      "ibm cognos analytics.html\n",
      "ibm db2.html\n",
      "ibm mq.html\n",
      "ibm mqbroker.html\n",
      "ibm planning analytics.html\n",
      "ibm server.html\n",
      "ibm watson.html\n",
      "ibm.html\n",
      "iceberg.html\n",
      "icinga.html\n",
      "icp.html\n",
      "ide.html\n",
      "idrive.html\n",
      "ie10+.html\n",
      "ignite.html\n",
      "iis.html\n",
      "imgui.html\n",
      "immutable.js.html\n",
      "impala.html\n",
      "in memory database.html\n",
      "influxdb.html\n",
      "infogram.html\n",
      "informatica.html\n",
      "infrastructure code.html\n",
      "inheritance.html\n",
      "instana.html\n",
      "intelij idea.html\n",
      "intellij.html\n",
      "inversify.html\n",
      "ionic.html\n",
      "ios sdk.html\n",
      "ios.html\n",
      "iota.html\n",
      "iotdb.html\n",
      "ip address.html\n",
      "iplanet web server.html\n",
      "ipython.html\n",
      "iq server.html\n",
      "ironmq.html\n",
      "istio.html\n",
      "j2ee.html\n",
      "j2se.html\n",
      "jackrabbit.html\n",
      "jade template.html\n",
      "jaeger.html\n",
      "jakarta ee.html\n",
      "james.html\n",
      "jamstack.html\n",
      "jasmine.html\n",
      "jasper.html\n",
      "java awt.html\n",
      "java swing.html\n",
      "java.html\n",
      "javaee.html\n",
      "javafx.html\n",
      "javascript.html\n",
      "jax-rs.html\n",
      "jax.html\n",
      "jboss.html\n",
      "jcl.html\n",
      "jdbc.html\n",
      "jdo.html\n",
      "jee.html\n",
      "jena.html\n",
      "jenkins.html\n",
      "jest.html\n",
      "jetty.html\n",
      "jfrog.html\n",
      "jinja.html\n",
      "jmeter.html\n",
      "jmp.html\n",
      "jms.html\n",
      "jmx.html\n",
      "jndi.html\n",
      "jobserver.html\n",
      "join.html\n",
      "jpa.html\n",
      "jquery mobile.html\n",
      "jquery.html\n",
      "jruby.html\n",
      "jsdoc.html\n",
      "jsf.html\n",
      "jshint.html\n",
      "jslint.html\n",
      "json.html\n",
      "jsp.html\n",
      "julia.html\n",
      "junit jupiter.html\n",
      "junit.html\n",
      "jupyter.html\n",
      "jwe.html\n",
      "jwt.html\n",
      "kafka.html\n",
      "kaggle.html\n",
      "kapacitor.html\n",
      "karaf.html\n",
      "kdb.html\n",
      "kedro.html\n",
      "kentik.html\n",
      "keras.html\n",
      "kibana.html\n",
      "kinesis.html\n",
      "kms.html\n",
      "knative.html\n",
      "knime.html\n",
      "knn.html\n",
      "knockoutjs.html\n",
      "koajs.html\n",
      "koin.html\n",
      "konga.html\n",
      "kotlin.html\n",
      "ktor.html\n",
      "kubeflow.html\n",
      "kubernetes.html\n",
      "kudu.html\n",
      "kustomize.html\n",
      "kvm.html\n",
      "kylin.html\n",
      "labview.html\n",
      "lagom.html\n",
      "lake formation.html\n",
      "lambda.html\n",
      "lando.html\n",
      "langchain.html\n",
      "language model.html\n",
      "laplink.html\n",
      "laravel.html\n",
      "lazy.html\n",
      "ldap.html\n",
      "leakcanary.html\n",
      "lerna.html\n",
      "less.html\n",
      "libavg.html\n",
      "libgdx.html\n",
      "liferay.html\n",
      "lightgbm.html\n",
      "linkerd.html\n",
      "linq.html\n",
      "liquibase.html\n",
      "lisp.html\n",
      "list.html\n",
      "lit.html\n",
      "load balancer.html\n",
      "loadrunner.html\n",
      "lock.html\n",
      "locust.html\n",
      "log4j.html\n",
      "log4net.html\n",
      "logging.html\n",
      "logstash.html\n",
      "logz.io.html\n",
      "lonic.html\n",
      "loopback.html\n",
      "lru cache.html\n",
      "lua.html\n",
      "lucene core.html\n",
      "lucene.html\n",
      "luigi.html\n",
      "lxc.html\n",
      "mac address.html\n",
      "magento.html\n",
      "mahout.html\n",
      "mailgun.html\n",
      "manageengine.html\n",
      "mapbox.html\n",
      "mapr.html\n",
      "mapreduce.html\n",
      "mariadb.html\n",
      "markdown.html\n",
      "material ui.html\n",
      "matlab.html\n",
      "matplotlib.html\n",
      "maven.html\n",
      "maximo.html\n",
      "maxscale.html\n",
      "maxwell.html\n",
      "mcv.html\n",
      "mdl.html\n",
      "mechanicalsoup.html\n",
      "memcached.html\n",
      "memorydb.html\n",
      "memorystore.html\n",
      "mercurial.html\n",
      "mermaid.html\n",
      "mesos.html\n",
      "message queue.html\n",
      "messagepack.html\n",
      "messos.html\n",
      "metastore.html\n",
      "meteor.html\n",
      "metricbeat.html\n",
      "mfc.html\n",
      "micronaut.html\n",
      "microservices.html\n",
      "microsoft game developer kit.html\n",
      "microsoft office.html\n",
      "microsoft quantum.html\n",
      "microsoft sql server.html\n",
      "microsoft sql.html\n",
      "microsoft systems center.html\n",
      "microstrategy.html\n",
      "migration.html\n",
      "mina.html\n",
      "mircosoft sql.html\n",
      "mircosoft visual code.html\n",
      "mircosoft visual studio.html\n",
      "mixpanel.html\n",
      "mlib.html\n",
      "mobile.html\n",
      "mobx.html\n",
      "mockito.html\n",
      "mod perl.html\n",
      "mojolicious.html\n",
      "mongodb atlas.html\n",
      "mongodb.html\n",
      "monitoring.html\n",
      "monolithic systems.html\n",
      "mootools.html\n",
      "mpls.html\n",
      "mq.html\n",
      "mqtt.html\n",
      "msmq.html\n",
      "mstest.html\n",
      "mule.html\n",
      "mulesoft.html\n",
      "multiprocessing.html\n",
      "multithreading.html\n",
      "multition.html\n",
      "mvc.html\n",
      "mvicore.html\n",
      "mvrx.html\n",
      "mvt.html\n",
      "mvvm.html\n",
      "mxnet.html\n",
      "mybatis.html\n",
      "myface.html\n",
      "mynewt.html\n",
      "mysql.html\n",
      "nagios.html\n",
      "nakivo.html\n",
      "nativescript.html\n",
      "nats.html\n",
      "natural language processing.html\n",
      "neo.html\n",
      "neo4j.html\n",
      "neptune.html\n",
      "nessus.html\n",
      "nestjs.html\n",
      "net maui.html\n",
      "netbeans.html\n",
      "netcrunch.html\n",
      "netegrity.html\n",
      "netezza.html\n",
      "nethereum.html\n",
      "network devices.html\n",
      "network monitoring.html\n",
      "network montioring.html\n",
      "network protocol.html\n",
      "network topology.html\n",
      "new relic.html\n",
      "newsql.html\n",
      "nextjs.html\n",
      "nfs.html\n",
      "nginx.html\n",
      "nhibernate.html\n",
      "nifi.html\n",
      "nikto.html\n",
      "ninjaone.html\n",
      "nixos.html\n",
      "nltk.html\n",
      "nmap.html\n",
      "node.js.html\n",
      "nomad.html\n",
      "non-relational.html\n",
      "npm.html\n",
      "nuget.html\n",
      "numpy.html\n",
      "nunit.html\n",
      "nutch.html\n",
      "nuttx.html\n",
      "nuxtjs.html\n",
      "oauth.html\n",
      "oauth2.html\n",
      "object pool.html\n",
      "object storage.html\n",
      "object-oriented.html\n",
      "object.html\n",
      "objective c.html\n",
      "observer.html\n",
      "observium.html\n",
      "ocaml.html\n",
      "octave.html\n",
      "octopus deploy.html\n",
      "odata.html\n",
      "odoo.html\n",
      "ofbix.html\n",
      "ognl.html\n",
      "oidc.html\n",
      "okhttp.html\n",
      "onsecurity.html\n",
      "ooad.html\n",
      "ood.html\n",
      "oop.html\n",
      "oozie.html\n",
      "open dynamics engine.html\n",
      "open vpn.html\n",
      "openai.html\n",
      "openapi.html\n",
      "opencart.html\n",
      "opencv.html\n",
      "opengl.html\n",
      "openid.html\n",
      "openjpa.html\n",
      "opennlp.html\n",
      "opennn.html\n",
      "openoffice.html\n",
      "openshift.html\n",
      "openssl.html\n",
      "openstack.html\n",
      "opentsdb.html\n",
      "openvino.html\n",
      "openvz.html\n",
      "operating systems.html\n",
      "opsgenie.html\n",
      "oracle c.html\n",
      "oracle cloud.html\n",
      "oracle database.html\n",
      "oracle linux.html\n",
      "oracle net.html\n",
      "oracle sql.html\n",
      "oracle virtual box.html\n",
      "oracle virtual machine.html\n",
      "orc.html\n",
      "orientdb.html\n",
      "orm.html\n",
      "os.html\n",
      "osgi.html\n",
      "ospf.html\n",
      "ovirt.html\n",
      "packer.html\n",
      "pagerduty.html\n",
      "pandas.html\n",
      "panel.html\n",
      "papertrail.html\n",
      "parcel.html\n",
      "parquet.html\n",
      "paw.html\n",
      "pax.html\n",
      "pcf.html\n",
      "pdfbox.html\n",
      "penetration testing.html\n",
      "pentaho.html\n",
      "percona xtradb.html\n",
      "perforce.html\n",
      "performance monitoring.html\n",
      "periscope.html\n",
      "perl.html\n",
      "phabricator.html\n",
      "phaser.html\n",
      "phoenix.html\n",
      "phonegap.html\n",
      "php.html\n",
      "phpspec.html\n",
      "phpstorm.html\n",
      "phpunit.html\n",
      "physx.html\n",
      "pig.html\n",
      "pillow.html\n",
      "pinecone.html\n",
      "pinot.html\n",
      "pinpoint.html\n",
      "pivot.html\n",
      "pivotal cloud foundry.html\n",
      "pixijs.html\n",
      "pl sql.html\n",
      "platform uno.html\n",
      "play.html\n",
      "playcanvas.html\n",
      "plc.html\n",
      "plotly.html\n",
      "podman.html\n",
      "poi.html\n",
      "pojo.html\n",
      "polly.js.html\n",
      "polymorphism.html\n",
      "portainer.html\n",
      "posix.html\n",
      "postcss.html\n",
      "postgis.html\n",
      "postgresql.html\n",
      "postman.html\n",
      "power bi.html\n",
      "powerpoint.html\n",
      "powershell.html\n",
      "pr.html\n",
      "predictive modeling.html\n",
      "presto.html\n",
      "private cloud.html\n",
      "programming.html\n",
      "prolog.html\n",
      "prometheus.html\n",
      "prototype.html\n",
      "protractor.html\n",
      "prtg.html\n",
      "pub sub.html\n",
      "public cloud.html\n",
      "pubsub+.html\n",
      "pug.html\n",
      "pullreview.html\n",
      "puppet.html\n",
      "pwa.html\n",
      "pybrain.html\n",
      "pycharm.html\n",
      "pyforms.html\n",
      "pyqt.html\n",
      "pyside2.html\n",
      "pysimplegui.html\n",
      "pyspark.html\n",
      "pyspider.html\n",
      "pytest.html\n",
      "python.html\n",
      "pytorch.html\n",
      "qilkview.html\n",
      "qiskit.html\n",
      "qlik.html\n",
      "qliksense.html\n",
      "qlikview.html\n",
      "qpid.html\n",
      "qt.html\n",
      "qtp.html\n",
      "qualys.html\n",
      "quantum.html\n",
      "quarkus.html\n",
      "qubole.html\n",
      "query.html\n",
      "queue.html\n",
      "quorum.html\n",
      "qwik.html\n",
      "r shiny.html\n",
      "r-drive image.html\n",
      "r.html\n",
      "rabbitmq.html\n",
      "racket.html\n",
      "rackspace.html\n",
      "raii.html\n",
      "raku.html\n",
      "rampart.html\n",
      "rancher.html\n",
      "ranorex.html\n",
      "rapid7.html\n",
      "rapidminer.html\n",
      "raspberry pi.html\n",
      "raygun.html\n",
      "rdbms.html\n",
      "rds.html\n",
      "react hook.html\n",
      "react native.html\n",
      "react router.html\n",
      "react.html\n",
      "react.js.html\n",
      "reactivecocoa.html\n",
      "reactivex.html\n",
      "realm.html\n",
      "red hat fuse.html\n",
      "redis.html\n",
      "redshift.html\n",
      "redux-saga.html\n",
      "redux.html\n",
      "relational.html\n",
      "reliability.html\n",
      "remix.html\n",
      "requests.html\n",
      "resharper c++.html\n",
      "respondjs.html\n",
      "restassured.html\n",
      "retrofit 2.html\n",
      "retrospect solo.html\n",
      "rhel.html\n",
      "riak.html\n",
      "ribbon.html\n",
      "rider.html\n",
      "ripple.html\n",
      "rnn.html\n",
      "robot.html\n",
      "rocketmq.html\n",
      "roller.html\n",
      "rollup.js.html\n",
      "route53.html\n",
      "royale.html\n",
      "rpc.html\n",
      "rpg maker.html\n",
      "rspec.html\n",
      "rubrik.html\n",
      "ruby on rails.html\n",
      "ruby.html\n",
      "rubymine.html\n",
      "rundeck.html\n",
      "rust.html\n",
      "rustover.html\n",
      "rvest.html\n",
      "rwd.html\n",
      "rxjava.html\n",
      "rxkotlin.html\n",
      "rxswift.html\n",
      "s3.html\n",
      "sagemaker.html\n",
      "sailsjs.html\n",
      "salesforce.html\n",
      "salt.html\n",
      "saml.html\n",
      "samza.html\n",
      "sap abap.html\n",
      "sap basis.html\n",
      "sap bi.html\n",
      "sap bw.html\n",
      "sas.html\n",
      "sass.html\n",
      "scala.html\n",
      "scalding.html\n",
      "scaling.html\n",
      "scikit-image.html\n",
      "scikit-learn.html\n",
      "scikit.html\n",
      "scimple.html\n",
      "scipy.html\n",
      "scrapy.html\n",
      "scratch.html\n",
      "scss.html\n",
      "scylladb.html\n",
      "sdn.html\n",
      "seaborn.html\n",
      "security montioring.html\n",
      "security onion.html\n",
      "selenium base.html\n",
      "selenium.html\n",
      "semantic ui.html\n",
      "semaphore.html\n",
      "sensu.html\n",
      "sentry.html\n",
      "serialization.html\n",
      "server.html\n",
      "service bus.html\n",
      "servicenow.html\n",
      "servlets.html\n",
      "ses.html\n",
      "shader.html\n",
      "shadowprotect.html\n",
      "sharegate.html\n",
      "sharepoint.html\n",
      "shell script.html\n",
      "shell.html\n",
      "shiro.html\n",
      "siebel.html\n",
      "signalr.html\n",
      "signoz.html\n",
      "silverlight.html\n",
      "simplecv.html\n",
      "singa.html\n",
      "singleton.html\n",
      "sinonjs.html\n",
      "sisense.html\n",
      "sketch.html\n",
      "skimage.html\n",
      "sling.html\n",
      "snort.html\n",
      "snort.html error.\n",
      "snowflake.html\n",
      "sns.html\n",
      "soa.html\n",
      "soap.html\n",
      "soapui.html\n",
      "socket.html\n",
      "socketio.html\n",
      "sockets.html\n",
      "software development life cycle.html\n",
      "solace.html\n",
      "solana.html\n",
      "solaris.html\n",
      "solarwinds.html\n",
      "solidity.html\n",
      "solidjs.html\n",
      "solr.html\n",
      "sonar qube.html\n",
      "sonarcloud.html\n",
      "sonarlint.html\n",
      "sonatype nexus.html\n",
      "spacelift.html\n",
      "spacy.html\n",
      "spamassassin.html\n",
      "spanner.html\n",
      "spark graphx.html\n",
      "spark streaming.html\n",
      "spark.html\n",
      "sparkml.html\n",
      "sparkr.html\n",
      "sparksql.html\n",
      "specflow.html\n",
      "spinnaker.html\n",
      "splunk.html\n",
      "spock.html\n",
      "spotfire.html\n",
      "spring aop.html\n",
      "spring batch.html\n",
      "spring boot.html\n",
      "spring cloud.html\n",
      "spring data.html\n",
      "spring gateway.html\n",
      "spring integration.html\n",
      "spring jpa.html\n",
      "spring mvc.html\n",
      "spring reactor.html\n",
      "spring security.html\n",
      "spring transaction management.html\n",
      "spring web.html\n",
      "spring.html\n",
      "sprint.html\n",
      "spss.html\n",
      "sql.html\n",
      "sqlalchemy.html\n",
      "sqlite.html\n",
      "sqoop.html\n",
      "sqs.html\n",
      "squid proxy.html\n",
      "sr sam 34 35.html\n",
      "ssis.html\n",
      "ssl.html\n",
      "ssrs.html\n",
      "stack.html\n",
      "stata.html\n",
      "state.html\n",
      "statistical analysis.html\n",
      "statsd.html\n",
      "stellar.html\n",
      "stitch data.html\n",
      "stm32wl.html\n",
      "storage area network.html\n",
      "storage.html\n",
      "storm.html\n",
      "storybook.html\n",
      "strata.html\n",
      "strategy.html\n",
      "streamlit.html\n",
      "streamsets.html\n",
      "structs.html\n",
      "structural.html\n",
      "structured analysis.html\n",
      "structured design.html\n",
      "struts.html\n",
      "stylus.html\n",
      "subnet mask.html\n",
      "subnet.html\n",
      "subversion.html\n",
      "sui network.html\n",
      "superset.html\n",
      "suricata.html\n",
      "suricata.html error.\n",
      "suse.html\n",
      "svelte.html\n",
      "swagger.html\n",
      "swarm.html\n",
      "swift.html\n",
      "swiftic.html\n",
      "swiftui.html\n",
      "swt.html\n",
      "sybase.html\n",
      "symfony.html\n",
      "synapse.html\n",
      "sysdig.html\n",
      "syslog.html\n",
      "systemds.html\n",
      "systems design strategy.html\n",
      "systems design.html\n",
      "t sql.html\n",
      "tableau.html\n",
      "tailwind css.html\n",
      "talend.html\n",
      "tanzu.html\n",
      "tapestry.html\n",
      "tauri.html\n",
      "tcl.html\n",
      "tcp.html\n",
      "tcpflow.html\n",
      "teamcity.html\n",
      "telegraf.html\n",
      "tenable nessus.html\n",
      "tensorflow quantum.html\n",
      "tensorflow.html\n",
      "tensorrt.html\n",
      "teradata.html\n",
      "terraform.html\n",
      "test labs.html\n",
      "test studio.html\n",
      "testcomplete.html\n",
      "testng.html\n",
      "testrail.html\n",
      "text analysis.html\n",
      "tezos.html\n",
      "tfs.html\n",
      "tfx.html\n",
      "theano.html\n",
      "three.js.html\n",
      "tibco ems.html\n",
      "tibco.html\n",
      "tibero.html\n",
      "tick stack.html\n",
      "tidyverse.html\n",
      "tiered.html\n",
      "tika.html\n",
      "time series.html\n",
      "timescaledb.html\n",
      "timestream.html\n",
      "tinkerpop.html\n",
      "titan.html\n",
      "titanium.html\n",
      "tkinter.html\n",
      "toad.html\n",
      "tomcat.html\n",
      "tomee.html\n",
      "toplink.html\n",
      "torch.html\n",
      "tosca.html\n",
      "tracisci.html\n",
      "traffic server.html\n",
      "transformers.html\n",
      "travis ci.html\n",
      "tree.html\n",
      "trie.html\n",
      "tron.html\n",
      "tuple.html\n",
      "turbine.html\n",
      "turbonomic.html\n",
      "twistlock.html\n",
      "typescript.html\n",
      "ubuntu.html\n",
      "udb.html\n",
      "udp.html\n",
      "uft.html\n",
      "ui automator.html\n",
      "uikit.html\n",
      "ulkit.html\n",
      "uml.html\n",
      "undertow.html\n",
      "unity.html\n",
      "unix.html\n",
      "uno platform.html\n",
      "unreal engine.html\n",
      "unstructured data.html\n",
      "unstructured datasets.html\n",
      "uwp.html\n",
      "vagrant.html\n",
      "validata qs.html\n",
      "vanillajs.html\n",
      "varnish.html\n",
      "vault.html\n",
      "vb script.html\n",
      "vba.html\n",
      "vcenter.html\n",
      "vcloud.html\n",
      "vector database.html\n",
      "veeam.html\n",
      "velocity.html\n",
      "vercel.html\n",
      "vert.x.html\n",
      "vertex ai.html\n",
      "vertica.html\n",
      "virtual machine.html\n",
      "virtuozzo.html\n",
      "visio.html\n",
      "visitor.html\n",
      "viso suite.html\n",
      "visual basic .net.html\n",
      "visual basic.html\n",
      "visual studio.html\n",
      "visualization.html\n",
      "viz.html\n",
      "vkey.html\n",
      "vmware certified professional.html\n",
      "voldemort.html\n",
      "vpc.html\n",
      "vreazlise.html\n",
      "vrrp.html\n",
      "vsphere.html\n",
      "vsts.html\n",
      "vue.js.html\n",
      "vulkan.html\n",
      "vxworks.html\n",
      "w3af.html\n",
      "wax.html\n",
      "wcf.html\n",
      "web api.html\n",
      "web crawler.html\n",
      "web token.html\n",
      "web workers.html\n",
      "web3.js.html\n",
      "webgl.html\n",
      "webhooks.html\n",
      "weblogic.html\n",
      "webpack.html\n",
      "webrtc.html\n",
      "websockets.html\n",
      "websphere.html\n",
      "webstorm.html\n",
      "weka.html\n",
      "whatgraph.html\n",
      "whatsup gold.html\n",
      "whitesource.html\n",
      "wicket.html\n",
      "wildfly.html\n",
      "windows batch.html\n",
      "windows server.html\n",
      "winform.html\n",
      "winforms.html\n",
      "winui.html\n",
      "wireshark.html\n",
      "word.html\n",
      "wordpress.html\n",
      "workbench.html\n",
      "wpbakery.html\n",
      "wpf.html\n",
      "ws02 apim.html\n",
      "wsdl.html\n",
      "wsk.html\n",
      "wxpython.html\n",
      "x-pack.html\n",
      "xalan.html\n",
      "xamarin.html\n",
      "xampp.html\n",
      "xarray.html\n",
      "xcode.html\n",
      "xen.html\n",
      "xerces.html\n",
      "xgboost.html\n",
      "xhtml.html\n",
      "xlm.html\n",
      "xml.html\n",
      "xmlbeans.html\n",
      "xmlrpc.html\n",
      "xmpp.html\n",
      "xpath.html\n",
      "xsd.html\n",
      "xsl.html\n",
      "xslt.html\n",
      "yaml.html\n",
      "yarn.html\n",
      "yetus.html\n",
      "yolo.html\n",
      "yugabytedb.html\n",
      "z-os.html\n",
      "zabbix.html\n",
      "zap.html\n",
      "zeek.html\n",
      "zend.html\n",
      "zenoss.html\n",
      "zeplin.html\n",
      "zeromq.html\n",
      "zig.html\n",
      "zigbee.html\n",
      "zipkin.html\n",
      "zoho analytics.html\n",
      "zookeeper.html\n",
      "zuul.html\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\n",
      " * Running on http://localhost:5000\n",
      "Press CTRL+C to quit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "triggered\n",
      "extract resume skill...\n",
      "extract job skill...\n",
      "Getting leetcode learning resource..\n",
      "Getting skill learning resource..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-03-31 21:29:25,531] ERROR in app: Exception on / [GET]\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\ng_mi\\anaconda3\\lib\\site-packages\\flask\\app.py\", line 2525, in wsgi_app\n",
      "    response = self.full_dispatch_request()\n",
      "  File \"C:\\Users\\ng_mi\\anaconda3\\lib\\site-packages\\flask\\app.py\", line 1822, in full_dispatch_request\n",
      "    rv = self.handle_user_exception(e)\n",
      "  File \"C:\\Users\\ng_mi\\anaconda3\\lib\\site-packages\\flask\\app.py\", line 1820, in full_dispatch_request\n",
      "    rv = self.dispatch_request()\n",
      "  File \"C:\\Users\\ng_mi\\anaconda3\\lib\\site-packages\\flask\\app.py\", line 1796, in dispatch_request\n",
      "    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)\n",
      "  File \"C:\\Users\\ng_mi\\AppData\\Local\\Temp\\ipykernel_17312\\1734381666.py\", line 1244, in generate_learning_resource\n",
      "    learning_resource.GenerateLearningResource(resume, job_description, company, generated_directory)\n",
      "  File \"C:\\Users\\ng_mi\\AppData\\Local\\Temp\\ipykernel_17312\\1734381666.py\", line 905, in GenerateLearningResource\n",
      "    skill_result_dict = self.GenerateSkillResource(difference_skill_dict_list, generated_directory)\n",
      "  File \"C:\\Users\\ng_mi\\AppData\\Local\\Temp\\ipykernel_17312\\1734381666.py\", line 233, in GenerateSkillResource\n",
      "    self.GenerateSkillResourceContent(document_prepare_set, result_dict[\"Skill Learning Resource Remarks\"],\n",
      "  File \"C:\\Users\\ng_mi\\AppData\\Local\\Temp\\ipykernel_17312\\1734381666.py\", line 272, in GenerateSkillResourceContent\n",
      "    skill_dict[title] =  self.ConvertHtmlToString2(file_content)\n",
      "  File \"C:\\Users\\ng_mi\\AppData\\Local\\Temp\\ipykernel_17312\\1734381666.py\", line 390, in ConvertHtmlToString2\n",
      "    h.ignore_images = True\n",
      "NameError: name 'h' is not defined\n",
      "127.0.0.1 - - [31/Mar/2024 21:29:25] \"GET / HTTP/1.1\" 500 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "triggered\n",
      "extract resume skill...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ng_mi\\anaconda3\\lib\\site-packages\\skillNer\\utils.py:99: UserWarning: [W008] Evaluating Token.similarity based on empty vectors.\n",
      "  vec_similarity = token1.similarity(token2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "extract job skill...\n",
      "Getting leetcode learning resource..\n",
      "Getting skill learning resource..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-03-31 21:32:14,343] ERROR in app: Exception on / [GET]\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\ng_mi\\anaconda3\\lib\\site-packages\\flask\\app.py\", line 2525, in wsgi_app\n",
      "    response = self.full_dispatch_request()\n",
      "  File \"C:\\Users\\ng_mi\\anaconda3\\lib\\site-packages\\flask\\app.py\", line 1822, in full_dispatch_request\n",
      "    rv = self.handle_user_exception(e)\n",
      "  File \"C:\\Users\\ng_mi\\anaconda3\\lib\\site-packages\\flask\\app.py\", line 1820, in full_dispatch_request\n",
      "    rv = self.dispatch_request()\n",
      "  File \"C:\\Users\\ng_mi\\anaconda3\\lib\\site-packages\\flask\\app.py\", line 1796, in dispatch_request\n",
      "    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)\n",
      "  File \"C:\\Users\\ng_mi\\AppData\\Local\\Temp\\ipykernel_17312\\1734381666.py\", line 1244, in generate_learning_resource\n",
      "    learning_resource.GenerateLearningResource(resume, job_description, company, generated_directory)\n",
      "  File \"C:\\Users\\ng_mi\\AppData\\Local\\Temp\\ipykernel_17312\\1734381666.py\", line 905, in GenerateLearningResource\n",
      "    skill_result_dict = self.GenerateSkillResource(difference_skill_dict_list, generated_directory)\n",
      "  File \"C:\\Users\\ng_mi\\AppData\\Local\\Temp\\ipykernel_17312\\1734381666.py\", line 233, in GenerateSkillResource\n",
      "    self.GenerateSkillResourceContent(document_prepare_set, result_dict[\"Skill Learning Resource Remarks\"],\n",
      "  File \"C:\\Users\\ng_mi\\AppData\\Local\\Temp\\ipykernel_17312\\1734381666.py\", line 272, in GenerateSkillResourceContent\n",
      "    skill_dict[title] =  self.ConvertHtmlToString2(file_content)\n",
      "  File \"C:\\Users\\ng_mi\\AppData\\Local\\Temp\\ipykernel_17312\\1734381666.py\", line 390, in ConvertHtmlToString2\n",
      "    h.ignore_images = True\n",
      "NameError: name 'h' is not defined\n",
      "127.0.0.1 - - [31/Mar/2024 21:32:14] \"GET / HTTP/1.1\" 500 -\n",
      "127.0.0.1 - - [31/Mar/2024 21:32:15] \"GET /favicon.ico HTTP/1.1\" 404 -\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "import pandas as pd\n",
    "import pypandoc\n",
    "import csv\n",
    "import os\n",
    "import glob\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import shutil\n",
    "import zipfile\n",
    "import html2text\n",
    "import json\n",
    "import re\n",
    "from flask import Flask, send_file, request\n",
    "from spacy.matcher import PhraseMatcher\n",
    "from skillNer.general_params import SKILL_DB\n",
    "from skillNer.skill_extractor_class import SkillExtractor\n",
    "from werkzeug.serving import run_simple\n",
    "from waitress import serve\n",
    "\n",
    "\"\"\"\n",
    "Sorry did not follow in python, all method also lower case.\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "Skill class are basically just a custom type to wrap all the data info\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "class Skill:\n",
    "\n",
    "    def __init__(self, name, keyword, groups=None):\n",
    "        filename = name\n",
    "        filename = filename.replace('/', '-')\n",
    "        filename = filename.replace(\"\\\\\", '-')\n",
    "        filename = filename + \".html\"\n",
    "        path = os.path.join(\"skill\", filename)\n",
    "        path = path.replace(\"\\\\\", '/')\n",
    "        self.resource_path = path  # for the resource path\n",
    "        self.keyword_search = keyword  # keyword for searching LLM\n",
    "        self.group_set = set()\n",
    "        if groups is not None:\n",
    "            self.UpdateGroupSet(groups)\n",
    "\n",
    "    def UpdateGroupSet(self, groups):\n",
    "        self.group_set.update(groups)\n",
    "        # print(\"skill group set updated.\")\n",
    "\n",
    "    def ChangeKeyword(self, keyword):\n",
    "        self.keyword_search = keyword\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Learning Resource Service as a an object that handle everything about generate learning resource\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "class LearningResourceService:\n",
    "    def __init__(self):\n",
    "        self.nlp = spacy.load('en_core_web_lg')\n",
    "        self.skill_extractor = SkillExtractor(self.nlp, SKILL_DB, PhraseMatcher)\n",
    "        self.skill_dict_list = {}\n",
    "        self.group_dict_list = {}\n",
    "        self.exact_match_replace_dict_list = {}\n",
    "        self.partial_match_replace_dict_list = {}\n",
    "        self.not_found_dict_list = {}\n",
    "        self.three_word_skill_classification_set = set()\n",
    "        self.two_word_skill_classification_set = set()\n",
    "        self.one_word_skill_classification_set = set()\n",
    "        self.backup_keyword_dict_list = {}\n",
    "        self.partial_search_ignore_list = [\"apache\", \"microsoft\", \"google\", \"amazon\", \"apple\", \"vmware\", \"ibm\",\n",
    "                                           \"oracle\", \"sap\"]\n",
    "        self.leetcode_list = [\"c++\", \"c\", \"c#\", \"python\", \"java\", \"javascript\", \"typescript\", \"php\", \"swift\", \"kotlin\",\n",
    "                              \"go\", \"ruby\", \"scala\", \"rust\", \"racket\"]\n",
    "        self.one_keyword_dict_list = {}\n",
    "        self.two_keyword_dict_list = {}\n",
    "        self.three_keyword_dict_list = {}\n",
    "        self.leetcode_company_dict_list = {}\n",
    "        self.leetcode_overall_frequency_dict_list = {}\n",
    "        self.AllThisWillBeRemoveOnceFinalize()\n",
    "        self.ImportClassificationSet()\n",
    "        self.ImportSkillDictList()\n",
    "        self.InitKeywordDictList()\n",
    "        self.InitLeetCodeCompanyNameDictList()\n",
    "        self.InitLeetcodeOverallFrequencyDictList()\n",
    "        self.request_queue_no = 0\n",
    "\n",
    "    \"\"\"\n",
    "    Take in any number of string,\n",
    "    lower case all word and keep only 1 space in between the word,\n",
    "    remove all the symbol,\n",
    "    except, dash which keep only if in between 2 word, \n",
    "    dot if in between 2 word and if . is the first character of the word\n",
    "    \"\"\"\n",
    "    @staticmethod\n",
    "    def WordPreprocessing(string_text):\n",
    "        string_text = string_text.replace(\"[\", \"\")\n",
    "        string_text = string_text.replace(\"]\", \"\")\n",
    "        string_text = string_text.replace(\"(\", \"\")\n",
    "        string_text = string_text.replace(\")\", \"\")\n",
    "        string_text = string_text.replace(\":\", \"\")\n",
    "        string_text = string_text.replace(\"*\", \"\")\n",
    "        string_text = string_text.replace(\"\\\\\", \"\")\n",
    "        string_text = string_text.replace(\"\\\"\", \"\")\n",
    "        string_text = string_text.replace(\"’s\", \"\")\n",
    "        string_text = string_text.replace(\"?\", \"\")\n",
    "        string_text = string_text.replace(\"!\", \"\")\n",
    "        string_text = string_text.replace(\"&\", \"\")\n",
    "        string_text = string_text.replace(\"%\", \"\")\n",
    "        string_text = string_text.replace(\"_\", \"\")\n",
    "        string_text = string_text.replace(\",\", \"\")\n",
    "        string_text = string_text.replace(\"*\", \"\")\n",
    "        string_text = string_text.replace(\"\\n\", \" \")\n",
    "        string_text = string_text.replace(\"/\", \" \")\n",
    "        string_text = re.sub(r'\\s+', ' ', string_text)\n",
    "        string_text = re.sub(r'\\s-\\s', ' ', string_text)\n",
    "        string_text = re.sub(r'\\s\\.\\s', ' ', string_text)\n",
    "        string_text = string_text.replace(\" -\", \" \")\n",
    "        string_text = string_text.replace(\"- \", \" \")\n",
    "        string_text = string_text.replace(\". \", \" \")\n",
    "        string_text = string_text.lower()\n",
    "        return string_text\n",
    "\n",
    "    \"\"\"\n",
    "    Convert HTML to text format, remove all image, link and rich text format\n",
    "    \"\"\"\n",
    "    def ConvertHtmlToString(self, html_text):\n",
    "        h = html2text.HTML2Text()\n",
    "        h.ignore_images = True\n",
    "        h.ignore_links = False\n",
    "        h.inline_links = True\n",
    "        h.reference_links = False\n",
    "        string_text = h.handle(html_text)\n",
    "        string_text = re.sub(r'https://\\S+', '', string_text)\n",
    "        string_text = re.sub(r'[^\\x00-\\x7F]+', '', string_text)\n",
    "        string_text = string_text.replace(\"[1]\", \"\")\n",
    "        string_text = string_text.replace(\"[2]\", \"\")\n",
    "        string_text = string_text.replace(\"[3]\", \"\")\n",
    "        string_text = string_text.replace(\"[4]\", \"\")\n",
    "        string_text = string_text.replace(\"[5]\", \"\")\n",
    "        string_text = string_text.replace(\"[6]\", \"\")\n",
    "        string_text = string_text.replace(\"[7]\", \"\")\n",
    "        string_text = string_text.replace(\"[8]\", \"\")\n",
    "        string_text = string_text.replace(\"[9]\", \"\")\n",
    "        string_text = string_text.replace(\"[0]\", \"\")\n",
    "        string_text = string_text.replace(\"**\", \"\")\n",
    "        string_text = self.WordPreprocessing(string_text)\n",
    "        return string_text\n",
    "\n",
    "    \"\"\"\n",
    "    Convert HTML to text format, keep all image and link, but remove rich text format\n",
    "    \"\"\"\n",
    "    @staticmethod\n",
    "    def ConvertHtmlToString2(html_text):\n",
    "        h = html2text.HTML2Text()\n",
    "        h.ignore_images = True\n",
    "        h.ignore_links = False\n",
    "        h.inline_links = False\n",
    "        h.reference_links = False\n",
    "        string_text = h.handle(html_text)\n",
    "        string_text = string_text.replace(\"[1]\", \"\")\n",
    "        string_text = string_text.replace(\"[2]\", \"\")\n",
    "        string_text = string_text.replace(\"[3]\", \"\")\n",
    "        string_text = string_text.replace(\"[4]\", \"\")\n",
    "        string_text = string_text.replace(\"[5]\", \"\")\n",
    "        string_text = string_text.replace(\"[6]\", \"\")\n",
    "        string_text = string_text.replace(\"[7]\", \"\")\n",
    "        string_text = string_text.replace(\"[8]\", \"\")\n",
    "        string_text = string_text.replace(\"[9]\", \"\")\n",
    "        string_text = string_text.replace(\"[0]\", \"\")\n",
    "        string_text = string_text.replace(\"**\", \"\")\n",
    "        return string_text\n",
    "\n",
    "    \"\"\"\n",
    "    Below method just how construct the skill dict list, import & export data\n",
    "    \"\"\"\n",
    "    def AddSkillDictList(self, name, keyword, groups=None):\n",
    "        if name not in self.skill_dict_list:\n",
    "            self.skill_dict_list[name] = Skill(name, keyword, groups)\n",
    "            if groups is not None:\n",
    "                for g in groups:\n",
    "                    if g in self.group_dict_list:\n",
    "                        self.group_dict_list.get(g).add(name)\n",
    "                    else:\n",
    "                        new_set = set()\n",
    "                        new_set.add(name)\n",
    "                        self.group_dict_list[g] = new_set\n",
    "\n",
    "        else:\n",
    "            self.skill_dict_list[name].UpdateGroupSet(groups)\n",
    "\n",
    "    def ReClassificationSkillDictList(self, name, keyword, groups):\n",
    "        search_keyword = keyword\n",
    "        if name in self.backup_keyword_dict_list:\n",
    "            search_keyword = self.backup_keyword_dict_list[name]\n",
    "        self.AddSkillDictList(name, search_keyword, groups)\n",
    "\n",
    "    def ImportClassificationSet(self):\n",
    "        file = open(\"word classification/classification words.txt\", \"r\")\n",
    "        for word in file:\n",
    "            word = word.replace(\"\\n\", \"\")\n",
    "            word_list = word.split()\n",
    "            if len(word_list) == 1:\n",
    "                self.one_word_skill_classification_set.add(word)\n",
    "            elif len(word_list) == 2:\n",
    "                self.two_word_skill_classification_set.add(word)\n",
    "            else:\n",
    "                self.three_word_skill_classification_set.add(word)\n",
    "        file.close()\n",
    "\n",
    "    def ExportSkillDictList(self):\n",
    "        file_path = \"skills.csv\"\n",
    "        with open(file_path, 'w', newline='') as file:\n",
    "            writer = csv.writer(file)\n",
    "            writer.writerow([\"Name\", \"Search Keyword\", \"Resource Path\", \"Groups\"])\n",
    "            for key, value in self.skill_dict_list.items():\n",
    "                name = key\n",
    "                search = value.keyword_search\n",
    "                path = value.resource_path\n",
    "                groups = \"\"\n",
    "\n",
    "                for g in value.group_set:\n",
    "                    groups += \"[\"\n",
    "                    groups += g\n",
    "                    groups += \"]\"\n",
    "\n",
    "                writer.writerow([name, search, path, groups])\n",
    "            file.close()\n",
    "        with open('skills.txt', 'w') as f:\n",
    "            for i in self.skill_dict_list:\n",
    "                f.write(i)\n",
    "                f.write(\"\\n\")\n",
    "            f.close()\n",
    "\n",
    "    def ImportSkillDictList(self):\n",
    "        df = pd.read_csv(\"skills.csv\")\n",
    "        for index, row in df.iterrows():\n",
    "            name = str(row['Name'])\n",
    "            keyword = str(row['Search Keyword'])\n",
    "            groups = str(row['Groups'])\n",
    "            groups_set = None\n",
    "            groups = groups.replace('[', '')\n",
    "            groups_list = groups.split(']')\n",
    "            if len(groups_list) > 0:\n",
    "                groups_list = groups_list[:-1]\n",
    "                groups_set = set()\n",
    "                for g in groups_list:\n",
    "                    groups_set.add(g)\n",
    "            # auto create group also\n",
    "            self.AddSkillDictList(name, keyword, groups_set)\n",
    "\n",
    "    def ExportGroupDictList(self):\n",
    "        file_path = \"groups.csv\"\n",
    "        with open(file_path, 'w', newline='') as file:\n",
    "            writer = csv.writer(file)\n",
    "            writer.writerow([\"Name\", \"skills\"])\n",
    "            for key, value in self.group_dict_list.items():\n",
    "                name = key\n",
    "                skills = \"\"\n",
    "                for s in value:\n",
    "                    skills += \"[\"\n",
    "                    skills += s\n",
    "                    skills += \"]\"\n",
    "                writer.writerow([name, skills])\n",
    "            file.close()\n",
    "\n",
    "    def ExportNotFoundSet(self):\n",
    "        file_path = \"not found.csv\"\n",
    "        with open(file_path, 'w', newline='') as file:\n",
    "            writer = csv.writer(file)\n",
    "            writer.writerow([\"Name\", \"Search Keyword\", \"Resource Path\"])\n",
    "            for key, value in self.not_found_dict_list.items():\n",
    "                name = key\n",
    "                search = value.keyword_search\n",
    "                path = \"skill unclassified/not tech/\" + name + \".html\"\n",
    "\n",
    "                writer.writerow([name, search, path])\n",
    "            file.close()\n",
    "\n",
    "    def InitKeywordDictList(self):\n",
    "        self.one_keyword_dict_list.clear()\n",
    "        self.two_keyword_dict_list.clear()\n",
    "        self.three_keyword_dict_list.clear()\n",
    "        for s in self.skill_dict_list:\n",
    "            words = s.split()\n",
    "            if len(words) == 1:\n",
    "                self.one_keyword_dict_list[s] = s\n",
    "            elif len(words) == 2:\n",
    "                self.two_keyword_dict_list[s] = s\n",
    "            else:\n",
    "                self.three_keyword_dict_list[s] = s\n",
    "\n",
    "    def InitLeetCodeCompanyNameDictList(self):\n",
    "        f = open(\"leetcode/companies.txt\", \"r\")\n",
    "\n",
    "        for c in f:\n",
    "            c = c.replace(\"\\n\", \"\")\n",
    "            key = c\n",
    "            key = key.lower()\n",
    "            self.leetcode_company_dict_list[key] = c\n",
    "        f.close()\n",
    "\n",
    "    def InitLeetcodeOverallFrequencyDictList(self):\n",
    "        df = pd.read_csv(\"leetcode/Question List.csv\")\n",
    "        for index, row in df.iterrows():\n",
    "            self.leetcode_overall_frequency_dict_list[str(row[\"No\"])] = str(row[\"Frequency\"])\n",
    "\n",
    "    def AllThisWillBeRemoveOnceFinalize(self):\n",
    "\n",
    "        self.exact_match_replace_dict_list[\"tdd\"] = \"testing\"\n",
    "        self.exact_match_replace_dict_list[\"webdriver\"] = \"web crawler\"\n",
    "        self.exact_match_replace_dict_list[\"vbnet\"] = \"visual basic .net\"\n",
    "        self.exact_match_replace_dict_list[\"vb.net\"] = \"visual basic .net\"\n",
    "        self.exact_match_replace_dict_list[\"vb\"] = \"visual basic\"\n",
    "        self.exact_match_replace_dict_list[\"html5\"] = \"html\"\n",
    "        self.exact_match_replace_dict_list[\"svn\"] = \"subversion\"\n",
    "        self.exact_match_replace_dict_list[\"unity3d\"] = \"unity\"\n",
    "        self.exact_match_replace_dict_list[\"mssql\"] = \"microsoft sql\"\n",
    "        self.exact_match_replace_dict_list[\"shaders\"] = \"shader\"\n",
    "        self.exact_match_replace_dict_list[\"uat\"] = \"testing\"\n",
    "        self.exact_match_replace_dict_list[\"mui\"] = \"material ui\"\n",
    "        self.exact_match_replace_dict_list[\"gui\"] = \"graphical user interface\"\n",
    "        self.exact_match_replace_dict_list[\"ui\"] = \"user interface\"\n",
    "        self.exact_match_replace_dict_list[\"aliyun\"] = \"alibaba cloud\"\n",
    "        self.exact_match_replace_dict_list[\"ali-cloud\"] = \"alibaba cloud\"\n",
    "        self.exact_match_replace_dict_list[\"asp.net mvc 5\"] = \"asp.net mvc\"\n",
    "\n",
    "        self.partial_match_replace_dict_list[\"ms\"] = \"microsoft\"\n",
    "        self.partial_match_replace_dict_list[\"db\"] = \"database\"\n",
    "\n",
    "    \"\"\"\n",
    "    not in use, this for if handle more than 1 request\n",
    "    \"\"\"\n",
    "    def GetRequestQueueNo(self):\n",
    "        #self.request_queue_no += 1\n",
    "        return self.request_queue_no\n",
    "\n",
    "    \"\"\"\n",
    "    This function for finding all technical term keyword from all skill the learning resource, \n",
    "    so that we can group those skill by relation.\n",
    "    \"\"\"\n",
    "    def FindClassificationKeyword(self):\n",
    "        directory = 'skill'\n",
    "        filenames = [f for f in listdir(directory) if isfile(join(directory, f))]\n",
    "        skillNer_dict_list = {}\n",
    "\n",
    "        for f in filenames:\n",
    "            words = f.rsplit(\".\")\n",
    "            extension = words[len(words) - 1]\n",
    "            if extension == \"html\":\n",
    "                print(f)\n",
    "                with open(directory + \"/\" + f, 'r', encoding=\"utf-8\") as file:\n",
    "                    html_content = file.read()\n",
    "                    file.close()\n",
    "                string_text = self.ConvertHtmlToString(html_content)\n",
    "\n",
    "                try:\n",
    "                    annotations = self.skill_extractor.annotate(string_text)\n",
    "                    # self.skill_extractor.describe(annotations)\n",
    "                    result = annotations[\"results\"]\n",
    "                    skill_list_1 = result[\"full_matches\"]\n",
    "                    skill_list_2 = result[\"ngram_scored\"]\n",
    "\n",
    "                    for i in range(len(skill_list_1)):\n",
    "                        info = skill_list_1[i]\n",
    "                        skill = info[\"doc_node_value\"]\n",
    "                        skill = skill.lower()\n",
    "                        if skill not in skillNer_dict_list:\n",
    "                            skillNer_dict_list[skill] = 0\n",
    "                        skillNer_dict_list[skill] += 1\n",
    "                    for i in range(len(skill_list_2)):\n",
    "                        info = skill_list_2[i]\n",
    "                        skill = info[\"doc_node_value\"]\n",
    "                        skill = skill.lower()\n",
    "                        if skill not in skillNer_dict_list:\n",
    "                            skillNer_dict_list[skill] = 0\n",
    "                        skillNer_dict_list[skill] += 1\n",
    "                except:\n",
    "                    print(f, \"error.\")\n",
    "\n",
    "        with open('word classification/skillNer word.txt', 'w', encoding=\"utf-8\") as f:\n",
    "            for s in sorted(skillNer_dict_list, key=skillNer_dict_list.get, reverse=True):\n",
    "                f.write(str(s) + \" - \" + str(skillNer_dict_list[s]))\n",
    "                f.write('\\n')\n",
    "            file.close()\n",
    "\n",
    "    \"\"\"\n",
    "    This function for classified all skill in the relation keyword.\n",
    "    \"\"\"\n",
    "    def SkillReClassification(self):\n",
    "        self.backup_keyword_dict_list.clear()\n",
    "        for s in self.skill_dict_list:\n",
    "            self.backup_keyword_dict_list[s] = self.skill_dict_list[s].keyword_search\n",
    "        self.skill_dict_list.clear()\n",
    "        self.group_dict_list.clear()\n",
    "        directory = 'skill'\n",
    "        filenames = [f for f in listdir(directory) if isfile(join(directory, f))]\n",
    "\n",
    "        for f in filenames:\n",
    "            words = f.rsplit(\".\")\n",
    "            extension = words[len(words) - 1]\n",
    "            if extension == \"html\":\n",
    "                print(f)\n",
    "                filename = f.replace(\".html\", \"\")\n",
    "                with open(directory + \"/\" + f, 'r', encoding=\"utf-8\") as file:\n",
    "                    html_content = file.read()\n",
    "                    file.close()\n",
    "                text_content = self.ConvertHtmlToString(html_content)\n",
    "\n",
    "                words = text_content.split()\n",
    "                have_classified = False\n",
    "                for i in range(len(words)):\n",
    "                    first_word = words[i]\n",
    "                    if first_word.endswith('.'):\n",
    "                        first_word = first_word[:-1]\n",
    "\n",
    "                    one_word = first_word\n",
    "\n",
    "                    if one_word in self.one_word_skill_classification_set:\n",
    "                        self.ReClassificationSkillDictList(filename, filename, {one_word})\n",
    "                        have_classified = True\n",
    "\n",
    "                    if i + 1 >= len(words):\n",
    "                        break\n",
    "                    second_word = words[i + 1]\n",
    "                    if second_word.endswith('.'):\n",
    "                        second_word = second_word[:-1]\n",
    "\n",
    "                    two_word = first_word + \" \" + second_word\n",
    "\n",
    "                    if two_word in self.two_word_skill_classification_set:\n",
    "                        self.ReClassificationSkillDictList(filename, filename, {two_word})\n",
    "                        have_classified = True\n",
    "\n",
    "                    if i + 2 >= len(words):\n",
    "                        break\n",
    "                    third_word = words[i + 2]\n",
    "                    if third_word.endswith('.'):\n",
    "                        third_word = third_word[:-1]\n",
    "                    three_word = first_word + \" \" + second_word + \" \" + third_word\n",
    "                    if three_word in self.three_word_skill_classification_set:\n",
    "                        self.ReClassificationSkillDictList(filename, filename, {three_word})\n",
    "                        have_classified = True\n",
    "\n",
    "                if not have_classified:\n",
    "                    self.ReClassificationSkillDictList(filename, filename + \" in tech\", {\"unknown\"})\n",
    "\n",
    "        self.InitKeywordDictList()\n",
    "        self.ExportSkillDictList()\n",
    "        self.ExportGroupDictList()\n",
    "\n",
    "    \"\"\"\n",
    "    This function for extract the technical skill in the description.\n",
    "    Two stages are used to extract the technical skill in the description,\n",
    "    the first stage are using the existing skill keyword (skill_dict_list) and do the extract matching.\n",
    "    the second stage is using spacy skillNer model to extract all the hard skill and soft skill are not in the \n",
    "    skill_dict_list\n",
    "    \"\"\"\n",
    "    def ExtractSkillKeyword(self, text):\n",
    "        skill_set = set()\n",
    "        text = self.WordPreprocessing(text)\n",
    "        words = text.split()\n",
    "\n",
    "        for i in range(2, len(words)):\n",
    "            search_word = words[i - 2] + \" \" + words[i - 1] + \" \" + words[i]\n",
    "            if search_word in self.three_keyword_dict_list:\n",
    "                skill_set.add(self.three_keyword_dict_list[search_word])\n",
    "        for i in range(1, len(words)):\n",
    "            search_word = words[i - 1] + \" \" + words[i]\n",
    "            if search_word in self.two_keyword_dict_list:\n",
    "                skill_set.add(self.two_keyword_dict_list[search_word])\n",
    "        for i in range(len(words)):\n",
    "            if words[i] in self.one_keyword_dict_list:\n",
    "                skill_set.add(self.one_keyword_dict_list[words[i]])\n",
    "\n",
    "        try:\n",
    "            annotations = self.skill_extractor.annotate(text)\n",
    "            # self.skill_extractor.describe(annotations)\n",
    "            result = annotations[\"results\"]\n",
    "            skill_list_1 = result[\"full_matches\"]\n",
    "            skill_list_2 = result[\"ngram_scored\"]\n",
    "\n",
    "            for i in range(len(skill_list_1)):\n",
    "                info = skill_list_1[i]\n",
    "                skill = info[\"doc_node_value\"]\n",
    "                skill = skill.lower()\n",
    "                skill_set.add(skill)\n",
    "            for i in range(len(skill_list_2)):\n",
    "                info = skill_list_2[i]\n",
    "                skill = info[\"doc_node_value\"]\n",
    "                skill = skill.lower()\n",
    "                skill_set.add(skill)\n",
    "        except:\n",
    "            print(\"skillNer error.\")\n",
    "\n",
    "        return list(skill_set)\n",
    "\n",
    "    \"\"\"\n",
    "    This function for compare both user and job description skill \n",
    "    \"\"\"\n",
    "    def GenerateSkillMatchScore(self, your_skill, job_skill):\n",
    "        result_dict = {\"Your Skills List\": None, \"Job Skills List\": None, \"Match Score\": None}\n",
    "        print(\"extract resume skill...\")\n",
    "        result_dict[\"Your Skills List\"] = self.ExtractSkillKeyword(your_skill)\n",
    "        print(\"extract job skill...\")\n",
    "        result_dict[\"Job Skills List\"] = self.ExtractSkillKeyword(job_skill)\n",
    "\n",
    "        match_list = []\n",
    "\n",
    "        for js in result_dict[\"Job Skills List\"]:\n",
    "            info = {\"Skill\": str(js), \"Score\": 0, \"Remarks\": str(\"\")}\n",
    "            if js in result_dict[\"Your Skills List\"]:\n",
    "                info[\"Score\"] = 1\n",
    "                info[\"Remarks\"] = \"Exact match with 1 of the user skill.\"\n",
    "                match_list.append(info)\n",
    "                continue\n",
    "\n",
    "            found = False\n",
    "            if js in self.group_dict_list:\n",
    "                group_skill_set = self.group_dict_list[js]\n",
    "                for gss in group_skill_set:\n",
    "                    if gss in result_dict[\"Your Skills List\"]:\n",
    "                        info[\"Score\"] = 1\n",
    "                        info[\"Remarks\"] = gss.title() + \" is \" + js.title() + \".\"\n",
    "                        found = True\n",
    "                        break\n",
    "            if found:\n",
    "                match_list.append(info)\n",
    "                continue\n",
    "\n",
    "            # future implement for comparing related functional user skills like mysql and oracle SQL,\n",
    "            # which both are sql will have some score point\n",
    "            # if js in self.skill_dict_list:\n",
    "            # group_skill_set = self.skill_dict_list[js]\n",
    "\n",
    "            info[\"Remarks\"] = js.title() + \" not found with in user skill.\"\n",
    "            match_list.append(info)\n",
    "\n",
    "        result_dict[\"Match Score\"] = match_list\n",
    "        return result_dict\n",
    "\n",
    "    \"\"\"\n",
    "    This function do all the necessary to generate leetcode learning content,\n",
    "    which consist frequency question from the company and\n",
    "    learning resource to learn all different type of question tag.\n",
    "    \"\"\"\n",
    "    def GenerateLeetcodeResource(self, company, generated_directory):\n",
    "\n",
    "        check_company = company\n",
    "        check_company = check_company.lower()\n",
    "        company_name_to_search = str(\"\")\n",
    "\n",
    "        for c in self.leetcode_company_dict_list:\n",
    "            check = c.lower()\n",
    "            if check == check_company:\n",
    "                company_name_to_search = c\n",
    "                break\n",
    "\n",
    "\n",
    "        if company_name_to_search == \"\":\n",
    "            try:\n",
    "                shutil.copyfile(\"leetcode/leetcode learning resource.html\",\"output/\" + generated_directory + \"/leetcode learning resource.html\")\n",
    "            except:\n",
    "                return \"IF BLOCK - Generate leetcode learning resource.html failed.\"\n",
    "            try:\n",
    "                shutil.copyfile(\"leetcode/leetcode learning resource.docx\",\"output/\" + generated_directory + \"/leetcode learning resource.docx\")\n",
    "            except:\n",
    "                return \"IF BLOCK - Generate leetcode learning resource.docx failed.\"\n",
    "\n",
    "            try:\n",
    "                df = pd.read_csv(\"leetcode/Top 100 Question List.csv\")\n",
    "                df[company + \" Company Frequency\"] = 0\n",
    "                df[\"Overall Frequency\"] = df[\"Frequency\"]\n",
    "                df = df.drop(columns=['Frequency'])\n",
    "                df.to_csv(\"output/\" + generated_directory + \"/leetcode question list.csv\", encoding='utf-8',index=False)\n",
    "            except:\n",
    "                return \"IF BLOCK - Generate leetcode question list failed.\"\n",
    "        else:\n",
    "            html_content = \"\"\n",
    "            title = \"<h1><u><b>\" + company + \" Leetcode Tag Type Appear in the Question Count</b></u></h1>\\n\"\n",
    "            html_content += title\n",
    "            html_content += \"<table>\\n\"\n",
    "            html_content += \"<tr>\\n\"\n",
    "            html_content += \"  <th>Tag</th>\\n\"\n",
    "            html_content += \"  <th>Count</th>\\n\"\n",
    "            html_content += \"</tr>\\n\"\n",
    "            try:\n",
    "                df = pd.read_csv(\"leetcode/Top Tag/\" + company_name_to_search + \".csv\")\n",
    "                for index, row in df.iterrows():\n",
    "                    html_content += \"<tr>\\n\"\n",
    "                    tag_html = \"  <td>\" + str(row[\"Tag\"]) + \"</td>\\n\"\n",
    "                    count_html = \"  <td>\" + str(row[\"Appearance\"]) + \"</td>\\n\"\n",
    "                    html_content += tag_html\n",
    "                    html_content += count_html\n",
    "                    html_content += \"</tr>\\n\"\n",
    "                html_content += \"</table>\\n\"\n",
    "            except:\n",
    "                return \"ELSE BLOCK - getting company tag count error.\"\n",
    "\n",
    "            try:\n",
    "                with open(\"leetcode/leetcode learning resource.html\", \"r\", encoding=\"utf-8\") as file:\n",
    "                    html_content += file.read()\n",
    "                    file.close()\n",
    "            except:\n",
    "                return \"ELSE BLOCK - in reading leetcode resource.html error.\"\n",
    "\n",
    "\n",
    "            with open(\"output/\" + generated_directory + \"/leetcode learning resource.html\", 'w',encoding='utf-8') as file:\n",
    "                file.write(html_content)\n",
    "                file.close()\n",
    "            pypandoc.convert_text(html_content, 'docx', format='html', outputfile=\"output/\" + generated_directory +\"/leetcode learning resource.docx\")\n",
    "\n",
    "\n",
    "            try:\n",
    "                df1 = pd.read_csv(\"leetcode/Companies Leetcode/\" + company_name_to_search + \".csv\")\n",
    "                df1[company + \" Company Frequency\"] = df1[\"Frequency\"]\n",
    "                df1 = df1.drop(columns=['Frequency'])\n",
    "                df1[\"Overall Frequency\"] = str(\"\")\n",
    "                for index, row in df1.iterrows():\n",
    "                    no = str(row['No'])\n",
    "                    if no in self.leetcode_overall_frequency_dict_list:\n",
    "                        df1.at[index, \"Overall Frequency\"] = self.leetcode_overall_frequency_dict_list[no]\n",
    "                df = pd.read_csv(\"leetcode/Top 100 Question List.csv\")\n",
    "                df[company + \" Company Frequency\"] = 0\n",
    "                df[\"Overall Frequency\"] = df['Frequency']\n",
    "                df = df.drop(columns=['Frequency'])\n",
    "                appended_df = pd.concat([df1, df], ignore_index=True)\n",
    "                appended_df = appended_df.drop_duplicates(keep='first')\n",
    "                final_df = appended_df.head(100).copy()\n",
    "                final_df.to_csv(\"output/\" + generated_directory + \"/leetcode question list.csv\",encoding='utf-8', index=False)\n",
    "            except:\n",
    "                return \"ELSE BLOCK - Generate leetcode quesiton list failed.\"\n",
    "            return \"LEETCODE SUCCESS\"\n",
    "\n",
    "    \"\"\"\n",
    "    This method is generate the skill learning resource which the job description required and the user did not \n",
    "    have the skill.\n",
    "    It chopped up 3 stages, preprocessing which consist (filter and search) and generate the skill learning resource\n",
    "    content.\n",
    "    \"\"\"\n",
    "    def GenerateSkillResource(self, skills, generated_directory):\n",
    "        result_dict = {\"Skill Learning Resource Content\": None, \"Skill Learning Resource Remarks\": str(\"\")}\n",
    "\n",
    "        result_dict[\"Skill Learning Resource Remarks\"], document_prepare_set = self.GenerateSkillResourcePreProcessing(\n",
    "            skills, result_dict[\"Skill Learning Resource Remarks\"])\n",
    "        if len(document_prepare_set) == 0:\n",
    "            return result_dict\n",
    "\n",
    "        result_dict[\"Skill Learning Resource Remarks\"], result_dict[\"Skill Learning Resource Content\"] = \\\n",
    "            self.GenerateSkillResourceContent(document_prepare_set, result_dict[\"Skill Learning Resource Remarks\"],\n",
    "                                              generated_directory)\n",
    "        return result_dict\n",
    "\n",
    "    def GenerateSkillResourcePreProcessing(self, skills, remarks):\n",
    "        document_prepare_set = set()\n",
    "\n",
    "        for key, value in skills.items():\n",
    "            remarks, skills[key] = self.SkillLearningResourceFilter(key, value, remarks)\n",
    "            if skills[key] != \"\":\n",
    "                remarks, document_prepare_set = self.SkillLearningResourceSearch(key, skills[key],\n",
    "                                                                                 document_prepare_set, remarks)\n",
    "        return remarks, document_prepare_set\n",
    "\n",
    "    def SkillLearningResourceFilter(self, key, text, remarks):\n",
    "        text = text.lower()\n",
    "        text = text.replace(\"/\", \" \")\n",
    "        if text.find('(') != -1:\n",
    "            text = text.split(\"(\")[0]\n",
    "            text = text.rsplit()[0]\n",
    "\n",
    "        if text in self.exact_match_replace_dict_list:\n",
    "            text = self.exact_match_replace_dict_list.get(text)\n",
    "        words = text.split()\n",
    "        new_text = \"\"\n",
    "        for word in words:\n",
    "            if word in self.partial_match_replace_dict_list:\n",
    "                new_text += self.partial_match_replace_dict_list.get(word)\n",
    "                new_text += \" \"\n",
    "            else:\n",
    "                new_text += word\n",
    "                new_text += \" \"\n",
    "        new_text = new_text[:-1]\n",
    "        lower_key = key.lower()\n",
    "        if lower_key != new_text:\n",
    "            if len(remarks) != 0:\n",
    "                remarks += \"\\n\"\n",
    "            remarks += key\n",
    "            remarks += \" also known as \"\n",
    "            remarks += new_text.title()\n",
    "        return remarks, new_text\n",
    "\n",
    "    def SkillLearningResourceSearch(self, key, text, document_prepare_set, remarks):\n",
    "        if text in self.skill_dict_list:\n",
    "            document_prepare_set.add(text)\n",
    "            return remarks, document_prepare_set\n",
    "\n",
    "        if text in self.group_dict_list:\n",
    "            document_prepare_set.add(text)\n",
    "            return remarks, document_prepare_set\n",
    "\n",
    "        # check for . - space and .js\n",
    "        for sdl in self.skill_dict_list:\n",
    "\n",
    "            check1 = sdl\n",
    "            check1 = re.sub(r'\\b(\\w+)s\\b', r'\\1', check1)\n",
    "            check2 = text\n",
    "            check2 = re.sub(r'\\b(\\w+)s\\b', r'\\1', check2)\n",
    "            if check1 == check2:\n",
    "                document_prepare_set.add(sdl)\n",
    "                return remarks, document_prepare_set\n",
    "            check1 = sdl\n",
    "            check1 = check1.replace(\".\", \"\")\n",
    "            check2 = text\n",
    "            check2 = check2.replace(\".\", \"\")\n",
    "            if check1 == check2:\n",
    "                document_prepare_set.add(sdl)\n",
    "                return remarks, document_prepare_set\n",
    "            check1 = sdl\n",
    "            check1 = check1.replace(\"-\", \" \")\n",
    "            check2 = text\n",
    "            check2 = check2.replace(\"-\", \" \")\n",
    "            if check1 == check2:\n",
    "                document_prepare_set.add(sdl)\n",
    "                return remarks, document_prepare_set\n",
    "            check1 = sdl\n",
    "            check1 = check1.replace(\" \", \"\")\n",
    "            check2 = text\n",
    "            check2 = check2.replace(\" \", \"\")\n",
    "            if check1 == check2:\n",
    "                document_prepare_set.add(sdl)\n",
    "                return remarks, document_prepare_set\n",
    "            check1 = sdl\n",
    "            check1 = check1.replace(\".js\", \"\")\n",
    "            check1 = check1.replace(\"js\", \"\")\n",
    "            check2 = text\n",
    "            check2 = check2.replace(\".js\", \"\")\n",
    "            check2 = check2.replace(\"js\", \"\")\n",
    "            if check1 == check2:\n",
    "                document_prepare_set.add(sdl)\n",
    "                return remarks, document_prepare_set\n",
    "\n",
    "        found = False\n",
    "        words = text.split()\n",
    "        # check word by word\n",
    "        for word in words:\n",
    "            if word not in self.partial_search_ignore_list:\n",
    "                if word in self.skill_dict_list:\n",
    "                    document_prepare_set.add(word)\n",
    "                    if len(remarks) != 0:\n",
    "                        remarks += \"\\n\"\n",
    "                    remarks += key\n",
    "                    remarks += \" also known as \"\n",
    "                    remarks += word.title()\n",
    "                    found = True\n",
    "\n",
    "        if not found:\n",
    "            if len(remarks) != 0:\n",
    "                remarks += \"\\n\"\n",
    "            remarks += key\n",
    "            remarks += \" not found\"\n",
    "        return remarks, document_prepare_set\n",
    "\n",
    "    def GenerateSkillResourceContent(self, document_prepare_set, remarks, generated_directory):\n",
    "        skill_dict = {}\n",
    "        html_content = \"\"\n",
    "        for d in document_prepare_set:\n",
    "            if d in self.skill_dict_list:\n",
    "                v = self.skill_dict_list.get(d)\n",
    "                path = v.resource_path\n",
    "            else:\n",
    "                continue\n",
    "            if not os.path.isfile(path):\n",
    "                if len(remarks) != 0:\n",
    "                    remarks += \"\\n\"\n",
    "                remarks += \"can't generate content for \"\n",
    "                remarks += d.title()\n",
    "            else:\n",
    "                with open(path, \"r\", encoding=\"utf-8\") as file:\n",
    "                    title = d.title()\n",
    "                    html_content += \"<h1><u><b>\"\n",
    "                    html_content += title\n",
    "                    html_content += \"</b></u></h1>\"\n",
    "                    file_content = file.read()\n",
    "                    html_content += file_content\n",
    "                    skill_dict[title] = self.ConvertHtmlToString2(file_content)\n",
    "                file.close()\n",
    "        with open(\"output/\" + generated_directory + \"/skill learning resource.html\", 'w',\n",
    "                  encoding='utf-8') as file:\n",
    "            file.write(html_content)\n",
    "            file.close()\n",
    "        pypandoc.convert_text(html_content, 'docx', format='html',\n",
    "                              outputfile=\"output/\" + generated_directory + \"/skill learning resource.docx\")\n",
    "        return remarks, skill_dict\n",
    "\n",
    "    \"\"\"\n",
    "    This method to zip all the file and ready to send to the user\n",
    "    \"\"\"\n",
    "    @staticmethod\n",
    "    def ZipLearningResource(generated_directory):\n",
    "        directory_path = \"output/\" + generated_directory\n",
    "        zip_filename = \"output/\" + generated_directory + \"/learning resource.zip\"\n",
    "        valid_extensions = ('.html', '.docx', '.csv', '.json')\n",
    "\n",
    "        with zipfile.ZipFile(zip_filename, 'w') as zipf:\n",
    "            for folder_name, sub_folders, filenames in os.walk(directory_path):\n",
    "                for filename in filenames:\n",
    "                    if filename.endswith(valid_extensions):\n",
    "                        file_path = os.path.join(folder_name, filename)\n",
    "                        zipf.write(file_path, arcname=filename)\n",
    "\n",
    "    \"\"\"\n",
    "    The main function which the user will call from the flask.\n",
    "    \"\"\"\n",
    "    def GenerateLearningResource(self, resume, job_description, company_name, generated_directory):\n",
    "\n",
    "        result_dict = {\"Skill Learning Resource Content\": None,\n",
    "                       \"Skill Learning Resource Remarks\": str(\"\"),\n",
    "                       \"Match Score\": None}\n",
    "\n",
    "        if not os.path.exists(\"output\"):\n",
    "            os.makedirs(\"output\")\n",
    "        if not os.path.exists(\"output/\" + generated_directory):\n",
    "            os.makedirs(\"output/\" + generated_directory)\n",
    "\n",
    "        # Path to the specific folder\n",
    "        folder_path = \"output/\" + generated_directory\n",
    "\n",
    "        # List all files in the folder\n",
    "        files = glob.glob(folder_path + '/*')\n",
    "\n",
    "        # Loop through the list and delete each file\n",
    "        for f in files:\n",
    "            try:\n",
    "                os.remove(f)\n",
    "            except OSError as e:\n",
    "                print(f\"Error: {f} : {e.strerror}\")\n",
    "\n",
    "\n",
    "        result = self.GenerateSkillMatchScore(resume, job_description)\n",
    "\n",
    "\n",
    "        job_skills = result[\"Job Skills List\"]\n",
    "        result_dict[\"Match Score\"] = result[\"Match Score\"]\n",
    "\n",
    "        for i in range(len(job_skills)):\n",
    "            text = job_skills[i]\n",
    "            text = text.lower()\n",
    "            if text in self.leetcode_list:\n",
    "                print(\"Getting leetcode learning resource..\")\n",
    "                debug_result = self.GenerateLeetcodeResource(company_name, generated_directory)\n",
    "                if debug_result !=\"LEETCODE SUCCESS\":\n",
    "                    return debug_result\n",
    "                break\n",
    "\n",
    "        ms_list = result[\"Match Score\"]\n",
    "        difference_skill_dict_list = {}\n",
    "        for i in range(len(ms_list)):\n",
    "            info = ms_list[i]\n",
    "            if info[\"Score\"] != 1:\n",
    "                key = info[\"Skill\"]\n",
    "                difference_skill_dict_list[key] = key\n",
    "\n",
    "        if len(difference_skill_dict_list) != 0:\n",
    "            print(\"Getting skill learning resource..\")\n",
    "            skill_result_dict = self.GenerateSkillResource(difference_skill_dict_list, generated_directory)\n",
    "            result_dict[\"Skill Learning Resource Content\"] = skill_result_dict[\"Skill Learning Resource Content\"]\n",
    "            result_dict[\"Skill Learning Resource Remarks\"] = skill_result_dict[\"Skill Learning Resource Remarks\"]\n",
    "\n",
    "        filename = \"output/\" + generated_directory + \"/response.json\"\n",
    "        # print(result_dict[\"Skill Learning Resource Remarks\"])\n",
    "\n",
    "        # Serialize and write the list of dictionaries to a file\n",
    "        with open(filename, 'w') as file:\n",
    "            json.dump(result_dict, file, indent=4)\n",
    "\n",
    "        self.ZipLearningResource(generated_directory)\n",
    "        return \"success\"\n",
    "\n",
    "\n",
    "app = Flask(__name__)\n",
    "learning_resource = LearningResourceService()\n",
    "\n",
    "\n",
    "# @app.route('/generate_learning_resource', methods=['GET'])\n",
    "@app.route('/')\n",
    "def generate_learning_resource():\n",
    "    print(\"triggered\")\n",
    "\n",
    "    resume_sample = \"\"\"\n",
    "\n",
    "Programming languages: C/C++, C#, Java, Python, Groovy, JavaScript, Typescript\n",
    "Frameworks & Lib: .NET, Spring, Angular, Cuda, Imgui, WPF, OpenGL, Vulkan, Nvidia PhysX, Pandas, NumPy,\n",
    "Scikit learn, Spacy, NLTK, PySpark, Seaborn, Matplotlib, Selenium Base, Junit, PyTest, streamlit, transformers,\n",
    "PyTorch, xgboost, restful\n",
    "Databases: MS SQL, MySQL, JPA, Cassandra, SQLite, Neo4j\n",
    "Cloud: Azure, AWS\n",
    "Platform: Window, Linux, Ubuntu, Databricks\n",
    "Game Engine: Unreal Engine, Unity\n",
    "Web Development: HTML, CSS\n",
    "IDE:VS Code, IntelliJ, Anaconda, Pycharm\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    job_description_sample = \"\"\"\n",
    "    Responsibilities:\\nCollaborate with business stakeholders to understand their data needs and objectives.\\n\n",
    "    Collect, clean, and preprocess data from various sources for analysis.\\n\n",
    "    Perform exploratory data analysis to identify trends, patterns, and correlations.\\n\n",
    "    Develop and implement predictive models and machine learning algorithms to solve business challenges.\\n\n",
    "    Apply statistical analysis techniques to analyze complex datasets and draw meaningful conclusions.\\n\n",
    "    Create data visualizations and reports to communicate insights effectively to non-technical audiences.\\n\n",
    "    Collaborate with data engineers to optimize data pipelines for efficient data processing.\\n\n",
    "    Conduct A/B testing and experimentation to evaluate the effectiveness of different strategies.\\n\n",
    "    Stay up-to-date with advancements in data science, machine learning, and artificial intelligence.\\n\n",
    "    Assist in the development and deployment of machine learning models into production environments.\\n\n",
    "    Provide data-driven insights and recommendations to support strategic decision-making.\\n\n",
    "    Collaborate with other data scientists, analysts, and cross-functional teams to drive data initiatives.\\n\n",
    "    Requirements:\\n\n",
    "    Bachelor's degree in Data Science, Computer Science, Statistics, Mathematics, or a related field \n",
    "    (or equivalent practical experience).\\n\n",
    "    Proven experience as a Data Scientist or similar role, with a portfolio of data science projects that \n",
    "    demonstrate your analytical skills.\\n\n",
    "    Proficiency in programming languages such as Python or R for data manipulation and analysis.\\n\n",
    "    Strong understanding of statistical analysis, machine learning algorithms, and data visualization techniques.\\n\n",
    "    Experience with machine learning frameworks and libraries (e.g., scikit-learn, TensorFlow, PyTorch).\\n\n",
    "    Familiarity with data manipulation libraries (e.g., Pandas, NumPy) and data visualization tools (e.g.,\n",
    "     Matplotlib, Seaborn).\\nSolid understanding of SQL and database concepts for querying and extracting data.\\n\n",
    "     Excellent problem-solving skills and the ability to work with complex, unstructured datasets.\\n\n",
    "     Effective communication skills to explain technical concepts to non-technical stakeholders.\\n\n",
    "     Experience with big data technologies (e.g., Hadoop, Spark) is a plus.\\n\n",
    "     Knowledge of cloud platforms and services for data analysis (e.g., AWS, Azure) is advantageous.\\n\n",
    "     Familiarity with natural language processing (NLP) and text analysis is a plus.\\n\n",
    "     Advanced degree (Master's or PhD) in a related field is beneficial but not required.\n",
    "    \"\"\"\n",
    "    company_sample = \"JPMorgan\"\n",
    "\n",
    "    resume = request.args.get('param1', default=None, type=str)\n",
    "    job_description = request.args.get('param2', default=None, type=str)\n",
    "    company = request.args.get('param3', default=None, type=str)\n",
    "\n",
    "    if resume is None:\n",
    "        resume = resume_sample\n",
    "\n",
    "    if job_description is None:\n",
    "        job_description = job_description_sample\n",
    "\n",
    "    if company is None:\n",
    "        company = company_sample\n",
    "\n",
    "    generated_directory = str(learning_resource.GetRequestQueueNo())\n",
    "    result = learning_resource.GenerateLearningResource(resume, job_description, company, generated_directory)\n",
    "    if result != \"success\":\n",
    "        return result\n",
    "\n",
    "    learning_resource_zip_path = \"output/\" + generated_directory + \"/learning resource.zip\"\n",
    "    return send_file(learning_resource_zip_path, as_attachment=True, download_name='learning resource.zip')\n",
    "\n",
    "@app.route(\"/ping\")\n",
    "def ping():\n",
    "    return 'ping'\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    serve(app, host='0.0.0.0', port=5000)\n",
    "    #run_simple('localhost', 5000, app)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2819df6-722a-4d9e-ba0e-bc56fca7a474",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b6c426e-98d9-485d-9795-73d5de1a2cf9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
